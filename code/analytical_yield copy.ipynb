{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical computation of the Maximum formation efficiency\n",
    "\n",
    "As described in section 2 from the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvanson/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "import multiprocessing as mp\n",
    "\n",
    "# add run_data path to sys\n",
    "sys.path.append('./run_data')\n",
    "from definitions import sim_flags_dict\n",
    "\n",
    "\n",
    "######################################\n",
    "## PLOT setttings\n",
    "plt.rc('font', family='serif')\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "fsize, SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = 30,20,25,30\n",
    "for obj in ['axes','xtick','ytick']:\n",
    "    plt.rc(obj, labelsize=SMALL_SIZE)          # controls default text sizes\n",
    "for obj in ['figure','axes']:\n",
    "    plt.rc(obj, titlesize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "\n",
    "\n",
    "home_dir    = os.path.expanduser(\"~\") \n",
    "compas_v    = \"v03.01.02\" #\"v02.46.01\" # #\"#v02.35.02/\"\n",
    "datar_root  =  f\"{home_dir}/ceph/CompasOutput/{compas_v}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate maximum formation efficiency\n",
    "\n",
    "We approximate the 'maximum' formation efficiency using a drake equation:\n",
    "\n",
    "\\begin{equation}\n",
    "     \\eta_{form} = \\frac{1}{\\langle M_{SF} \\rangle } \\Bigl( f_{\\mathrm{primary}} \\times f_{\\mathrm{secondary}} \\times f_{\\mathrm{init \\, sep}} \\times f_{\\mathrm{survive \\, SN1}} \\times f_{\\mathrm{survive \\, SN2}} \\Bigr)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### Probability of forming \n",
    "\n",
    "We approximate the terms _within the round brackets of Equation 2 above_ with the probability to form a pair of massive stars with the `right' set of (initial) conditions. The conditions in questions are random variables at ZAMS (the primary mass, $m_1$, secondary mass, $m_2$, orbital separation, $a$), and factors affecting the stars' survival during supernovae in the first and second mass transfer phases. \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(m_1, ~m_2, ~a, ~\\text{survive SN1}, ~\\text{survive SN2}) \n",
    "& = p(m_1) \\times p(m_2~|~m_1) \\\\\n",
    "& \\times p(a ~|~m_1, ~m_2) \\\\\n",
    "& \\times  p(\\text{survive SN1}~|~m_1, ~m_2, ~a) \\\\\n",
    "& \\times p(\\text{survive SN2}~|~m_1, ~m_2, ~a, ~\\text{survive SN1})\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "By integrating over the relevant ranges of $m_1, ~q, ~a, ~\\text{survive SN1}, ~\\text{survive SN2} \\in C$, we obtain the probability for a specific type of compact binary merger to occur. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Primary and secondary masses\n",
    "We compute the probability that $m_2$ falls within a certain mass range [c,d] given that $m_1$ within a certain mass range [a,b]:\n",
    "\n",
    "\\begin{equation} \n",
    "\\begin{split}\n",
    "f_{\\text{primary}} \\times f_{\\text{secondary}} \n",
    "&  \\approx   \\int_{m_1 = a}^{m_1 = b} \\int_{m_2 = c}^{m_2 = d} p(m_1) \\times p(m_2 | m_1)\n",
    "%\\frac{M_{\\odot}}{m_1}p(q~|~m_1)    d(m_1/M_{\\odot}) ~dq\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "We can write $m_2$ in terms of the mass ratio $q \\equiv m_2/m_1 < 1$:\n",
    "\\begin{equation}\n",
    "    p(m_2~|~m_1) = \\frac{\\partial q}{\\partial (m_2/M_{\\odot})} p(q~|~m_1) = \\frac{1}{m_1/M_{\\odot}} p(q~|~m_1)\n",
    "\\end{equation}\n",
    "\n",
    "We assume $p(q)$ follows a uniform probability distribution between $0$ and $1$:\n",
    "\\begin{equation} \n",
    "    p(q~|~m_1) = U(q|0,1)\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "We assume $p(m_1)$ follows the Kroupa IMF, defined as:\n",
    "\\begin{equation} \n",
    "\\text{Kroupa IMF}(m_1) = (\\text{constant})\n",
    "    \\begin{cases}\n",
    "      \\big(\\frac{m_1}{M_{\\odot}}\\big)^{-0.3} & 0.05~M_{\\odot} \\leq m_1 < 0.08~M_{\\odot}\\\\\n",
    "      \\big(\\frac{m_1}{M_{\\odot}}\\big)^{-1.3} & 0.08~M_{\\odot} \\leq m_1 < 0.5~M_{\\odot}\\\\\n",
    "      \\big(\\frac{m_1}{M_{\\odot}}\\big)^{-2.3} & 0.5~M_{\\odot} \\leq m_1 < 1~M_{\\odot}\\\\\n",
    "      \\big(\\frac{m_1}{M_{\\odot}}\\big)^{-2.7} & 1~M_{\\odot} \\leq m_1 < 20~M_{\\odot}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n",
    "%We interpret $p(q~|~m_1)$ as follows: given a fixed primary mass $m_1$, this represents the probability density of finding a partner star such that the mass ratio becomes $q$. \n",
    "\n",
    "The constant is determined by normalizing the IMF over the entire mass range:\n",
    "\\begin{equation*}\n",
    "    \\text{constant} = \\Big[ \\frac{0.08^{(-0.3+1)}-0.05^{(-0.3+1)}}{(-0.3+1)} + \\frac{0.5^{(-1.3+1)}-0.08^{(-1.3+1)}}{(-1.3+1)} + \\frac{1^{(-2.3+1)}-0.5^{(-2.3+1)}}{(-2.3+1)} + \\frac{20^{(-2.7+1)}-1^{(-2.7+1)}}{(-2.7+1)} \\Big]^{-1}\n",
    "\\end{equation*}\n",
    "Note that we set the minimum and maximum stellar masses to $0.05~M_{\\odot}$ and $300~M_{\\odot}$, respectively.\n",
    "\n",
    "\n",
    "Combining equations above we get:\n",
    "\n",
    "\\begin{equation}\n",
    "        f_{\\text{primary}} \\times f_{\\text{secondary}} = \\int_{m_1=a}^{m_1=b} d(m_1/M_{\\odot}) \\int_{q=c/m_1}^{q=d/m_1} dq ~\\text{Kroupa IMF}(m_1) \\times \\frac{M_{\\odot}}{m_1}U(q|0,1)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20881520176143864\n"
     ]
    }
   ],
   "source": [
    "# the integral of a piece (or term) of a broken powerlaw\n",
    "def norm_term(minm, maxm, power):\n",
    "    return (maxm**(power + 1) - minm**(power + 1)) / (power + 1)\n",
    "\n",
    "term1 = norm_term(0.05, 0.08, -0.3)\n",
    "term2 = norm_term(0.08, 0.5, -1.3)\n",
    "term3 = norm_term(0.5, 1, -2.3)\n",
    "term4 = norm_term(1, 300, -2.7)\n",
    "\n",
    "constant = 1/(term1+ term2 + term3 + term4)\n",
    "print(constant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BHBH\n",
    "\n",
    "For BHBH, we assume both primary and secondary masses range from [$20M_{\\odot}$,$300M_{\\odot}$]\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    f_{\\text{primary}} \\times f_{\\text{secondary}}\n",
    "    & = (\\text{constant}) \\int_{m_1=20M_{\\odot}}^{m_1=300M_{\\odot}} d(m_1/M_{\\odot}) \\int_{q=20/m_1}^{q=300/m_1} dq ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-2.7} \\times \\frac{M_{\\odot}}{m_1} \\\\\n",
    "    & = \\text{constant} \\int_{m_1=20M_{\\odot}}^{m_1=20M_{\\odot}} \\left(\\frac{20}{m_1} - \\frac{20}{m_1} \\right) ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-3.7} \\\\\n",
    "    & = \\text{constant} \\int_{m_1=20M_{\\odot}}^{m_1=20M_{\\odot}} m_1 ^{-1} \\left(20 - 20 \\right) ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-3.7} \\\\\n",
    "    & = \\text{constant}  \\left(20 - 20 \\right) \\int_{m_1=20M_{\\odot}}^{m_1=20M_{\\odot}} ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-4.7} \\\\\n",
    "    & = \\text{constant}  \\frac{\\left(300 - 20 \\right)}{-3.7} \\Big[ \\left(\\frac{m_1}{M_{\\odot}}\\right)^{-3.7} \\Big]^{300}_{20} \\\\\n",
    "    & = \\text{constant}  \\frac{\\left(300 - 20 \\right)}{-3.7} \\Big[ 300^{-3.7} - 20^{-3.7} \\Big]\\\\\n",
    "    & = 2.43 \\times 10^{-4}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "We can write this more generally as:\n",
    "\n",
    "Generally: \n",
    "\\begin{equation}\n",
    "    f_{\\text{primary}} \\times f_{\\text{secondary}} = \\text{constant}  \\frac{\\left(d - c \\right)}{-3.7} \\Big[b^{-3.7} - a^{-3.7} \\Big]\\\\\n",
    "\\end{equation}\n",
    "\n",
    "for $m_1 = [a,b]$ and $m_2 = [c,d]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00024259849614994677\n",
      "0.00024259849614994677\n"
     ]
    }
   ],
   "source": [
    "print((constant * (300 - 20)/-3.7) * (300**-3.7 - 20**-3.7) ) \n",
    "\n",
    "def f_primaryXf_secondary(power, a,b,c,d, C1 = constant):\n",
    "    # here power is the powerlaw that the mass distribution pdf follows. \n",
    "    # This only works if a-b, and c-d all fall within one leg of the Kroupa IMF\n",
    "    # i.e. have the same power alpha\n",
    "    return C1 * (d-c)/(power- 1) * (b**(power-1) - a**(power-1) )\n",
    "\n",
    "f_primaryf_secondary_bhbh = f_primaryXf_secondary(-2.7, 20,300,20,300, C1 = constant) \n",
    "print(f_primaryf_secondary_bhbh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSNS\n",
    "\n",
    "For NSNS we assume both primary and secondary masses range from [$8M_{\\odot}$,$20M_{\\odot}$]\n",
    "\n",
    "<!-- \\begin{equation}\n",
    "\\begin{split}\n",
    "    f_{\\text{primary}} \\times f_{\\text{secondary}}\n",
    "    & = (\\text{constant}) \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} d(m_1/M_{\\odot}) \\int_{q=8/m_1}^{q=20/m_1} dq ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-2.7} \\times \\frac{M_{\\odot}}{m_1} \\\\\n",
    "    & = \\text{constant} \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} \\left(\\frac{20}{m_1} - \\frac{8}{m_1} \\right) ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-3.7} \\\\\n",
    "    & = \\text{constant} \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} m_1 ^{-1} \\left(20 - 8 \\right) ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-3.7} \\\\\n",
    "    & = \\text{constant}  \\left(20 - 8 \\right) \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-4.7} \\\\\n",
    "    & = \\text{constant}  \\frac{\\left(20 - 8 \\right)}{-3.7} \\Big[ \\left(\\frac{m_1}{M_{\\odot}}\\right)^{-3.7} \\Big]^{20}_{8} \\\\\n",
    "    & = \\text{constant}  \\frac{\\left(20 - 8 \\right)}{-3.7} \\Big[ 20^{-3.7} - 8^{-3.7} \\Big]\\\\\n",
    "    & = 2.43 \\times 10^{-4}\n",
    "\\end{split}\n",
    "\\end{equation} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002981404745950069\n"
     ]
    }
   ],
   "source": [
    "f_primaryf_secondary_nsns = f_primaryXf_secondary(-2.7, 8,20,8,20, C1 = constant) \n",
    "\n",
    "print(f_primaryf_secondary_nsns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BHNS\n",
    "\n",
    "Lastly for BHNS we assume $m_1 = [20M_{\\odot}$,$300M_{\\odot}]$ while $m_2 = [8M_{\\odot}$,$20M_{\\odot}]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0397078406426292e-05\n"
     ]
    }
   ],
   "source": [
    "f_primaryf_secondary_bhns =  f_primaryXf_secondary(-2.7, 20,300,8,20, C1 = constant)\n",
    "print(f_primaryf_secondary_bhns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for $f_{init sep}$, we adopt the fraction of systems that interacts ever. \n",
    "\n",
    "We assume that binaries can form with separations between 0.01AU and 1000 AU \n",
    "\n",
    "we assume a flat-in-log distribution of initial separations\n",
    "\n",
    "\\begin{equation}\n",
    "P(a_i) = 1/a_i\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "f_{init sep} = \\frac{\\log(a_i)|_{mina}^{maxa} }{\\log(a_i)|_{0.01 AU}^{1000 AU} }\n",
    "\\end{equation}\n",
    "\n",
    "where $mina$ and $maxa$ are the min and max separation for interaction,\n",
    "For the minimum, we look at our case A,B C plots, and stars have radii of $3-20R_{\\odot}$ at birth (roughly), leading to a range of 0.0279AU - 0.186AU. We adopt the average of $mina \\approx 0.1 AU$\n",
    "\n",
    "For the upper end, we use our max R per Z to estimate this. Very roughly stars range between a max R of 1000 and 5000, so we adopt $maxa \\approx 3000 R_{\\odot} = 13.95 AU$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "f_{init sep} = \\frac{\\log(13.95) - \\log(0.1)}{\\log(1000) - \\log(0.01)} \\approx 0.42\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42891484152192333\n"
     ]
    }
   ],
   "source": [
    "print( (np.log(13.95) - np.log(0.1))/ (np.log(1000) - np.log(0.01)) )\n",
    "f_init_sep = 0.42 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability to survive SN1 and SN2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We assume no kicks for BBH so $f_{SN1} = f_{SN2} = 1$\n",
    "\n",
    " We assume full kicks for NSNS so $f_{SN2} = f_{SN1} \\approx 0.2$ (See derivationin appendix A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sn1_bbh = 1.\n",
    "f_sn2_bbh = 1.\n",
    "\n",
    "f_sn1_nsns = 0.14\n",
    "f_sn2_nsns = 0.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average SF mass per binary system\n",
    "\n",
    "We use the 'total mass evolved per Z' function that we also use for the yield calculations for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalMassEvolvedPerZ(pathCOMPASh5, x2=0.08, x3=0.5, a1=-0.3, a2=-1.3, a3=-2.3, C1=1.,\n",
    "                         binaryFraction=0.7, Mmin_universe=0.1, Mmax_universe=300., sampleSize=2000000):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        # COMPAS simulation parameters\n",
    "        pathCOMPASh5 (_type_, optional): path to your COMPAS file. Defaults to None.\n",
    "\n",
    "        # Broken powerlaw (Kroupa IMF) parameters\n",
    "        x1, x2, x3, x4: float, the break points (mass ranges) for the three segments\n",
    "        a1, a2, a3: float, the power law indices \n",
    "        <0.01 - 0.08> a = -0.3, <0.08 - 0.5> a = -1.3, <0.5 - 200> a = -2.3\n",
    "        C1: float, the normalization constant for the first segment\n",
    "        \n",
    "        # Believes about star formation in the Universe\n",
    "        binaryFraction (int, optional): What fraction of stars are in binaries. Default= 1.\n",
    "        Mmin_universe, Mmax_universe (float): the min and max mass that stars in the Universe can be born with  Defaults: 0.01 and 200.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\" \n",
    "    x1 = Mmin_universe\n",
    "    x4 = Mmax_universe\n",
    "\n",
    "    # Open the COMPAS file\n",
    "    COMPASdataf = h5.File(pathCOMPASh5, 'r')\n",
    "\n",
    "    # Min and max M sampled in your COMPAS simulation.\n",
    "    COMPAS_m1       = COMPASdataf['BSE_System_Parameters']['Mass@ZAMS(1)'][()]\n",
    "    Mlower_COMPAS   = np.min(COMPAS_m1)\n",
    "    Mupper_COMPAS   = np.max(COMPAS_m1)\n",
    "\n",
    "    ##########################\n",
    "    # Create Sample Universe \n",
    "    ##########################\n",
    "    # we will use 'inverse transform sampling method' to sample our sample Universe from the IMF\n",
    "\n",
    "    ### Primary mass\n",
    "    # first we compute the y-values of the CDF of our IMF at Mmin_universe and Mmax_universe\n",
    "    # Mmin_universe and Mmax_universe have to be between x1 and x4\n",
    "    CDFmin = CDFbrokenPowerLaw(np.array([Mmin_universe]), x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "    CDFmax = CDFbrokenPowerLaw(np.array([Mmax_universe]), x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "\n",
    "    # Now we can sample Uniformly from the CDF between CDFmin and CDFmax\n",
    "    drawM1      = np.random.uniform(CDFmin,CDFmax,sampleSize)\n",
    "    # Convert CDF values back to masses\n",
    "    M1          = invertCDFbrokenPowerLaw(drawM1, x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "\n",
    "    ### Binary fraction\n",
    "    # we want that binaryFraction of the stars are in binaries\n",
    "    # Hence by drawing between 0-1, we have to throw out everything that is above binaryFraction (i.e. = single and m2 = 0)\n",
    "    # ! NOTE that this assumes that the binary Fraction is mass indepent! > Future work to implenet Max Moe ps and qs options\n",
    "    drawBinary      = np.random.uniform(0,1,sampleSize)\n",
    "    maskBinary      = drawBinary < binaryFraction  #booleans\n",
    "\n",
    "    ### Secondary mass\n",
    "    # mass ratio (q = m2/m1) distribution is assumed to be flat \n",
    "    # so then the drawM2 (if it is in a binary) just becomes the mass fraction.\n",
    "    drawM2          = np.random.uniform(0,1,sampleSize)    # we are actually sampling q\n",
    "    M2              = np.zeros(sampleSize)                 #\n",
    "    M2[maskBinary]  = drawM2[maskBinary] * M1[maskBinary]  # = q * m1, all the ones outside the mask remain zero\n",
    "    \n",
    "    totalMassInStarFormation = np.sum(M1) + np.sum(M2)\n",
    "\n",
    "    ##########################\n",
    "    # Select what lies in the range of COMPAS\n",
    "    ##########################\n",
    "    # mask M1 and M2 to see what lies in the range of COMPAS\n",
    "    maskM1          = (M1>=Mlower_COMPAS) & (M1<=Mupper_COMPAS)\n",
    "    maskBinaries    = (M2!=0)\n",
    "    mask_COMPAS     = maskM1 & maskBinaries\n",
    "\n",
    "    totalMassEvolvedCOMPAS = np.sum(M1[mask_COMPAS]) + np.sum(M2[mask_COMPAS])\n",
    "\n",
    "    ##########################\n",
    "    # Finally compute the tot mass evolved per Z\n",
    "    ##########################\n",
    "    \n",
    "    # load a bit more COMPAS data\n",
    "    COMPAS_m2       = COMPASdataf['BSE_System_Parameters']['Mass@ZAMS(2)'][()]\n",
    "    COMPAS_metals   = COMPASdataf['BSE_System_Parameters']['Metallicity@ZAMS(1)'][()]\n",
    "    uniqueZ_COMPAS  = np.unique(COMPAS_metals)\n",
    "    \n",
    "    # Determine if your samples are weighted\n",
    "    # boolWeighted = 'mixture_weight' in COMPASdataf['BSE_System_Parameters'].keys()\n",
    "\n",
    "    # I assume that if you have more than 100 metallicities, it's not discrete, but a continuous Z distribution\n",
    "    w_NbinariesEvolvedPerZ = []                                                           # Nbinaries simulated per Z //floor\n",
    "    for Z in uniqueZ_COMPAS:\n",
    "        mask = COMPAS_metals == Z\n",
    "        Nbinaries = len(COMPAS_m1[mask])\n",
    "        w_NbinariesEvolvedPerZ.append(Nbinaries)\n",
    "    w_NbinariesEvolvedPerZ        = np.array(w_NbinariesEvolvedPerZ)\n",
    "    w_AverageMassPerBinaryCOMPAS  = totalMassEvolvedCOMPAS / len(M1[mask_COMPAS])         # average mass of a binary in COMPAS simulation  //floor\n",
    "    w_MassEvolvedPerZ             = w_AverageMassPerBinaryCOMPAS * w_NbinariesEvolvedPerZ     # //floor    \n",
    "\n",
    "    # Simulation with discrete metallicities\n",
    "    total = []\n",
    "    for Z in uniqueZ_COMPAS:\n",
    "        Zmask = COMPAS_metals == Z\n",
    "        total.append( np.sum(COMPAS_m1[Zmask]) + np.sum(COMPAS_m2[Zmask]) )\n",
    "\n",
    "        MassEvolvedPerZ  = np.array(total)\n",
    "\n",
    "    # fraction of total universe that was sampled by COMPAS\n",
    "    fraction = totalMassEvolvedCOMPAS/float(totalMassInStarFormation)\n",
    "\n",
    "    # We need to muliply the mass evolved per metallicity times (1/fraction) to know the total mass evolved per metallicity\n",
    "    totalMassEvolvedPerMetallicity = (MassEvolvedPerZ)/(fraction)\n",
    "\n",
    "    return w_NbinariesEvolvedPerZ, w_AverageMassPerBinaryCOMPAS, w_MassEvolvedPerZ, totalMassEvolvedCOMPAS, float(totalMassInStarFormation),  MassEvolvedPerZ\n",
    "\n",
    "\n",
    "def CDFbrokenPowerLaw(x, x1=0.01, x2=0.08, x3=0.5, x4=200, a1=-0.3, a2=-1.3, a3=-2.3, C1=1):\n",
    "    \"\"\"\n",
    "    CDF values of a three-part broken powerlaw representing a Kroupa IMF by default.\n",
    "    \n",
    "    Parameters:\n",
    "    x: array-like, the input values\n",
    "    x1, x2, x3, x4: float, the break points (mass ranges) for the three segments\n",
    "    a1, a2, a3: float, the power law indices \n",
    "    C1: float, the normalization constant for the first segment\n",
    "    \n",
    "    Returns:\n",
    "    yvalues: array-like, the output values of the CDF\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the output array\n",
    "    yvalues = np.zeros(len(x))\n",
    "    \n",
    "    # Calculate the normalization constants for the other segments\n",
    "    # Ensuring that the next segments start where the previous segment ends\n",
    "    C2 = float(C1 * (x2**(a1-a2)))\n",
    "    C3 = float(C2 * (x3**(a2-a3)))\n",
    "    \n",
    "    # Calculate the normalization factors for the three segments\n",
    "    N1 = float(((1./(a1+1)) * C1 * (x2**(a1+1))) - ((1./(a1+1)) * C1 * (x1**(a1+1))))\n",
    "    N2 = float(((1./(a2+1)) * C2 * (x3**(a2+1))) - ((1./(a2+1)) * C2 * (x2**(a2+1))))\n",
    "    N3 = float(((1./(a3+1)) * C3 * (x4**(a3+1))) - ((1./(a3+1)) * C3 * (x3**(a3+1))))\n",
    "    \n",
    "    # Calculate the denominator of the CDF\n",
    "    bottom = N1+N2+N3\n",
    "    \n",
    "    # Calculate the CDF values for x range: x1<=x<x2\n",
    "    mask1 = (x>=x1) & (x<x2)\n",
    "    top1 = ( (1./(a1+1) ) * C1 * (x[mask1]**(a1+1) ) - (1./(a1+1) ) * C1 * (x1**(a1+1) ) ) \n",
    "    yvalues[mask1] = top1/bottom\n",
    "    \n",
    "    # Calculate the CDF values for x range: x2<=x<x3\n",
    "    mask2 = (x>=x2) & (x<x3)\n",
    "    top2 =  N1 + ( (1./(a2+1) ) * C2 * (x[mask2]**(a2+1) ) - (1./(a2+1)) * C2 * (x2**(a2+1) ) ) \n",
    "    yvalues[mask2] = top2/bottom\n",
    "    \n",
    "    # Calculate the CDF values for x range: x3<=x<=x4\n",
    "    mask3 = (x>=x3) & (x<=x4)\n",
    "    top3 =  N1 + N2 + ( (1./(a3+1)) * C3 * (x[mask3]**(a3+1)) - (1./(a3+1)) * C3 * (x3**(a3+1) ) )\n",
    "    yvalues[mask3] = top3/bottom\n",
    "    \n",
    "    return yvalues\n",
    "\n",
    "\n",
    "def invertCDFbrokenPowerLaw(CDF, x1, x2, x3, x4, a1, a2, a3, C1):\n",
    "    \"\"\"\n",
    "    Invert y-values of a CDF back to x-vals (i.e. the masses)\n",
    "    Specifically for a three-part piece-wise powerlaw representing a Kroupa IMF by default. \n",
    "\n",
    "    Parameters:\n",
    "    CDF: array-like, the CDF values to invert\n",
    "    x1, x2, x3, x4: float, the break points (ranges) for the three segments\n",
    "    a1, a2, a3: float, the power law indices for the three segments\n",
    "    C1: float, the normalization constant for the first segment\n",
    "\n",
    "    Returns:\n",
    "    xvalues: array-like, the inverted CDF values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the normalization constants for the second and third segments\n",
    "    C2 = float(C1 * (x2**(a1-a2)))\n",
    "    C3 = float(C2 * (x3**(a2-a3)))\n",
    "    \n",
    "    # Calculate the area under the curve for each segment\n",
    "    N1 = float(((1./(a1+1)) * C1 * (x2**(a1+1))) - ((1./(a1+1)) * C1 * (x1**(a1+1))))\n",
    "    N2 = float(((1./(a2+1)) * C2 * (x3**(a2+1))) - ((1./(a2+1)) * C2 * (x2**(a2+1))))\n",
    "    N3 = float(((1./(a3+1)) * C3 * (x4**(a3+1))) - ((1./(a3+1)) * C3 * (x3**(a3+1))))\n",
    "    \n",
    "    # Calculate the CDF values at the breakpoints\n",
    "    CDFx2 = CDFbrokenPowerLaw(np.array([x2,x2]), x1, x2, x3, x4, a1, a2, a3, C1)[0]\n",
    "    CDFx3 = CDFbrokenPowerLaw(np.array([x3,x3]), x1, x2, x3, x4, a1, a2, a3, C1)[0]\n",
    "\n",
    "    # Initialize the output array\n",
    "    xvalues = np.zeros(len(CDF))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the first segment\n",
    "    mask1 = (CDF < CDFx2)\n",
    "    xvalues[mask1] =  (((CDF[mask1]*(N1+N2+N3))  + \\\n",
    "                      ( (1./(a1+1))*C1*(x1**(a1+1))))/((1./(a1+1))*C1))**(1./(a1+1))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the second segment\n",
    "    mask2 = (CDFx2<= CDF) & (CDF < CDFx3)\n",
    "    xvalues[mask2] = ((((CDF[mask2]*(N1+N2+N3))-(N1))  + \\\n",
    "                      ( (1./(a2+1))*C2*(x2**(a2+1))))/((1./(a2+1))*C2))**(1./(a2+1))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the third segment\n",
    "    mask3 = (CDFx3<= CDF) \n",
    "    xvalues[mask3] = ((((CDF[mask3]*(N1+N2+N3))-(N1+N2))  + \\\n",
    "                      ((1./(a3+1))*C3*(x3**(a3+1))))/((1./(a3+1))*C3))**(1./(a3+1))\n",
    "    \n",
    "    # Return the inverse CDF values\n",
    "    return xvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'totalMassEvolvedPerZ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m sim_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNewWinds_RemFryer2012\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m Sampe_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2e6\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m w_NbinariesEvolvedPerZ, w_AverageMassPerBinaryCOMPAS, w_MassEvolvedPerZ, totalMassEvolvedCOMPAS, totalMassInStarFormation,  MassEvolvedPerZ \u001b[38;5;241m=\u001b[39m totalMassEvolvedPerZ(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatar_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msim_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/COMPAS_Output_combinedZ.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, sampleSize\u001b[38;5;241m=\u001b[39mSampe_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'totalMassEvolvedPerZ' is not defined"
     ]
    }
   ],
   "source": [
    "sim_name = 'NewWinds_RemFryer2012'\n",
    "\n",
    "Sampe_size = int(2e6)\n",
    "\n",
    "w_NbinariesEvolvedPerZ, w_AverageMassPerBinaryCOMPAS, w_MassEvolvedPerZ, totalMassEvolvedCOMPAS, totalMassInStarFormation,  MassEvolvedPerZ = totalMassEvolvedPerZ(f'{datar_root}/{sim_name}/COMPAS_Output_combinedZ.h5', sampleSize=Sampe_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mass per system in Universe 0.9\n"
     ]
    }
   ],
   "source": [
    "average_mass_per_system_univ = 0.9 #totalMassInStarFormation/Sampe_size\n",
    "print(f'Average mass per system in Universe {average_mass_per_system_univ}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "*** \n",
    "## max $\\eta_{BBH}$\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_BBH = 0.00011321263153664183\n"
     ]
    }
   ],
   "source": [
    "eta_BBH = 1./average_mass_per_system_univ * (f_primaryf_secondary_bhbh * f_init_sep * f_sn1_bbh * f_sn2_bbh )\n",
    "print(f'eta_BBH = {eta_BBH}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## max $\\eta_{NSNS}$\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_nsns = 2.7269915409623303e-06\n"
     ]
    }
   ],
   "source": [
    "eta_NSNS = 1./average_mass_per_system_univ * (f_primaryf_secondary_nsns * f_init_sep * f_sn1_nsns * f_sn2_nsns )\n",
    "print(f'eta_nsns = {eta_NSNS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## max $\\eta_{BHNS}$\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "$f_{init sep} = 0.42$ stays the same\n",
    "$f_{SN1} = 1$\n",
    "$f_{SN2} = 0.14$\n",
    "$f_{primary} = 7.6 \\cdot 10^{-4}$ (same as for BBH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_BHNS = 1.9478511006873788e-05\n"
     ]
    }
   ],
   "source": [
    "f_prim_bhns = (300**-1.35 - 20**-1.35)/(300**-1.35 - 0.1**-1.35)\n",
    "f_sn1_bhns = 1\n",
    "f_sn2_bhns = 0.14\n",
    "\n",
    "eta_BHNS = 1./average_mass_per_system_univ * (f_primaryf_secondary_nsns * f_init_sep * f_sn1_bhns * f_sn2_bhns )\n",
    "print(f'eta_BHNS = {eta_BHNS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
