{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# created 05-03-2024\n",
    "#\n",
    "# Python script meant to run COMPAS using DisBatch\n",
    "# I run 10^6 systems at a bunch of discrete metallicities (each divided into batches)\n",
    "# The end of this script combines the output using h5copy\n",
    "# \n",
    "##############################################\n",
    "import numpy as np\n",
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "import h5py as h5\n",
    "\n",
    "from definitions import sim_flags_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "## \n",
    "##    Should be Changed by user ##\n",
    "##\n",
    "#################################################################\n",
    "sim_name             = \"OldWinds_RemFryer2012_noBHkick\"#\"OldWinds_RemFryer2012\" # Note: the sim_name will determine which flags to run COMPAS with\n",
    "root_out_dir         = f\"/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/{sim_name}\"\n",
    "file_name            = 'COMPAS_Output_wWeights.h5'\n",
    "user_email           = \"aac.van.son@gmail.com\"\n",
    "gid_filename         = \"BSE_grid_mass_sep_kick.txt\"\n",
    "\n",
    "### Different options for the metalicites:\n",
    "# 0.0001, 0.0003, 0.001, 0.004, 0.01, 0.02, 0.03 # Hurley Z's\n",
    "# [0.0001, 0.00017321, 0.0003, 0.00054772, 0.001, 0.002, 0.004, 0.00632456, 0.01, 0.01414214, 0.02, 0.03] # Hurley with extra steps\n",
    "# np.logspace(-4, np.log10(0.03), 17)  # flat in log\n",
    "metallicities = [0.0001, 0.00017321, 0.0003, 0.00054772, 0.001, 0.002, 0.004, 0.00632456, 0.01, 0.01414214, 0.02, 0.03] # Hurley with extra steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What COMPAS flags to run with? \n",
    "\n",
    "Based on your sim_name, we will now construct a combination of COMPAS flags that set the 'physics' we would like to run with.\n",
    "\n",
    "\n",
    "#### Main flags for the run\n",
    "\n",
    "There are also a bunch of flags that are the same for every run:\n",
    "\n",
    "--add-options-to-sysparms: 'NEVER' <br>\n",
    "--grid: f'{root_out_dir}/{gid_filename}' <br>\n",
    "--logfile-definitions: f'{root_out_dir}/COMPAS_Output_Definitions.txt' <br>\n",
    "--grid-start-line: f\"{Njob*batch_size}\" <br>\n",
    "--grid-lines-to-process: f\"{batch_size}\" <br>\n",
    "--output-path:  f\"{run_dir}\" <br>\n",
    "--metallicity z\n",
    "\n",
    "\n",
    "### 'old' winds (i.e. fiducial in v02.35.02) \n",
    "Should be retrieved with '--mass-loss-prescription BELCZYNSKI2010 ` but explicitely:  <br>\n",
    "\n",
    "--OB-mass-loss VINK2001 <br> \n",
    "--VMS-mass-loss NONE <br> \n",
    "--VERY_MASSIVE_MINIMUM_MASS 200 (i.e., not applied since Mmax =150)  <br> \n",
    "--RSG-mass-loss NJ90 <br> \n",
    "--WR-mass-loss BELCZYNSKI2010 <br>\n",
    "\n",
    "\n",
    "### 'new' winds (fiducial in v02_46_01) \n",
    "` --wolf-rayet-multiplier 1 --mass-loss-prescription BELCZYNSKI2010\n",
    "Note Compas used `--wolf-rayet-multiplier 0.1` as a default, but I never adopted that\n",
    "\n",
    "--OB-mass-loss VINK2021 <br> \n",
    "--VMS-mass-loss SABHAHIT2023 <br> \n",
    "--VERY_MASSIVE_MINIMUM_MASS 100 (i.e., not applied since Mmax =150)  <br> \n",
    "--RSG-mass-loss DECIN2023  <br> \n",
    "--WR-mass-loss SANDERVINK2023 <br> \n",
    "\n",
    "\n",
    "### Remnant mass & kick variations\n",
    "\n",
    "Old fiducial is Fryer, with reduced fallback\n",
    "`--remnant-mass-prescription FRYER2012` , with  `--kick-magnitude-distribution MAXWELLIAN`  <br> \n",
    "\n",
    "`--remnant-mass-prescription MULLERMANDEL` with `--kick-magnitude-distribution MULLERMANDEL`  <br>\n",
    "  \n",
    "\n",
    "\n",
    "### variations\n",
    "\n",
    "NO MS winds `--OB-mass-loss NONE` & no VMS winds `--VMS-mass-loss NONE` <br> \n",
    "NO WR winds `--wolf-rayet-multiplier 0`  (previously noWRWindN1e6 = 0, StrongWRWindN1e6 = 5.0) <br> \n",
    "NO winds at all `--overall-wind-mass-loss-multiplier 0` # ZEROWindsN1e6 <br>\n",
    "NO BH kicks `--remnant-mass-prescription FRYER2012`  with `--black-hole-kicks ZERO`  <br>\n",
    "NO kicks at all `--remnant-mass-prescription FRYER2012`  with `--kick-magnitude-distribution ZERO` <br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<b> other older Wind Variations:</b>\n",
    "\n",
    "--cool-wind-mass-loss-multiplier # noCoolWindN1e6 = 0, StrongCoolWindN1e6 = 10.0 <br>\n",
    "--black-hole-kicks (kills all kicks) options: [FULL, REDUCED, ZERO, FALLBACK], default = FALLBACK  # noBHkickN1e6 <br>\n",
    "--luminous-blue-variable-prescription # noLBVN1e6 (options: [NONE, HURLEY_ADD, HURLEY, BELCZYNSKI], default = HURLEY_ADD) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--mass-loss-prescription BELCZYNSKI2010 --OB-mass-loss VINK2001 --VMS-mass-loss VINK2011 --RSG-mass-loss NJ90 --WR-mass-loss BELCZYNSKI2010  --remnant-mass-prescription FRYER2012 --kick-magnitude-distribution MAXWELLIAN  --black-hole-kicks ZERO \n"
     ]
    }
   ],
   "source": [
    "# Check if sim_name exists in the dictionary\n",
    "if sim_name in sim_flags_dict:\n",
    "    sim_variation_flags = sim_flags_dict[sim_name]\n",
    "    print(sim_variation_flags)\n",
    "else:\n",
    "    print(f\"Unknown sim_name: {sim_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make root out dir and Copy your BSE_grid \n",
    "I am interested in rerunning the exact same ~1e6 binaries at different metallicities\n",
    "\n",
    "I am using masterfolder/BSE_grid_mass_sep_kick.txt, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_out_dir =   /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noNSBHkick\n",
      "num_lines 1000000\n",
      "n_jobs 40 of batch_size 25000\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Make the output directory if it doesn't exist\n",
    "if not os.path.isdir(root_out_dir):\n",
    "    print('root_out_dir =  ', root_out_dir)\n",
    "    os.makedirs(root_out_dir, exist_ok=True)\n",
    "\n",
    "    # copy this python script to the ROOT out dir (for reference)\n",
    "    shutil.copyfile('Grid_Call.ipynb', f'{root_out_dir}/Grid_Call.ipynb')  \n",
    "    shutil.copyfile(f'{gid_filename}', f'{root_out_dir}/{gid_filename}')  \n",
    "    shutil.copyfile('COMPAS_Output_Definitions.txt', f'{root_out_dir}/COMPAS_Output_Definitions.txt')  \n",
    "else:\n",
    "    print(f'Nothing to do, {root_out_dir} already exists')\n",
    "\n",
    "###############################################\n",
    "def divide_with_remainder(numerator, denominator):\n",
    "    batch_size = numerator // denominator\n",
    "    n_jobs     = numerator/batch_size\n",
    "    remainder  = numerator % denominator\n",
    "    return batch_size, int(n_jobs), remainder\n",
    "\n",
    "# details for your run\n",
    "with open(f'{root_out_dir}/{gid_filename}', 'r') as f:\n",
    "    # Read the file into a list of lines\n",
    "    lines = f.readlines()\n",
    "num_lines = len(lines)\n",
    "print('num_lines',num_lines)\n",
    "\n",
    "N_binaries           = num_lines #int(1e3)  # how many binaries to run in total\n",
    "N_chunks             = 40         # how many batches to run this in (N_binaries/N_chunks is not an int, you will run the remainder in an extra last batch)\n",
    "\n",
    "# Determine how many batches to run\n",
    "batch_size, n_jobs, remainder = divide_with_remainder(N_binaries, N_chunks)\n",
    "last_batch_size, extra_job    =  batch_size, 0\n",
    "if remainder != 0.:\n",
    "    extra_job = 1\n",
    "    print(r'N_binaries = %s can not be divided properly into N_chunks=%s'%(N_binaries, N_chunks))\n",
    "    print('You will run 1 extra job with %s binaries'%(remainder))\n",
    "\n",
    "print('n_jobs',n_jobs, 'of batch_size', batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make a list of tasks to submit to [disBatch](https://github.com/flatironinstitute/disBatch)\n",
    "\n",
    "Now we are going to construct tasks. A task looks somthing like ( cd /path/to/workdir ; source SetupEnv ; myprog -a 0 -b 0 -c 0 ) &> task_0_0_0.log\n",
    "\n",
    "For my COMPAS batches, this consists of the follwing steps:\n",
    "* cd {rundir}\n",
    "* module load python gsl boost hdf5\n",
    "* $COMPAS_ROOT_DIR/src/COMPAS -flags  > COMPAS_batch_i.log\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metallicity 0.0001\n",
      "metallicity 0.00017321\n",
      "metallicity 0.0003\n",
      "metallicity 0.00054772\n",
      "metallicity 0.001\n",
      "metallicity 0.002\n",
      "metallicity 0.004\n",
      "metallicity 0.00632456\n",
      "metallicity 0.01\n",
      "metallicity 0.01414214\n",
      "metallicity 0.02\n",
      "metallicity 0.03\n"
     ]
    }
   ],
   "source": [
    "# open a file to write the tasks to \n",
    "with open(f'{root_out_dir}/Tasks', 'w') as f:\n",
    "\n",
    "    # Hurley metallicities + extra steps\n",
    "    for metallicity in metallicities: #\n",
    "        print('metallicity', metallicity)\n",
    "\n",
    "        # Make a dir for this metallicity\n",
    "        base_run_dir = root_out_dir+f'/logZ{np.round(np.log10(metallicity),2)}/'\n",
    "        os.makedirs(base_run_dir, exist_ok=True)\n",
    "\n",
    "        # Loop over every batch \n",
    "        for Njob in range(n_jobs + extra_job):\n",
    "            # directory where you will copy the files to and run compas from\n",
    "            run_dir = base_run_dir+'/batch'+'_%s'%(Njob) +'/'\n",
    "            os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "            ############################################\n",
    "            # Compile the flags you want for this task\n",
    "            # if you are on the last job and the remainder is nonzero, run the remainder\n",
    "            if np.logical_and(remainder !=0, Njob == n_jobs):\n",
    "                print('you are on the extra job, use remainder as batch_size ')\n",
    "                COMPAS_batch_flags = f\"--metallicity {metallicity} {sim_variation_flags} --allow-touching-at-birth True --add-options-to-sysparms 'NEVER' --grid '{root_out_dir}/{gid_filename}' --logfile-definitions '{root_out_dir}/COMPAS_Output_Definitions.txt' --grid-start-line '{Njob*batch_size}' --grid-lines-to-process '{remainder}' --output-path '{run_dir}' \"\n",
    "            else:\n",
    "                COMPAS_batch_flags = f\"--metallicity {metallicity} {sim_variation_flags} --allow-touching-at-birth True --add-options-to-sysparms 'NEVER' --grid '{root_out_dir}/{gid_filename}' --logfile-definitions '{root_out_dir}/COMPAS_Output_Definitions.txt' --grid-start-line '{Njob*batch_size}' --grid-lines-to-process '{batch_size}' --output-path '{run_dir}' \"\n",
    "\n",
    "            # print(COMPAS_batch_flags)\n",
    "            # NOTE!!  --allow-touching-at-birth = True, otherwise as I increase Z, some systems will fail!\n",
    "\n",
    "            task_line = f\"cd {run_dir} ; module load python gsl boost hdf5 ; $COMPAS_ROOT_DIR/src/COMPAS {COMPAS_batch_flags}  > COMPAS_batch_{Njob}.log 2>&1 \" \n",
    "            f.write(task_line + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Execute the Tasks with DisBatch\n",
    "\n",
    "make sure to `module load disBatch` \n",
    "\n",
    "Go to your root_out_dir and just run: \n",
    "sbatch -n 50 disBatch Tasks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3519875']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Initialize an empty list to store the job IDs\n",
    "disBatch_job_ids = []\n",
    "\n",
    "# disBatch Command\n",
    "command = f\"module load disBatch && sbatch -p cca -n 100 disBatch {root_out_dir}/Tasks\"\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Extract the job ID from the output\n",
    "match = re.search(r\"Submitted batch job (\\d+)\", result.stdout)\n",
    "if match:\n",
    "    job_id = match.group(1)\n",
    "    disBatch_job_ids.append(job_id)\n",
    "\n",
    "print(disBatch_job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Combine the hdf5 files in post processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-4.0/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-3.76/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-3.52/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-3.26/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-3.0/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-2.7/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-2.4/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-2.2/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-2.0/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-1.85/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-1.7/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/logZ-1.52/\n",
      "['3520417']\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# post proces tasks \n",
    "###############################################\n",
    "print(10* \"*\" + ' You are Going to Run PostProcessing.py')\n",
    "\n",
    "with open(f'{root_out_dir}/PP_Tasks', 'w') as f:\n",
    "\n",
    "    for metallicity in metallicities: \n",
    "        base_run_dir = root_out_dir+f'/logZ{np.round(np.log10(metallicity),2)}/'\n",
    "\n",
    "        print(base_run_dir)\n",
    "\n",
    "        # copy the h5copy to the root out dir\n",
    "        shutil.copyfile('h5copy.py', f'{base_run_dir}/h5copy.py')  \n",
    "\n",
    "        # task line\n",
    "        task_line = f\"cd {base_run_dir} ; module load python ; python h5copy.py {base_run_dir} -r 2 -o COMPAS_Output.h5  > COMPAS_PP.log 2>&1 \" \n",
    "        f.write(task_line + '\\n')\n",
    "\n",
    "\n",
    "############################################\n",
    "# Submit the job! \n",
    "PP_job_ids = []\n",
    "\n",
    "# disBatch Command\n",
    "command = f\"module load disBatch && sbatch --dependency=afterok:{disBatch_job_ids} -p cca -n 20 disBatch {root_out_dir}/PP_Tasks\"\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Extract the job ID from the output\n",
    "match = re.search(r\"Submitted batch job (\\d+)\", result.stdout)\n",
    "if match:\n",
    "    job_id = match.group(1)\n",
    "    PP_job_ids.append(job_id)\n",
    "\n",
    "print(PP_job_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on the outcome of your individual simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z =  [0.0001]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.00017321]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.0003]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.00054772]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.001]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.002]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.004]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.00632456]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.01]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.01414214]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.02]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n",
      "Z =  [0.03]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (1000000,), type \"<u8\">\n"
     ]
    }
   ],
   "source": [
    "## First check the individual metallicity runs\n",
    "root_data_dir = f'/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/{sim_name}/'\n",
    "\n",
    "for metallicity in metallicities: \n",
    "    data = h5.File(f'{root_data_dir}/logZ{np.round(np.log10(metallicity),2)}/COMPAS_Output.h5','r')\n",
    "\n",
    "    print('Z = ', np.unique(data['BSE_System_Parameters']['Metallicity@ZAMS(1)'][()]) )\n",
    "\n",
    "    print(data.keys())\n",
    "    # data['BSE_System_Parameters'].keys()\n",
    "    print(data['BSE_System_Parameters']['SEED'] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 combine individual Z sim into a big hdf5 file\n",
    "\n",
    "### Finally combine each individual metallicity simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the h5copy to the root out dir\n",
    "shutil.copyfile('h5copy.py', f'{root_out_dir}/h5copy.py')  \n",
    "\n",
    "with open(f'{root_out_dir}/combineZ_Tasks', 'w') as f:\n",
    "\n",
    "    # task line\n",
    "    task_line = f\"cd {root_out_dir} ; module load python ; python h5copy.py {root_out_dir} -r 1 -o COMPAS_Output_combinedZ.h5  > COMPAS_PP.log 2>&1 \" \n",
    "    f.write(task_line + '\\n')\n",
    "\n",
    "# disBatch Command\n",
    "command = f\"module load disBatch && sbatch -p cca -n 20 disBatch {root_out_dir}/combineZ_Tasks\" #--dependency=afterok:{PP_job_ids}\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/CombineMetallicities.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=CombineMetallicities               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/CombineMetallicities.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/CombineMetallicities.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p cca\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick -r 1 -o COMPAS_Output_combinedZ.h5 > CombineMetallicities.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemFryer2012_noBHkick/CombineMetallicities.sbatch\n",
      "out =  b'Submitted batch job 3520445\\n'\n",
      "job_id b'3520445'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Make and safe a slurm command to combine all metallicities\n",
    "h5Flags = f' {root_out_dir} -r 1 -o COMPAS_Output_combinedZ.h5'\n",
    "\n",
    "PP_job_string = MakeSlurmBatch(run_dir = root_out_dir, job_line = \"python h5copy.py \",\\\n",
    "job_name = \"CombineMetallicities\", number_of_cores = 1, partition='cca',\\\n",
    "walltime = \"0-1:00:00\" ,memory = \"1G\", email = user_email, flags= h5Flags)\n",
    "\n",
    "print(PP_job_string)\n",
    "\n",
    "# copy the h5copy to the root out dir\n",
    "shutil.copyfile('h5copy.py', f'{root_out_dir}/h5copy.py')  \n",
    "\n",
    "\n",
    "############################################\n",
    "# Submit the job to sbatch! \n",
    "PPjob_id = RunSlurmBatch(run_dir = root_out_dir, job_name = \"/CombineMetallicities\")#, dependency = True, dependent_ID = PP_job_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# This is the slurm script youre using\n",
    "##################################################################\n",
    "def MakeSlurmBatch(run_dir = None, job_line = \"python runSubmit.py\", job_name = \"runCOMPAS\",\n",
    "                   number_of_cores = 1, partition='cca,gen', flags=\" \", walltime = '01:00:00' ,memory = '1000', email = None):\n",
    "\n",
    "    outfile = f\"{run_dir}/{job_name}.out\"\n",
    "    errfile = f\"{run_dir}/{job_name}.err\"\n",
    "\n",
    "    job = job_line + flags + \" > \"+job_name+\".log\"\n",
    "\n",
    "    # Make slurm script string\n",
    "    SlurmJobString=f\"\"\"#!/bin/bash\n",
    "#SBATCH --job-name={job_name}               #job name\n",
    "#SBATCH --ntasks={number_of_cores}                 # Number of cores\n",
    "#SBATCH --output={outfile}                 # output storage file\n",
    "#SBATCH --error={errfile}                  # error storage file\n",
    "#SBATCH --time={walltime}                   # Runtime in minutes\n",
    "#SBATCH --mem={memory}                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
    "#SBATCH -p {partition}\n",
    "#SBATCH --mail-user={user_email}              # Send email to user\n",
    "#SBATCH --mail-type=FAIL            #\n",
    "#\n",
    "#Load modules\n",
    "module load python gsl boost hdf5\n",
    "# \n",
    "#CD to output directory\n",
    "cd {run_dir}\n",
    "#\n",
    "# Run your job\n",
    "{job}\n",
    "\"\"\"\n",
    "\n",
    "    sbatchFile = open(f'{run_dir}/{job_name}.sbatch','w')\n",
    "    print('writing ',  f'{run_dir}/{job_name}.sbatch')\n",
    "    sbatchFile.write(SlurmJobString)\n",
    "    sbatchFile.close()\n",
    "\n",
    "    return SlurmJobString\n",
    "\n",
    "\n",
    "###############################################\n",
    "###\n",
    "###############################################\n",
    "def RunSlurmBatch(run_dir = None, job_name = \"runCOMPAS\", dependency = False, dependent_IDs = None):\n",
    "\n",
    "    if not dependency:\n",
    "        sbatchArrayCommand = 'sbatch ' + os.path.join(run_dir+job_name+'.sbatch') \n",
    "    else:\n",
    "        # Join the dependent IDs with colons\n",
    "        dependent_IDs_str = \":\".join(map(str, dependent_IDs))\n",
    "        sbatchArrayCommand = 'sbatch --dependency=afterok:' + dependent_IDs_str + ' ' + os.path.join(run_dir+job_name+'.sbatch') \n",
    "        # sbatchArrayCommand = 'sbatch --dependency=afterok:' + str(int(dependent_ID)) + ' ' + os.path.join(run_dir+job_name+'.sbatch') \n",
    "\n",
    "    # Open a pipe to the sbatch command.\n",
    "    proc = Popen(sbatchArrayCommand, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)\n",
    "\n",
    "    # Send job_string to sbatch\n",
    "    if (sys.version_info > (3, 0)):\n",
    "        proc.stdin.write(sbatchArrayCommand.encode('utf-8'))\n",
    "    else:\n",
    "        proc.stdin.write(sbatchArrayCommand)\n",
    "\n",
    "    print('sbatchArrayCommand:', sbatchArrayCommand)\n",
    "    out, err = proc.communicate()\n",
    "    print(\"out = \", out)\n",
    "    if out:\n",
    "        job_id = out.split()[-1]\n",
    "        print(\"job_id\", job_id)\n",
    "        return job_id\n",
    "    else:\n",
    "        print(\"Error: sbatch returned no output\")\n",
    "        print(\"err = \", err)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-4.0/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-4.0//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-4.0//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-4.0//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-4.0/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-4.0/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-4.0/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520289\\n'\n",
      "job_id b'3520289'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.76/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.76//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.76//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.76//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.76/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.76/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.76/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520290\\n'\n",
      "job_id b'3520290'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.52/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.52//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.52//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.52//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.52/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.52/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.52/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520291\\n'\n",
      "job_id b'3520291'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.26/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.26//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.26//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.26//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.26/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.26/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.26/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520292\\n'\n",
      "job_id b'3520292'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.0/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.0//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.0//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.0//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.0/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.0/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-3.0/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520293\\n'\n",
      "job_id b'3520293'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.7/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.7//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.7//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.7//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.7/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.7/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.7/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520294\\n'\n",
      "job_id b'3520294'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.4/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.4//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.4//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.4//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.4/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.4/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.4/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520295\\n'\n",
      "job_id b'3520295'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.2/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.2//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.2//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.2//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.2/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.2/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.2/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520296\\n'\n",
      "job_id b'3520296'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.0/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.0//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.0//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.0//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.0/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.0/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-2.0/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520297\\n'\n",
      "job_id b'3520297'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.85/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.85//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.85//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.85//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.85/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.85/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.85/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520298\\n'\n",
      "job_id b'3520298'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.7/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.7//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.7//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.7//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.7/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.7/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.7/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520299\\n'\n",
      "job_id b'3520299'\n",
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.52/\n",
      "writing  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.52//COMPAS_PP.sbatch\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=COMPAS_PP               #job name\n",
      "#SBATCH --ntasks=1                 # Number of cores\n",
      "#SBATCH --output=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.52//COMPAS_PP.out                 # output storage file\n",
      "#SBATCH --error=/mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.52//COMPAS_PP.err                  # error storage file\n",
      "#SBATCH --time=0-1:00:00                   # Runtime in minutes\n",
      "#SBATCH --mem=1G                    # Memory per cpu in MB (see also --mem-per-cpu)\n",
      "#SBATCH -p gen\n",
      "#SBATCH --mail-user=aac.van.son@gmail.com              # Send email to user\n",
      "#SBATCH --mail-type=FAIL            #\n",
      "#\n",
      "#Load modules\n",
      "module load python gsl boost hdf5\n",
      "# \n",
      "#CD to output directory\n",
      "cd /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.52/\n",
      "#\n",
      "# Run your job\n",
      "python h5copy.py  /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.52/ -r 2 -o COMPAS_Output.h5 > COMPAS_PP.log\n",
      "\n",
      "sbatchArrayCommand: sbatch /mnt/home/lvanson/ceph/CompasOutput/v02.46.01/OldWinds_RemMullerMandel/logZ-1.52/COMPAS_PP.sbatch\n",
      "out =  b'Submitted batch job 3520300\\n'\n",
      "job_id b'3520300'\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Make Post Processing batch and submit it\n",
    "###############################################\n",
    "\n",
    "PP_job_ids = []\n",
    "for metallicity in metallicities: \n",
    "    base_run_dir = root_out_dir+f'/logZ{np.round(np.log10(metallicity),2)}/'\n",
    "\n",
    "    print(10* \"*\" + ' You are Going to Run PostProcessing.py')\n",
    "    print(base_run_dir)\n",
    "\n",
    "    ###############################################\n",
    "    # Make and safe a slurm command\n",
    "    h5Flags = f' {base_run_dir} -r 2 -o COMPAS_Output.h5'\n",
    "\n",
    "    # copy the h5copy to the root out dir\n",
    "    shutil.copyfile('h5copy.py', f'{base_run_dir}/h5copy.py')  \n",
    "\n",
    "    PP_job_string = MakeSlurmBatch(run_dir = base_run_dir, job_line = \"python h5copy.py \",\\\n",
    "    job_name = \"COMPAS_PP\", number_of_cores = 1, partition='gen',\\\n",
    "    walltime = \"0-1:00:00\" ,memory = \"1G\", email = user_email, flags= h5Flags)\n",
    "\n",
    "    print(PP_job_string)\n",
    "\n",
    "    ############################################\n",
    "    # Submit the job to sbatch! \n",
    "    PPjob_id = RunSlurmBatch(run_dir = base_run_dir, job_name = \"COMPAS_PP\", dependency = False, dependent_IDs = disBatch_job_ids)\n",
    "    PP_job_ids.append(PPjob_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
