{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# created 05-03-2024\n",
    "#\n",
    "# Python script meant to run COMPAS using DisBatch\n",
    "# I run 5 x 10^6 systems at a bunch of discrete metallicities (each divided into batches)\n",
    "# The end of this script combines the output using h5copy\n",
    "# \n",
    "##############################################\n",
    "import numpy as np\n",
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "import h5py as h5\n",
    "import re\n",
    "\n",
    "from definitions import sim_flags_dict\n",
    "\n",
    "import importlib\n",
    "# Reload the definitions module\n",
    "importlib.reload(sys.modules['definitions'])\n",
    "from definitions import sim_flags_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "## \n",
    "##    Should be Changed by user ##\n",
    "##\n",
    "#################################################################\n",
    "sim_name             = \"NewWinds_RemFryer2012_strongWRwinds\"#  # Note: the sim_name will determine which flags to run COMPAS with\n",
    "compas_v             = \"v03.01.02\" #\"v02.46.01/\"#v02.35.02/\"\n",
    "\n",
    "root_out_dir         = f\"/mnt/home/lvanson/ceph/CompasOutput/{compas_v}/{sim_name}\"\n",
    "file_name            = 'COMPAS_Output_wWeights.h5'\n",
    "user_email           = \"aac.van.son@gmail.com\"\n",
    "gid_filename         = \"BSE_grid_N5e6_mass_sep_kick.txt\"\n",
    "\n",
    "### Different options for the metalicites:\n",
    "# 0.0001, 0.0003, 0.001, 0.004, 0.01, 0.02, 0.03 # Hurley Z's\n",
    "# [0.0001, 0.00017321, 0.0003, 0.00054772, 0.001, 0.002, 0.004, 0.00632456, 0.01, 0.01414214, 0.02, 0.03] # Hurley with extra steps\n",
    "# np.logspace(-4, np.log10(0.03), 17)  # flat in log\n",
    "metallicities = [0.0001, 0.00017321, 0.0003, 0.00054772, 0.001, 0.002, 0.004, 0.00632456, 0.01, 0.01414214, 0.02, 0.03] # Hurley with extra steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What COMPAS flags to run with? \n",
    "\n",
    "Based on your sim_name, we will now construct a combination of COMPAS flags that set the 'physics' we would like to run with.\n",
    "\n",
    "\n",
    "#### Main flags for the run\n",
    "\n",
    "There are also a bunch of flags that are the same for every run:\n",
    "\n",
    "--add-options-to-sysparms: 'NEVER' <br>\n",
    "--grid: f'{root_out_dir}/{gid_filename}' <br>\n",
    "--logfile-definitions: f'{root_out_dir}/COMPAS_Output_Definitions.txt' <br>\n",
    "--grid-start-line: f\"{Njob*batch_size}\" <br>\n",
    "--grid-lines-to-process: f\"{batch_size}\" <br>\n",
    "--output-path:  f\"{run_dir}\" <br>\n",
    "--metallicity z\n",
    "\n",
    "\n",
    "### 'old' winds (i.e. fiducial in v02.35.02) \n",
    "Should be retrieved with '--mass-loss-prescription BELCZYNSKI2010 ` but explicitely:  <br>\n",
    "\n",
    "--OB-mass-loss VINK2001 <br> \n",
    "--VMS-mass-loss NONE <br> \n",
    "--VERY_MASSIVE_MINIMUM_MASS 200 (i.e., not applied since Mmax =150)  <br> \n",
    "--RSG-mass-loss NJ90 <br> \n",
    "--WR-mass-loss BELCZYNSKI2010 <br>\n",
    "\n",
    "\n",
    "### 'new' winds (fiducial in v02_46_01) \n",
    "` --wolf-rayet-multiplier 1 --mass-loss-prescription BELCZYNSKI2010\n",
    "Note Compas used `--wolf-rayet-multiplier 0.1` as a default, but I never adopted that\n",
    "\n",
    "--OB-mass-loss VINK2021 <br> \n",
    "--VMS-mass-loss SABHAHIT2023 <br> \n",
    "--VERY_MASSIVE_MINIMUM_MASS 100 (i.e., not applied since Mmax =150)  <br> \n",
    "--RSG-mass-loss DECIN2023  <br> \n",
    "--WR-mass-loss SANDERVINK2023 <br> \n",
    "\n",
    "\n",
    "### Remnant mass & kick variations\n",
    "\n",
    "Old fiducial is Fryer, with reduced fallback\n",
    "`--remnant-mass-prescription FRYER2012` , with  `--kick-magnitude-distribution MAXWELLIAN`  <br> \n",
    "\n",
    "`--remnant-mass-prescription MULLERMANDEL` with `--kick-magnitude-distribution MULLERMANDEL`  <br>\n",
    "  \n",
    "\n",
    "\n",
    "### variations\n",
    "\n",
    "NO MS winds `--OB-mass-loss NONE` & no VMS winds `--VMS-mass-loss NONE` <br> \n",
    "NO WR winds `--wolf-rayet-multiplier 0`  (previously noWRWindN1e6 = 0, StrongWRWindN1e6 = 5.0) <br> \n",
    "NO winds at all `--overall-wind-mass-loss-multiplier 0` # ZEROWindsN1e6 <br>\n",
    "NO BH kicks `--remnant-mass-prescription FRYER2012`  with `--black-hole-kicks ZERO`  <br>\n",
    "NO kicks at all `--remnant-mass-prescription FRYER2012`  with `--kick-magnitude-distribution ZERO` <br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<b> other older Wind Variations:</b>\n",
    "\n",
    "--cool-wind-mass-loss-multiplier # noCoolWindN1e6 = 0, StrongCoolWindN1e6 = 10.0 <br>\n",
    "--black-hole-kicks (kills all kicks) options: [FULL, REDUCED, ZERO, FALLBACK], default = FALLBACK  # noBHkickN1e6 <br>\n",
    "--luminous-blue-variable-prescription # noLBVN1e6 (options: [NONE, HURLEY_ADD, HURLEY, BELCZYNSKI], default = HURLEY_ADD) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--OB-mass-loss-prescription VINK2021 --VMS-mass-loss-prescription SABHAHIT2023 --RSG-mass-loss-prescription DECIN2023  --WR-mass-loss-prescription SANDERVINK2023  --remnant-mass-prescription FRYER2012 --kick-magnitude-distribution MAXWELLIAN --wolf-rayet-multiplier 5 \n"
     ]
    }
   ],
   "source": [
    "# Check if sim_name exists in the dictionary\n",
    "if sim_name in sim_flags_dict:\n",
    "    sim_variation_flags = sim_flags_dict[sim_name]\n",
    "    print(sim_variation_flags)\n",
    "else:\n",
    "    print(f\"Unknown sim_name: {sim_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make root out dir and Copy your BSE_grid \n",
    "I am interested in rerunning the exact same ~1e6 binaries at different metallicities\n",
    "\n",
    "I am using masterfolder/BSE_grid_mass_sep_kick.txt, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_out_dir =   /mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds\n",
      "num_lines 5000000\n",
      "n_jobs 100 of batch_size 50000\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Make the output directory if it doesn't exist\n",
    "if not os.path.isdir(root_out_dir):\n",
    "    print('root_out_dir =  ', root_out_dir)\n",
    "    os.makedirs(root_out_dir, exist_ok=True)\n",
    "\n",
    "    # copy this python script to the ROOT out dir (for reference)\n",
    "    shutil.copyfile('Grid_Call.ipynb', f'{root_out_dir}/Grid_Call.ipynb')  \n",
    "    shutil.copyfile(f'{gid_filename}', f'{root_out_dir}/{gid_filename}')  \n",
    "    shutil.copyfile('COMPAS_Output_Definitions.txt', f'{root_out_dir}/COMPAS_Output_Definitions.txt')  \n",
    "else:\n",
    "    print(f'Nothing to do, {root_out_dir} already exists')\n",
    "\n",
    "###############################################\n",
    "def divide_with_remainder(numerator, denominator):\n",
    "    batch_size = numerator // denominator\n",
    "    n_jobs     = numerator/batch_size\n",
    "    remainder  = numerator % denominator\n",
    "    return batch_size, int(n_jobs), remainder\n",
    "\n",
    "# details for your run\n",
    "with open(f'{root_out_dir}/{gid_filename}', 'r') as f:\n",
    "    # Read the file into a list of lines\n",
    "    lines = f.readlines()\n",
    "num_lines = len(lines)\n",
    "print('num_lines',num_lines)\n",
    "\n",
    "N_binaries           = num_lines  # how many binaries to run in total\n",
    "N_chunks             = 100         # how many batches to run this in (N_binaries/N_chunks is not an int, you will run the remainder in an extra last batch)\n",
    "\n",
    "# Determine how many batches to run\n",
    "batch_size, n_jobs, remainder = divide_with_remainder(N_binaries, N_chunks)\n",
    "last_batch_size, extra_job    =  batch_size, 0\n",
    "if remainder != 0.:\n",
    "    extra_job = 1\n",
    "    print(r'N_binaries = %s can not be divided properly into N_chunks=%s'%(N_binaries, N_chunks))\n",
    "    print('You will run 1 extra job with %s binaries'%(remainder))\n",
    "\n",
    "print('n_jobs',n_jobs, 'of batch_size', batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make a list of tasks to submit to [disBatch](https://github.com/flatironinstitute/disBatch)\n",
    "\n",
    "Now we are going to construct tasks. A task looks somthing like ( cd /path/to/workdir ; source SetupEnv ; myprog -a 0 -b 0 -c 0 ) &> task_0_0_0.log\n",
    "\n",
    "For my COMPAS batches, this consists of the follwing steps:\n",
    "* cd {rundir}\n",
    "* module load python gsl boost hdf5\n",
    "* $COMPAS_ROOT_DIR/src/COMPAS -flags  > COMPAS_batch_i.log\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metallicity 0.0001\n",
      "metallicity 0.00017321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metallicity 0.0003\n",
      "metallicity 0.00054772\n",
      "metallicity 0.001\n",
      "metallicity 0.002\n",
      "metallicity 0.004\n",
      "metallicity 0.00632456\n",
      "metallicity 0.01\n",
      "metallicity 0.01414214\n",
      "metallicity 0.02\n",
      "metallicity 0.03\n"
     ]
    }
   ],
   "source": [
    "# open a file to write the tasks to \n",
    "with open(f'{root_out_dir}/Tasks', 'w') as f:\n",
    "\n",
    "    # Hurley metallicities + extra steps\n",
    "    for metallicity in metallicities: #\n",
    "        print('metallicity', metallicity)\n",
    "\n",
    "        # Make a dir for this metallicity\n",
    "        base_run_dir = root_out_dir+f'/logZ{np.round(np.log10(metallicity),2)}/'\n",
    "        os.makedirs(base_run_dir, exist_ok=True)\n",
    "\n",
    "        # Loop over every batch \n",
    "        for Njob in range(n_jobs + extra_job):\n",
    "            # directory where you will copy the files to and run compas from\n",
    "            run_dir = base_run_dir+'/batch'+'_%s'%(Njob) +'/'\n",
    "            os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "            ############################################\n",
    "            # Compile the flags you want for this task\n",
    "            # if you are on the last job and the remainder is nonzero, run the remainder\n",
    "            if np.logical_and(remainder !=0, Njob == n_jobs):\n",
    "                print('you are on the extra job, use remainder as batch_size ')\n",
    "                COMPAS_batch_flags = f\"--metallicity {metallicity} {sim_variation_flags} --allow-touching-at-birth True --add-options-to-sysparms 'NEVER' --grid '{root_out_dir}/{gid_filename}' --logfile-definitions '{root_out_dir}/COMPAS_Output_Definitions.txt' --grid-start-line '{Njob*batch_size}' --grid-lines-to-process '{remainder}' --output-path '{run_dir}' \"\n",
    "            else:\n",
    "                COMPAS_batch_flags = f\"--metallicity {metallicity} {sim_variation_flags} --allow-touching-at-birth True --add-options-to-sysparms 'NEVER' --grid '{root_out_dir}/{gid_filename}' --logfile-definitions '{root_out_dir}/COMPAS_Output_Definitions.txt' --grid-start-line '{Njob*batch_size}' --grid-lines-to-process '{batch_size}' --output-path '{run_dir}' \"\n",
    "\n",
    "            # print(COMPAS_batch_flags)\n",
    "            # NOTE!!  --allow-touching-at-birth = True, otherwise as I increase Z, some systems will fail!\n",
    "\n",
    "            task_line = f\"cd {run_dir} ; module load python gsl boost hdf5 ; $COMPAS_ROOT_DIR/src/COMPAS {COMPAS_batch_flags}  > COMPAS_batch_{Njob}.log 2>&1 \" \n",
    "            f.write(task_line + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Execute the Tasks with DisBatch\n",
    "\n",
    "make sure to `module load disBatch` \n",
    "\n",
    "Go to your root_out_dir and just run: \n",
    "sbatch -n 50 disBatch Tasks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3760368\n"
     ]
    }
   ],
   "source": [
    "# disBatch Command\n",
    "command = f\"module load disBatch && sbatch -p cca -n 300 disBatch {root_out_dir}/Tasks\"\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Extract the job ID from the output\n",
    "match = re.search(r\"Submitted batch job (\\d+)\", result.stdout)\n",
    "if match:\n",
    "    disBatch_job_ids = match.group(1)\n",
    "\n",
    "print(disBatch_job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Combine the hdf5 files in post processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** You are Going to Run PostProcessing.py\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-4.0/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-3.76/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-3.52/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-3.26/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-3.0/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-2.7/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-2.4/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-2.2/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-2.0/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-1.85/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-1.7/\n",
      "/mnt/home/lvanson/ceph/CompasOutput/v03.01.02/NewWinds_RemFryer2012_strongWRwinds/logZ-1.52/\n",
      "3760369\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# post proces tasks \n",
    "###############################################\n",
    "print(10* \"*\" + ' You are Going to Run PostProcessing.py')\n",
    "\n",
    "with open(f'{root_out_dir}/PP_Tasks', 'w') as f:\n",
    "\n",
    "    for metallicity in metallicities: \n",
    "        base_run_dir = root_out_dir+f'/logZ{np.round(np.log10(metallicity),2)}/'\n",
    "\n",
    "        print(base_run_dir)\n",
    "\n",
    "        # copy the h5copy to the root out dir\n",
    "        shutil.copyfile('h5copy.py', f'{base_run_dir}/h5copy.py')  \n",
    "\n",
    "        # task line\n",
    "        task_line = f\"cd {base_run_dir} ; module load python ; python h5copy.py {base_run_dir} -r 2 -o COMPAS_Output.h5  > COMPAS_PP.log 2>&1 \" \n",
    "        f.write(task_line + '\\n')\n",
    "\n",
    "\n",
    "############################################\n",
    "# Submit the job! \n",
    "# PP_job_ids = []\n",
    "\n",
    "# disBatch Command\n",
    "command = f\"module load disBatch && sbatch --dependency=afterok:{disBatch_job_ids}  -p gen -n 20 disBatch {root_out_dir}/PP_Tasks\" #\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Extract the job ID from the output\n",
    "match = re.search(r\"Submitted batch job (\\d+)\", result.stdout)\n",
    "if match:\n",
    "    PP_job_ids = match.group(1)\n",
    "\n",
    "print(PP_job_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 combine individual Z sim into a big hdf5 file\n",
    "\n",
    "### Finally combine each individual metallicity simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the h5copy to the root out dir\n",
    "shutil.copyfile('h5copy.py', f'{root_out_dir}/h5copy.py')  \n",
    "\n",
    "with open(f'{root_out_dir}/combineZ_Tasks', 'w') as f:\n",
    "\n",
    "    # task line\n",
    "    task_line = f\"cd {root_out_dir} ; module load python ; python h5copy.py {root_out_dir} -r 1 -o COMPAS_Output_combinedZ.h5  > COMPAS_PP.log 2>&1 \" \n",
    "    f.write(task_line + '\\n')\n",
    "\n",
    "# disBatch Command\n",
    "command = f\"module load disBatch && sbatch --dependency=afterok:{PP_job_ids} -p gen -n 2 disBatch {root_out_dir}/combineZ_Tasks\" #{PP_job_ids}\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on the outcome of your individual simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z =  [0.0003]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.001]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.00632456]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.01414214]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "Z =  [0.002]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.01]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.00017321]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.004]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "Z =  [0.00054772]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.0001]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.03]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n",
      "Z =  [0.02]\n",
      "<KeysViewHDF5 ['BSE_Common_Envelopes', 'BSE_Double_Compact_Objects', 'BSE_RLOF', 'BSE_Supernovae', 'BSE_System_Parameters', 'Run_Details']>\n",
      "<HDF5 dataset \"SEED\": shape (5000000,), type \"<u8\">\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "## check the individual metallicity runs\n",
    "def check_data(root_data_dir, metallicity):\n",
    "    #  metallicity in metallicities: \n",
    "    data = h5.File(f'{root_data_dir}/logZ{np.round(np.log10(metallicity),2)}/COMPAS_Output.h5','r')\n",
    "\n",
    "    print('Z = ', np.unique(data['BSE_System_Parameters']['Metallicity@ZAMS(1)'][()]) )\n",
    "\n",
    "    print(data.keys())\n",
    "    # data['BSE_System_Parameters'].keys()\n",
    "    print(data['BSE_System_Parameters']['SEED'] )\n",
    "\n",
    "\n",
    "sim_name = 'RemFryer2012_NOwinds'\n",
    "root_data_dir = f'/mnt/home/lvanson/ceph/CompasOutput/{compas_v}/{sim_name}/'\n",
    "\n",
    "# Create a pool of workers\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    # create a new function that has root_data_dir already filled in\n",
    "    func = partial(check_data, root_data_dir)\n",
    "    # Map func over the metallicities\n",
    "    pool.map(func, metallicities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
