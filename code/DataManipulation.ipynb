{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "\n",
    "Read the full COMPAS data, and extract only the information that you need (specifically only the systems that are every a DCO)\n",
    "\n",
    "Then we want to add relevant information about the system in the following cases:\n",
    "\n",
    " * The first mass transfer that the binary engaged in\n",
    " * The first mass transfer that star 2 engaged in\n",
    " * The mass transfer that lead to a stellar merger (if any)\n",
    " * The supernova information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import gc\n",
    "\n",
    "import multiprocessing\n",
    "import importlib\n",
    "import DataManipulation\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(DataManipulation)\n",
    "\n",
    "# Turn off natural name warning for panda tables (this is due to '@' and '>' in the COMPAS column names)\n",
    "import warnings\n",
    "from tables import NaturalNameWarning\n",
    "warnings.filterwarnings('ignore', category=NaturalNameWarning)\n",
    "\n",
    "\n",
    "######################################\n",
    "home_dir = os.path.expanduser(\"~\") \n",
    "compas_v = \"v03.01.02\" #\"v02.46.01/\"#v02.35.02/\"\n",
    "datar_root =  f\"{home_dir}/ceph/CompasOutput/{compas_v}/\"\n",
    "\n",
    "sim_name =  'NewWinds_RemFryer2012'#'OldWinds_RemFryer2012'#  \n",
    "\n",
    "# do you only want to select a certain formation channel? \n",
    "channel_key     = '' #'_stable' # '_CE' '_CHE'  '' \n",
    "\n",
    "######################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Data Manipulation using the overall python script\n",
    "this script follows the same steps as below, but it is easier to multiprocess the total python script\n",
    "\n",
    "-- it takes about 10 min to run the full 'DataManipulation' script that extracts all the potential DCO information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential_DCO_progenitors_CHE.h5\n",
      "first DCO table already exists, loading it\n",
      "RLOF DCO table already exists, loading it\n",
      "Table already exists, loading it\n",
      "Finished with NewWinds_RemMullerMandel_oldRSG,  _CHE \n"
     ]
    }
   ],
   "source": [
    "from DataManipulation import main\n",
    "\n",
    "# Define your sim_name and channel_key options to vary over\n",
    "sim_names = ['NewWinds_RemMullerMandel_oldRSG'] \n",
    "    # 'NewWinds_RemFryer2012', 'OldWinds_RemFryer2012', 'NewWinds_RemMullerMandel', 'NewWinds_RemFryer2012_noBHkick', 'NewWinds_RemFryer2012_noNSBHkick',\\\n",
    "    # #  'NewWinds_RemFryer2012_noWRwinds', 'NewWinds_RemFryer2012_noMSwinds', 'RemFryer2012_NOwinds','NewWinds_RemFryer2012_WRBELCZYNSKI2010', 'NewWinds_RemFryer2012_noCHE'] \n",
    "\n",
    "channel_keys = ['_CHE'] #'_stable', '_CE',  '_CHE'  ''\n",
    "\n",
    "# Define a function that takes two arguments and calls main with the other argument constant\n",
    "def main_wrapper(sim_name, channel_key):\n",
    "    return main(sim_name = sim_name, channel_key = channel_key, compas_v = 'v03.01.02')\n",
    "\n",
    "# Create a pool of processes\n",
    "with multiprocessing.Pool() as pool:\n",
    "    # For each sim_name\n",
    "    for sim_name in sim_names:\n",
    "        # Apply main_wrapper to every channel_key\n",
    "        pool.starmap(main_wrapper, [(sim_name, key) for key in channel_keys])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the potential DCO progenitors\n",
    "\n",
    "Read the full COMPAS data, and extract systems that become a DCO at any of the simulated metallicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential_DCO_progenitors_stable.h5\n",
      "reading from /mnt/home/lvanson/ceph/CompasOutput/v03.01.02//NewWinds_RemMullerMandel_oldRSG/\n",
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "len All_DCO_seeds 2229751\n",
      "for _stable, All_DCO_seeds [      7       9      28 ... 4999909 4999991 4999994] 262061\n",
      "potential_DCO_seeds [      7       9      28 ... 4999909 4999991 4999994] counts [12 12 12 ... 12 12 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1610677/1764337309.py:107: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = f'potential_DCO_progenitors{channel_key}.h5'\n",
    "print(save_name_table)\n",
    "\n",
    "# Initialize a list to store all SEEDS that ever become a DCO\n",
    "All_DCO_seeds = []\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    print(f'reading from {datar_root}/{sim_name}/')\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\")\n",
    "\n",
    "            # Open the HDF5 file for all systems at a given metallicity\n",
    "            data = h5.File(f'{datar_root}/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "\n",
    "            # Get the seeds that ever become a DCO\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "\n",
    "            # Simple case: you want all DCOs\n",
    "            if channel_key == '':\n",
    "                channel_bool = np.ones_like(DCO_seeds, dtype=bool)\n",
    "                \n",
    "            # Add extra constraints based on the channel you are interested in\n",
    "            else:\n",
    "                # I didn't save the CHE bool in most variations :(\n",
    "                try: \n",
    "                    CHE_in_DCO = data['BSE_Double_Compact_Objects']['CH_on_MS(1)'][()]      \n",
    "                except:          \n",
    "                    # Create a mask to map between the DCO seeds and the seeds in the system parameters\n",
    "                    SYS_SEED            = data['BSE_System_Parameters']['SEED'][()]\n",
    "                    SYS_DCO_mask        = np.in1d(SYS_SEED, DCO_seeds)\n",
    "                    #print('SAFETY CHECK FOR THE IN1D SEED COUPLING: ', np.nonzero(np.array(SYS_SEED[SYS_DCO_mask]).flatten() - np.array(DCO_seeds).flatten()) )\n",
    "\n",
    "                    CHE_bool            = data['BSE_System_Parameters']['CH_on_MS(1)'][()]\n",
    "                    CHE_in_DCO          = CHE_bool[SYS_DCO_mask]\n",
    "\n",
    "                if channel_key == '_stable':\n",
    "                    CE_Event_Counter    = pd.Series(data['BSE_Double_Compact_Objects']['CE_Event_Counter'][()])\n",
    "                    channel_bool        = np.logical_and(CE_Event_Counter == 0, CHE_in_DCO == 0 ) # stable and non-CHE\n",
    "\n",
    "                elif channel_key == '_CE':\n",
    "                    CE_Event_Counter    = pd.Series(data['BSE_Double_Compact_Objects']['CE_Event_Counter'][()])\n",
    "                    channel_bool        = np.logical_and(CE_Event_Counter > 0, CHE_in_DCO == 0 ) # Common envelope and non-CHE\n",
    "\n",
    "                elif channel_key == '_CHE':\n",
    "                    channel_bool        = CHE_in_DCO == 1\n",
    "\n",
    "                else:\n",
    "                    raise Exception(f'Unknown channel key {channel_key}')\n",
    "\n",
    "            # Add them to the list of all DCO seeds\n",
    "            All_DCO_seeds.extend(DCO_seeds[channel_bool])\n",
    "        else:\n",
    "            continue\n",
    "    print(f'len All_DCO_seeds {len(All_DCO_seeds)}' )\n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "    print(f'for {channel_key}, All_DCO_seeds', All_DCO_seeds, len(All_DCO_seeds) )\n",
    "    # Save the seeds to a file\n",
    "    np.savetxt(datar_root+ f'/{sim_name}/All_DCO_seeds{channel_key}.txt', All_DCO_seeds)\n",
    "\n",
    "    # Open the HDF5 file for all systems at all metallicities (This is heavy on the memory)\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "\n",
    "    # Create a mask to select only the systems that could potentially become a DCO\n",
    "    SYS_mask = np.in1d(All_data['BSE_System_Parameters']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    # Read the HDF5 datasets as pandas dataframes\n",
    "    SYS = pd.DataFrame()\n",
    "    # chosen to allow for rerunning of systems and other interesting parameters\n",
    "    SYS_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Stellar_Type(1)', 'Stellar_Type(2)','CE_Event_Counter', 'Mass@ZAMS(1)', 'Mass@ZAMS(2)','SemiMajorAxis@ZAMS',\n",
    "                            'Merger','Merger_At_Birth','Unbound', 'Immediate_RLOF>CE','Optimistic_CE', 'Applied_Kick_Magnitude(1)', 'Applied_Kick_Magnitude(2)', 'CH_on_MS(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(1)','SN_Kick_Phi(1)','SN_Kick_Theta(1)','SN_Kick_Mean_Anomaly(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(2)','SN_Kick_Phi(2)','SN_Kick_Theta(2)','SN_Kick_Mean_Anomaly(2)' ]\n",
    "    for key in SYS_keys_of_interest:\n",
    "        # You cant directly apply the mask to the HDF5 dataset, so you have to read it first\n",
    "        read_data = All_data['BSE_System_Parameters'][key][()]\n",
    "        SYS[key] = read_data[SYS_mask]\n",
    "\n",
    "    # Same mask for the DCO \n",
    "    DCO_mask = np.in1d(All_data['BSE_Double_Compact_Objects']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    DCO = pd.DataFrame()\n",
    "    DCO_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Merges_Hubble_Time', 'SemiMajorAxis@DCO','Coalescence_Time', 'Eccentricity@DCO', 'MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'Mass(1)', 'Mass(2)']\n",
    "    for key in DCO_keys_of_interest:\n",
    "        read_data = All_data['BSE_Double_Compact_Objects'][key][()]\n",
    "        DCO[key] = read_data[DCO_mask]\n",
    "\n",
    "    # Merge the SYS and DCO dataframes to make potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = SYS.merge(DCO, on=['SEED', 'Metallicity@ZAMS(1)'], how='left')\n",
    "    # Create a unique SEED that is a combination of SEED and metallicity\n",
    "    potential_DCO_progenitors['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(potential_DCO_progenitors['SEED'], potential_DCO_progenitors['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # test that this worked (every seed should occur len(metallicity) times, once for each Z)\n",
    "    potential_DCO_seeds, counts = np.unique(potential_DCO_progenitors['SEED'], return_counts=True)\n",
    "    print('potential_DCO_seeds', potential_DCO_seeds, 'counts', counts)\n",
    "\n",
    "    # Save the total dataframe\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we add the RLOF information to the potential DCO progenitor table\n",
    "\n",
    "Use the above created table to start from and add\n",
    "* mass transfer 1\n",
    "* First MT from star 2\n",
    "* the mass transfer that lead to a merger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the potential DCO table\n",
      "start reading RLOF data\n",
      "add a few extra cols to RLOF\n",
      "Adding the MT information for the first MT \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1610677/798653940.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1610677/798653940.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n",
      "this should be 1 [1]\n",
      "start merging tables\n",
      "done with first_RLOF_table\n",
      "done with MT_leading_to_merger_table\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1610677/798653940.py:106: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = f'potential_DCO_progenitors_RLOFinfo{channel_key}.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(f'{datar_root}/{sim_name}/{save_name_table}'):\n",
    "    print(f'Table {datar_root}/{sim_name}/{save_name_table} already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    print('Loading the potential DCO table')\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors{channel_key}.h5', key='All_DCO')\n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    unique_potentialDCO_seeds = np.unique(potential_DCO_progenitors['SEED'])\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    with h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "        ####################################\n",
    "        # Read RLOF data\n",
    "        RLOF = pd.DataFrame()\n",
    "        # Select only the RLOF events for systems that could potentially become a DCO\n",
    "        RLOF_mask = np.in1d(All_data['BSE_RLOF']['SEED'][()], unique_potentialDCO_seeds)\n",
    "\n",
    "        ########################################################################################\n",
    "        # Create the new RLOF columns in the potential DCO progenitors table\n",
    "        print('start reading RLOF data')\n",
    "        RLOF_keys = ['SEED', 'Metallicity@ZAMS(1)','SemiMajorAxis<MT', 'SemiMajorAxis>MT', 'Radius(1)<MT', 'Radius(2)<MT', 'Radius(1)>MT', \n",
    "                    'Radius(2)>MT', 'Mass(1)<MT', 'Mass(2)<MT', 'Mass(1)>MT', 'Mass(2)>MT','Stellar_Type(1)<MT', 'Stellar_Type(2)<MT', \n",
    "                    'Stellar_Type(1)>MT', 'Stellar_Type(2)>MT', 'MT_Event_Counter', 'CEE>MT', 'RLOF(1)>MT', 'RLOF(2)>MT', 'Merger']\n",
    "        for key in RLOF_keys:\n",
    "            read_data = All_data['BSE_RLOF'][key][()]\n",
    "            RLOF[key] = read_data[RLOF_mask]\n",
    "        print('add a few extra cols to RLOF')\n",
    "        RLOF['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(RLOF['SEED'], RLOF['Metallicity@ZAMS(1)'])]\n",
    "        RLOF['M1_M2<MT'] = RLOF['Mass(1)<MT']/RLOF['Mass(2)<MT'].astype(float)\n",
    "        RLOF.rename(columns={'Merger': 'RLOF_Merger'}, inplace=True) # rename so it wont conflict with the SYS['Merger']\n",
    "\n",
    "\n",
    "    ########################################################################################\n",
    "    # Now make subselections of this RLOF table that we can later add to the potential DCO progenitors table\n",
    "    # first_RLOF_table    = first_RLOF_table.add_prefix('firstMT_')                                               # Add prefix to all the keys\n",
    "    # first_RLOF_table.rename(columns={'firstMT_unique_Z_SEED': 'unique_Z_SEED'}, inplace=True)                   # Except the unique_Z_SEED\n",
    "    ################################\n",
    "    # First MT event\n",
    "    print('Adding the MT information for the first MT ')\n",
    "    first_MT_event_bool = RLOF['MT_Event_Counter'] == 1\n",
    "    first_RLOF_table    = RLOF[first_MT_event_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'first MT' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_RLOF_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################\n",
    "    # mass transfer that lead to a merger\n",
    "    print('Adding the MT information for the mass transfer that lead to a merger')\n",
    "    RLOF_Merger_bool            = RLOF['RLOF_Merger'] == 1\n",
    "    MT_leading_to_merger_table  = RLOF[RLOF_Merger_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'mass transfer leading to stellar merger' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(MT_leading_to_merger_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################################################\n",
    "    # First mass transfer from the second star\n",
    "    print('Adding the MT information for the first MT from star 2')\n",
    "    star_2_is_RLOF              = RLOF['RLOF(2)>MT'] == 1 # Star 2 is RLOF\n",
    "    star_2_is_RLOF_table        = RLOF[star_2_is_RLOF]\n",
    "\n",
    "    # Find the minimum 'MT_Event_Counter' for each 'unique_Z_SEED' where Star 2 is RLOF\n",
    "    Minimun_MT_event_count_bool = np.where(star_2_is_RLOF_table['MT_Event_Counter'] == star_2_is_RLOF_table.groupby('unique_Z_SEED')['MT_Event_Counter'].transform('min'), True, False)\n",
    "    first_MT_from_star2_table   = star_2_is_RLOF_table[Minimun_MT_event_count_bool].copy()\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_MT_from_star2_table.rename(columns={col: 'star2_firstMT_' + col for col in first_MT_from_star2_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # lastly, the first MT from star 2 should also only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_MT_from_star2_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ########################\n",
    "    # Empty RLOF to save mem\n",
    "    del RLOF\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    print('start merging tables')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_RLOF_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_RLOF_table')\n",
    "    del first_RLOF_table # to save memory\n",
    "    # Merge info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(MT_leading_to_merger_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with MT_leading_to_merger_table')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_MT_from_star2_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_MT_from_star2_table')\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with MT info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEED</th>\n",
       "      <th>Metallicity@ZAMS(1)</th>\n",
       "      <th>Stellar_Type(1)</th>\n",
       "      <th>Stellar_Type(2)</th>\n",
       "      <th>CE_Event_Counter</th>\n",
       "      <th>Mass@ZAMS(1)</th>\n",
       "      <th>Mass@ZAMS(2)</th>\n",
       "      <th>SemiMajorAxis@ZAMS</th>\n",
       "      <th>Merger</th>\n",
       "      <th>Merger_At_Birth</th>\n",
       "      <th>...</th>\n",
       "      <th>star2_firstMT_Stellar_Type(1)&lt;MT</th>\n",
       "      <th>star2_firstMT_Stellar_Type(2)&lt;MT</th>\n",
       "      <th>star2_firstMT_Stellar_Type(1)&gt;MT</th>\n",
       "      <th>star2_firstMT_Stellar_Type(2)&gt;MT</th>\n",
       "      <th>star2_firstMT_MT_Event_Counter</th>\n",
       "      <th>star2_firstMT_CEE&gt;MT</th>\n",
       "      <th>star2_firstMT_RLOF(1)&gt;MT</th>\n",
       "      <th>star2_firstMT_RLOF(2)&gt;MT</th>\n",
       "      <th>star2_firstMT_RLOF_Merger</th>\n",
       "      <th>star2_firstMT_M1_M2&lt;MT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600004</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>60.628779</td>\n",
       "      <td>36.346818</td>\n",
       "      <td>1.795626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3600017</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>28.199632</td>\n",
       "      <td>25.659874</td>\n",
       "      <td>2.087447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3600043</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>69.679098</td>\n",
       "      <td>41.052767</td>\n",
       "      <td>14.947039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3600048</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.888392</td>\n",
       "      <td>14.406964</td>\n",
       "      <td>0.414274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3600068</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>68.552507</td>\n",
       "      <td>63.833719</td>\n",
       "      <td>353.252381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144727</th>\n",
       "      <td>3849915</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>80.932091</td>\n",
       "      <td>73.428291</td>\n",
       "      <td>817.135069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144728</th>\n",
       "      <td>3849918</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>39.277391</td>\n",
       "      <td>32.621156</td>\n",
       "      <td>45.570032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144729</th>\n",
       "      <td>3849935</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>69.899077</td>\n",
       "      <td>9.603328</td>\n",
       "      <td>12.302885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144730</th>\n",
       "      <td>3849941</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>49.619535</td>\n",
       "      <td>10.480344</td>\n",
       "      <td>1.363107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.871779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144731</th>\n",
       "      <td>3849950</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>56.132327</td>\n",
       "      <td>30.574039</td>\n",
       "      <td>0.572888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3144732 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SEED  Metallicity@ZAMS(1)  Stellar_Type(1)  Stellar_Type(2)  \\\n",
       "0        3600004             0.014142               14               14   \n",
       "1        3600017             0.014142               14               14   \n",
       "2        3600043             0.014142               14               14   \n",
       "3        3600048             0.014142               14               14   \n",
       "4        3600068             0.014142               14               14   \n",
       "...          ...                  ...              ...              ...   \n",
       "3144727  3849915             0.000100               14               14   \n",
       "3144728  3849918             0.000100               14               14   \n",
       "3144729  3849935             0.000100               14               13   \n",
       "3144730  3849941             0.000100               14               13   \n",
       "3144731  3849950             0.000100               14               14   \n",
       "\n",
       "         CE_Event_Counter  Mass@ZAMS(1)  Mass@ZAMS(2)  SemiMajorAxis@ZAMS  \\\n",
       "0                       0     60.628779     36.346818            1.795626   \n",
       "1                       0     28.199632     25.659874            2.087447   \n",
       "2                       0     69.679098     41.052767           14.947039   \n",
       "3                       0     54.888392     14.406964            0.414274   \n",
       "4                       0     68.552507     63.833719          353.252381   \n",
       "...                   ...           ...           ...                 ...   \n",
       "3144727                 0     80.932091     73.428291          817.135069   \n",
       "3144728                 0     39.277391     32.621156           45.570032   \n",
       "3144729                 0     69.899077      9.603328           12.302885   \n",
       "3144730                 0     49.619535     10.480344            1.363107   \n",
       "3144731                 1     56.132327     30.574039            0.572888   \n",
       "\n",
       "         Merger  Merger_At_Birth  ...  star2_firstMT_Stellar_Type(1)<MT  \\\n",
       "0             0                0  ...                              14.0   \n",
       "1             0                0  ...                              14.0   \n",
       "2             0                0  ...                               NaN   \n",
       "3             0                0  ...                              14.0   \n",
       "4             0                0  ...                               NaN   \n",
       "...         ...              ...  ...                               ...   \n",
       "3144727       0                0  ...                               NaN   \n",
       "3144728       0                0  ...                               NaN   \n",
       "3144729       0                0  ...                               NaN   \n",
       "3144730       0                0  ...                              14.0   \n",
       "3144731       0                0  ...                              14.0   \n",
       "\n",
       "         star2_firstMT_Stellar_Type(2)<MT  star2_firstMT_Stellar_Type(1)>MT  \\\n",
       "0                                     2.0                              14.0   \n",
       "1                                     2.0                              14.0   \n",
       "2                                     NaN                               NaN   \n",
       "3                                     2.0                              14.0   \n",
       "4                                     NaN                               NaN   \n",
       "...                                   ...                               ...   \n",
       "3144727                               NaN                               NaN   \n",
       "3144728                               NaN                               NaN   \n",
       "3144729                               NaN                               NaN   \n",
       "3144730                               4.0                              14.0   \n",
       "3144731                               4.0                              14.0   \n",
       "\n",
       "         star2_firstMT_Stellar_Type(2)>MT  star2_firstMT_MT_Event_Counter  \\\n",
       "0                                     7.0                             2.0   \n",
       "1                                     7.0                             2.0   \n",
       "2                                     NaN                             NaN   \n",
       "3                                     7.0                             2.0   \n",
       "4                                     NaN                             NaN   \n",
       "...                                   ...                             ...   \n",
       "3144727                               NaN                             NaN   \n",
       "3144728                               NaN                             NaN   \n",
       "3144729                               NaN                             NaN   \n",
       "3144730                               7.0                             1.0   \n",
       "3144731                               7.0                             2.0   \n",
       "\n",
       "         star2_firstMT_CEE>MT  star2_firstMT_RLOF(1)>MT  \\\n",
       "0                         0.0                       0.0   \n",
       "1                         0.0                       0.0   \n",
       "2                         NaN                       NaN   \n",
       "3                         0.0                       0.0   \n",
       "4                         NaN                       NaN   \n",
       "...                       ...                       ...   \n",
       "3144727                   NaN                       NaN   \n",
       "3144728                   NaN                       NaN   \n",
       "3144729                   NaN                       NaN   \n",
       "3144730                   0.0                       0.0   \n",
       "3144731                   1.0                       0.0   \n",
       "\n",
       "         star2_firstMT_RLOF(2)>MT  star2_firstMT_RLOF_Merger  \\\n",
       "0                             1.0                        0.0   \n",
       "1                             1.0                        0.0   \n",
       "2                             NaN                        NaN   \n",
       "3                             1.0                        0.0   \n",
       "4                             NaN                        NaN   \n",
       "...                           ...                        ...   \n",
       "3144727                       NaN                        NaN   \n",
       "3144728                       NaN                        NaN   \n",
       "3144729                       NaN                        NaN   \n",
       "3144730                       1.0                        0.0   \n",
       "3144731                       1.0                        0.0   \n",
       "\n",
       "         star2_firstMT_M1_M2<MT  \n",
       "0                      0.355043  \n",
       "1                      0.227159  \n",
       "2                           NaN  \n",
       "3                      0.775676  \n",
       "4                           NaN  \n",
       "...                         ...  \n",
       "3144727                     NaN  \n",
       "3144728                     NaN  \n",
       "3144729                     NaN  \n",
       "3144730                1.871779  \n",
       "3144731                0.498394  \n",
       "\n",
       "[3144732 rows x 93 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(potential_DCO_progenitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally Add SN information\n",
    "\n",
    "#####  'Supernova_State'\n",
    "*  No supernova = 0 \n",
    "*  Star 1 is the supernova \t = 1 \n",
    "*  Star 2 is the supernova \t = 2 \n",
    "*  Both stars are supernovae \t = 3\n",
    "\n",
    "##### 'SN_Type(SN)'\n",
    "*  NONE \t = 0 \n",
    "*  CCSN \t = 1 \n",
    "*  ECSN \t = 2 \n",
    "*  PISN \t = 4 \n",
    "*  PPISN \t = 8 \n",
    "*  USSN \t = 16 \n",
    "*  AIC \t     = 32 \n",
    "*  SNIA \t = 64 \n",
    "*  HeSD \t = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the SN information\n",
      "Adding the SN information for star 1 going SN\n",
      "this should be 1 [1]\n",
      "done with SN1\n",
      "Adding the SN information for star 2 going SN\n",
      "this should be 1 [1]\n",
      "done with SN1\n",
      "Done!, Saving the potential DCO progenitors with SN info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1610677/175097832.py:90: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = f'potential_DCO_progenitors_Allinfo{channel_key}.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors_RLOFinfo{channel_key}.h5', key='All_DCO')\n",
    "    \n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    unique_potentialDCO_seeds = np.unique(potential_DCO_progenitors['SEED'])\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "    #################################################################################\n",
    "    # Finally, add supernove information\n",
    "    print('Adding the SN information')\n",
    "    with h5.File(datar_root+f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:        \n",
    "        # Read SN info as pandas dataframes\n",
    "        SNe = pd.DataFrame()\n",
    "        \n",
    "        # Select only the SN events for systems that could potentially become a DCO\n",
    "        SN_mask = np.in1d(All_data['BSE_Supernovae']['SEED'][()], unique_potentialDCO_seeds)\n",
    "\n",
    "        SN_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'SN_Type(SN)', 'Supernova_State',\\\n",
    "                            'Unbound', 'Applied_Kick_Magnitude(SN)', 'Fallback_Fraction(SN)', 'Mass_CO_Core@CO(SN)', \\\n",
    "                            'Mass_Core@CO(SN)', 'Mass_He_Core@CO(SN)', 'Mass_Total@CO(SN)', 'Orb_Velocity<SN']\n",
    "        for key in SN_keys_of_interest:\n",
    "            read_data   = All_data['BSE_Supernovae'][key][()]\n",
    "            SNe[key]    = read_data[SN_mask]\n",
    "\n",
    "        #Add unique seed key\n",
    "        SNe['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(SNe['SEED'], SNe['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "\n",
    "    ########################################################################################\n",
    "    # Now make subselections of this SN table that we can add to the potential DCO progenitors table\n",
    "    # # Star 1 is going SN\n",
    "    # star1_SN = SNe[SNe['Supernova_State'] == 1]\n",
    "    # # Star 2 is going SN\n",
    "    # star2_SN = SNe[SNe['Supernova_State'] == 2]\n",
    "    ################################\n",
    "    # First star is going SN\n",
    "    print('Adding the SN information for star 1 going SN')\n",
    "    star1_going_SN_bool = SNe['Supernova_State'] == 1\n",
    "    SN1_table    = SNe[star1_going_SN_bool].copy()\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    SN1_table.rename(columns={col: 'SN_star1_' + col for col in SN1_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # Star 1 should only go SN once per unique_Z_SEED\n",
    "    s, counts = np.unique(SN1_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(SN1_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with SN1')\n",
    "    del SN1_table # to save memory\n",
    "\n",
    "    ################################\n",
    "    # Second star is going SN\n",
    "    print('Adding the SN information for star 2 going SN')\n",
    "    star2_going_SN_bool = SNe['Supernova_State'] == 2\n",
    "    SN2_table    = SNe[star2_going_SN_bool].copy()\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    SN2_table.rename(columns={col: 'SN_star2_' + col for col in SN2_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # Star 1 should only go SN once per unique_Z_SEED\n",
    "    s, counts = np.unique(SN2_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(SN2_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with SN1')\n",
    "    del SN2_table # to save memory\n",
    "\n",
    "    # Add the SN info to the potential DCO progenitors\n",
    "    # potential_DCO_progenitors['SN_Type(1)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 1].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "    # potential_DCO_progenitors['SN_Type(2)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 2].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "\n",
    "    # del SNe # empty SNe to save memory\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with SN info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, split your potential DCO table between potential BBH, BHNS and NSNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 560052 entries, 0 to 560051\n",
      "Columns: 114 entries, SEED to pot_NSNS_bool\n",
      "dtypes: bool(3), float64(98), int32(2), object(3), uint32(1), uint64(1), uint8(6)\n",
      "memory usage: 451.3+ MB\n",
      "Table exists, reading in...  None\n",
      "saving at  /mnt/home/lvanson/ceph/CompasOutput/v03.01.02//NewWinds_RemFryer2012/potential_DCO_progenitors_Allinfo.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3343784/3494885404.py:33: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root + f'/{sim_name}/{prog_table_name}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "sim_name = 'NewWinds_RemFryer2012'\n",
    "channel_key = '' #'_stable' # '_CE' '_CHE'  ''\n",
    "\n",
    "####################################\n",
    "# read the potential DCO progenitors\n",
    "prog_table_name = f'potential_DCO_progenitors_Allinfo{channel_key}.h5'\n",
    "\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/'+prog_table_name):\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'{sim_name}/' + prog_table_name, key='All_DCO')\n",
    "    print('Table exists, reading in... ',  potential_DCO_progenitors.info())\n",
    "else:\n",
    "    print(f'error, {datar_root}/{sim_name}/{prog_table_name} does not exist')\n",
    "\n",
    "with h5.File(datar_root+f'{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "    DCO = All_data['BSE_Double_Compact_Objects']\n",
    "    st1 = DCO['Stellar_Type(1)'][()]\n",
    "    st2 = DCO['Stellar_Type(2)'][()]\n",
    "    dco_merger = DCO['Merges_Hubble_Time'][()]  \n",
    "    DCO_seed = DCO['SEED'][()]\n",
    "    # Now I want to add a bool that tells me if this system is ever a BBH, BHNS or BNS progenitor\n",
    "    BBH_bool = np.logical_and(st1 == 14,st2 == 14)\n",
    "    BHNS_bool = np.logical_or(np.logical_and(st1 == 13,st2 == 14),\n",
    "                            np.logical_and(st1 == 14,st2 == 13) )\n",
    "    NSNS_bool = np.logical_and(st1 == 13,st2 == 13)\n",
    "    merger_bool = dco_merger == 1\n",
    "\n",
    "    potential_DCO_progenitors['pot_BHBH_bool'] = np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BBH_bool*merger_bool]) )\n",
    "    potential_DCO_progenitors['pot_BHNS_bool'] = np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BHNS_bool*merger_bool]) )\n",
    "    potential_DCO_progenitors['pot_NSNS_bool'] = np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[NSNS_bool*merger_bool]) )\n",
    "\n",
    "    # Save the dataframe, appending to the existing file\n",
    "    print('saving at ', datar_root + f'/{sim_name}/{prog_table_name}')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root + f'/{sim_name}/{prog_table_name}', key='All_DCO', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our potential DCO progenitors into BBH, BHNS and NSNS progenitors\n",
    "potential_BBH_progenitors  = potential_DCO_progenitors[potential_DCO_progenitors['pot_BHBH_bool']]\n",
    "potential_BHNS_progenitors = potential_DCO_progenitors[potential_DCO_progenitors['pot_BHNS_bool']]\n",
    "potential_NSNS_progenitors = potential_DCO_progenitors[potential_DCO_progenitors['pot_NSNS_bool']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEED</th>\n",
       "      <th>Metallicity@ZAMS(1)</th>\n",
       "      <th>Stellar_Type(1)</th>\n",
       "      <th>Stellar_Type(2)</th>\n",
       "      <th>CE_Event_Counter</th>\n",
       "      <th>Mass@ZAMS(1)</th>\n",
       "      <th>Mass@ZAMS(2)</th>\n",
       "      <th>SemiMajorAxis@ZAMS</th>\n",
       "      <th>Merger</th>\n",
       "      <th>Merger_At_Birth</th>\n",
       "      <th>...</th>\n",
       "      <th>SN_star2_Applied_Kick_Magnitude(SN)</th>\n",
       "      <th>SN_star2_Fallback_Fraction(SN)</th>\n",
       "      <th>SN_star2_Mass_CO_Core@CO(SN)</th>\n",
       "      <th>SN_star2_Mass_Core@CO(SN)</th>\n",
       "      <th>SN_star2_Mass_He_Core@CO(SN)</th>\n",
       "      <th>SN_star2_Mass_Total@CO(SN)</th>\n",
       "      <th>SN_star2_Orb_Velocity&lt;SN</th>\n",
       "      <th>pot_BHBH_bool</th>\n",
       "      <th>pot_BHNS_bool</th>\n",
       "      <th>pot_NSNS_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SEED, Metallicity@ZAMS(1), Stellar_Type(1), Stellar_Type(2), CE_Event_Counter, Mass@ZAMS(1), Mass@ZAMS(2), SemiMajorAxis@ZAMS, Merger, Merger_At_Birth, Unbound, Immediate_RLOF>CE, Optimistic_CE, Applied_Kick_Magnitude(1), Applied_Kick_Magnitude(2), CH_on_MS(1), SN_Kick_Magnitude_Random_Number(1), SN_Kick_Phi(1), SN_Kick_Theta(1), SN_Kick_Mean_Anomaly(1), SN_Kick_Magnitude_Random_Number(2), SN_Kick_Phi(2), SN_Kick_Theta(2), SN_Kick_Mean_Anomaly(2), Merges_Hubble_Time, SemiMajorAxis@DCO, Coalescence_Time, Eccentricity@DCO, MT_Donor_Hist(1), MT_Donor_Hist(2), Mass(1), Mass(2), unique_Z_SEED, firstMT_SemiMajorAxis<MT, firstMT_SemiMajorAxis>MT, firstMT_Radius(1)<MT, firstMT_Radius(2)<MT, firstMT_Radius(1)>MT, firstMT_Radius(2)>MT, firstMT_Mass(1)<MT, firstMT_Mass(2)<MT, firstMT_Mass(1)>MT, firstMT_Mass(2)>MT, firstMT_Stellar_Type(1)<MT, firstMT_Stellar_Type(2)<MT, firstMT_Stellar_Type(1)>MT, firstMT_Stellar_Type(2)>MT, firstMT_MT_Event_Counter, firstMT_CEE>MT, firstMT_RLOF(1)>MT, firstMT_RLOF(2)>MT, firstMT_RLOF_Merger, firstMT_M1_M2<MT, MT_lead_to_merger_SemiMajorAxis<MT, MT_lead_to_merger_SemiMajorAxis>MT, MT_lead_to_merger_Radius(1)<MT, MT_lead_to_merger_Radius(2)<MT, MT_lead_to_merger_Radius(1)>MT, MT_lead_to_merger_Radius(2)>MT, MT_lead_to_merger_Mass(1)<MT, MT_lead_to_merger_Mass(2)<MT, MT_lead_to_merger_Mass(1)>MT, MT_lead_to_merger_Mass(2)>MT, MT_lead_to_merger_Stellar_Type(1)<MT, MT_lead_to_merger_Stellar_Type(2)<MT, MT_lead_to_merger_Stellar_Type(1)>MT, MT_lead_to_merger_Stellar_Type(2)>MT, MT_lead_to_merger_MT_Event_Counter, MT_lead_to_merger_CEE>MT, MT_lead_to_merger_RLOF(1)>MT, MT_lead_to_merger_RLOF(2)>MT, MT_lead_to_merger_RLOF_Merger, MT_lead_to_merger_M1_M2<MT, star2_firstMT_SemiMajorAxis<MT, star2_firstMT_SemiMajorAxis>MT, star2_firstMT_Radius(1)<MT, star2_firstMT_Radius(2)<MT, star2_firstMT_Radius(1)>MT, star2_firstMT_Radius(2)>MT, star2_firstMT_Mass(1)<MT, star2_firstMT_Mass(2)<MT, star2_firstMT_Mass(1)>MT, star2_firstMT_Mass(2)>MT, star2_firstMT_Stellar_Type(1)<MT, star2_firstMT_Stellar_Type(2)<MT, star2_firstMT_Stellar_Type(1)>MT, star2_firstMT_Stellar_Type(2)>MT, star2_firstMT_MT_Event_Counter, star2_firstMT_CEE>MT, star2_firstMT_RLOF(1)>MT, star2_firstMT_RLOF(2)>MT, star2_firstMT_RLOF_Merger, star2_firstMT_M1_M2<MT, SN_star1_SN_Type(SN), SN_star1_Supernova_State, SN_star1_Unbound, SN_star1_Applied_Kick_Magnitude(SN), SN_star1_Fallback_Fraction(SN), SN_star1_Mass_CO_Core@CO(SN), SN_star1_Mass_Core@CO(SN), ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 116 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(potential_NSNS_progenitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
