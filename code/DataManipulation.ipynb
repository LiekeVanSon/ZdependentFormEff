{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "\n",
    "Read the full COMPAS data, and extract only the information that you need (specifically only the systems that are every a DCO)\n",
    "\n",
    "Then we want to add relevant information about the system in the following cases:\n",
    "\n",
    " * The first mass transfer that the binary engaged in\n",
    " * The first mass transfer that star 2 engaged in\n",
    " * The mass transfer that lead to a stellar merger (if any)\n",
    " * The supernova information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "home_dir = os.path.expanduser(\"~\") \n",
    "datar_root = home_dir + \"/ceph/CompasOutput/v02.46.01/\" #v02.35.02/\"\n",
    "sim_name =  'OldWinds_RemFryer2012'#  \n",
    "\n",
    "######################################\n",
    "## PLOT setttings\n",
    "plt.rc('font', family='serif')\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "fsize, SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = 30,20,25,30\n",
    "for obj in ['axes','xtick','ytick']:\n",
    "    plt.rc(obj, labelsize=SMALL_SIZE)          # controls default text sizes\n",
    "for obj in ['figure','axes']:\n",
    "    plt.rc(obj, titlesize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "\n",
    "# Turn off natural name warning for panda tables (this is due to '@' and '>' in the COMPAS column names)\n",
    "import warnings\n",
    "from tables import NaturalNameWarning\n",
    "warnings.filterwarnings('ignore', category=NaturalNameWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the potential DCO progenitors\n",
    "\n",
    "Read the full COMPAS data, and extract systems that become a DCO at any of the simulated metallicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "All_DCO_seeds [    72    144    217 ... 999909 999985 999995] 9996\n",
      "potential_DCO_seeds [    72    144    217 ... 999909 999985 999995] counts [12 12 12 ... 12 12 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/2618102458.py:71: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors.h5'\n",
    "\n",
    "\n",
    "# Initialize a list to store all SEEDS that ever become a DCO\n",
    "All_DCO_seeds = []\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\")\n",
    "\n",
    "            # Open the HDF5 file for all systems at a given metallicity\n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "\n",
    "            # Get the seeds that ever become a DCO\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "\n",
    "            # Add them to the list of all DCO seeds\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "    print('All_DCO_seeds', All_DCO_seeds, len(All_DCO_seeds) )\n",
    "\n",
    "    # Open the HDF5 file for all systems at all metallicities (This is heavy on the memory)\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "\n",
    "    # Create a mask to select only the systems that could potentially become a DCO\n",
    "    SYS_mask = np.in1d(All_data['BSE_System_Parameters']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    # Read the HDF5 datasets as pandas dataframes\n",
    "    SYS = pd.DataFrame()\n",
    "    # chosen to allow for rerunning of systems and other interesting parameters\n",
    "    SYS_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Stellar_Type(1)', 'Stellar_Type(2)','CE_Event_Counter', 'Mass@ZAMS(1)', 'Mass@ZAMS(2)','SemiMajorAxis@ZAMS',\n",
    "                            'Merger','Merger_At_Birth','Unbound', 'Immediate_RLOF>CE','Optimistic_CE', 'Applied_Kick_Magnitude(1)', 'Applied_Kick_Magnitude(2)', 'CH_on_MS(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(1)','SN_Kick_Phi(1)','SN_Kick_Theta(1)','SN_Kick_Mean_Anomaly(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(2)','SN_Kick_Phi(2)','SN_Kick_Theta(2)','SN_Kick_Mean_Anomaly(2)' ]\n",
    "    for key in SYS_keys_of_interest:\n",
    "        # You cant directly apply the mask to the HDF5 dataset, so you have to read it first\n",
    "        read_data = All_data['BSE_System_Parameters'][key][()]\n",
    "        SYS[key] = read_data[SYS_mask]\n",
    "\n",
    "    # Same mask for the DCO\n",
    "    DCO_mask = np.in1d(All_data['BSE_Double_Compact_Objects']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    DCO = pd.DataFrame()\n",
    "    DCO_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Merges_Hubble_Time', 'SemiMajorAxis@DCO','Coalescence_Time', 'Eccentricity@DCO', 'MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'Mass(1)', 'Mass(2)']\n",
    "    for key in DCO_keys_of_interest:\n",
    "        read_data = All_data['BSE_Double_Compact_Objects'][key][()]\n",
    "        DCO[key] = read_data[DCO_mask]\n",
    "\n",
    "    # Merge the SYS and DCO dataframes to make potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = SYS.merge(DCO, on=['SEED', 'Metallicity@ZAMS(1)'], how='left')\n",
    "    # Create a unique SEED that is a combination of SEED and metallicity\n",
    "    potential_DCO_progenitors['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(potential_DCO_progenitors['SEED'], potential_DCO_progenitors['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # test that this worked (every seed should occur 7 times, once for each Z)\n",
    "    potential_DCO_seeds, counts = np.unique(potential_DCO_progenitors['SEED'], return_counts=True)\n",
    "    print('potential_DCO_seeds', potential_DCO_seeds, 'counts', counts)\n",
    "\n",
    "    # Save the total dataframe\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEED</th>\n",
       "      <th>Metallicity@ZAMS(1)</th>\n",
       "      <th>Stellar_Type(1)</th>\n",
       "      <th>Stellar_Type(2)</th>\n",
       "      <th>CE_Event_Counter</th>\n",
       "      <th>Mass@ZAMS(1)</th>\n",
       "      <th>Mass@ZAMS(2)</th>\n",
       "      <th>SemiMajorAxis@ZAMS</th>\n",
       "      <th>Merger</th>\n",
       "      <th>Merger_At_Birth</th>\n",
       "      <th>...</th>\n",
       "      <th>SN_Kick_Mean_Anomaly(2)</th>\n",
       "      <th>Merges_Hubble_Time</th>\n",
       "      <th>SemiMajorAxis@DCO</th>\n",
       "      <th>Coalescence_Time</th>\n",
       "      <th>Eccentricity@DCO</th>\n",
       "      <th>MT_Donor_Hist(1)</th>\n",
       "      <th>MT_Donor_Hist(2)</th>\n",
       "      <th>Mass(1)</th>\n",
       "      <th>Mass(2)</th>\n",
       "      <th>unique_Z_SEED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900111</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>37.623091</td>\n",
       "      <td>37.623091</td>\n",
       "      <td>0.077936</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.924066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900111_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900180</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>148.784525</td>\n",
       "      <td>105.977012</td>\n",
       "      <td>16.882112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.047951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900180_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900319</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>143.292795</td>\n",
       "      <td>101.826748</td>\n",
       "      <td>0.601512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900319_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900364</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>10.330220</td>\n",
       "      <td>9.763986</td>\n",
       "      <td>0.758063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900364_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900407</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>23.645548</td>\n",
       "      <td>11.599888</td>\n",
       "      <td>12.263075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.807385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900407_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119947</th>\n",
       "      <td>824412</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>26.603089</td>\n",
       "      <td>26.077880</td>\n",
       "      <td>7.643769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.502000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>824412_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119948</th>\n",
       "      <td>824602</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.612204</td>\n",
       "      <td>11.819922</td>\n",
       "      <td>3.327411</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.091113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>824602_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119949</th>\n",
       "      <td>824766</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.189704</td>\n",
       "      <td>8.017419</td>\n",
       "      <td>0.686693</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.347039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>824766_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119950</th>\n",
       "      <td>824848</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>62.598380</td>\n",
       "      <td>34.624825</td>\n",
       "      <td>0.795329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.562958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030577</td>\n",
       "      <td>12.704059</td>\n",
       "      <td>0.168223</td>\n",
       "      <td>b'2               '</td>\n",
       "      <td>b'4               '</td>\n",
       "      <td>25.092719</td>\n",
       "      <td>18.397697</td>\n",
       "      <td>824848_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119951</th>\n",
       "      <td>824858</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>60.295524</td>\n",
       "      <td>60.295524</td>\n",
       "      <td>0.078640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.375425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171886</td>\n",
       "      <td>3911.119314</td>\n",
       "      <td>0.195007</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>31.559764</td>\n",
       "      <td>31.559764</td>\n",
       "      <td>824858_0.00010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119952 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SEED  Metallicity@ZAMS(1)  Stellar_Type(1)  Stellar_Type(2)  \\\n",
       "0       900111             0.014142               16               16   \n",
       "1       900180             0.014142               14               14   \n",
       "2       900319             0.014142                1                1   \n",
       "3       900364             0.014142               13               13   \n",
       "4       900407             0.014142               14               13   \n",
       "...        ...                  ...              ...              ...   \n",
       "119947  824412             0.000100                7                7   \n",
       "119948  824602             0.000100                7                1   \n",
       "119949  824766             0.000100                7                1   \n",
       "119950  824848             0.000100               14               14   \n",
       "119951  824858             0.000100               14               14   \n",
       "\n",
       "        CE_Event_Counter  Mass@ZAMS(1)  Mass@ZAMS(2)  SemiMajorAxis@ZAMS  \\\n",
       "0                      0     37.623091     37.623091            0.077936   \n",
       "1                      0    148.784525    105.977012           16.882112   \n",
       "2                      1    143.292795    101.826748            0.601512   \n",
       "3                      1     10.330220      9.763986            0.758063   \n",
       "4                      0     23.645548     11.599888           12.263075   \n",
       "...                  ...           ...           ...                 ...   \n",
       "119947                 1     26.603089     26.077880            7.643769   \n",
       "119948                 1     29.612204     11.819922            3.327411   \n",
       "119949                 1     10.189704      8.017419            0.686693   \n",
       "119950                 1     62.598380     34.624825            0.795329   \n",
       "119951                 0     60.295524     60.295524            0.078640   \n",
       "\n",
       "        Merger  Merger_At_Birth  ...  SN_Kick_Mean_Anomaly(2)  \\\n",
       "0            1                1  ...                 5.924066   \n",
       "1            0                0  ...                 5.047951   \n",
       "2            1                0  ...                 1.536282   \n",
       "3            0                0  ...                 1.021885   \n",
       "4            0                0  ...                 1.807385   \n",
       "...        ...              ...  ...                      ...   \n",
       "119947       1                0  ...                 2.502000   \n",
       "119948       1                0  ...                 4.091113   \n",
       "119949       1                0  ...                 3.347039   \n",
       "119950       0                0  ...                 1.562958   \n",
       "119951       0                0  ...                 3.375425   \n",
       "\n",
       "        Merges_Hubble_Time  SemiMajorAxis@DCO  Coalescence_Time  \\\n",
       "0                      NaN                NaN               NaN   \n",
       "1                      NaN                NaN               NaN   \n",
       "2                      NaN                NaN               NaN   \n",
       "3                      NaN                NaN               NaN   \n",
       "4                      NaN                NaN               NaN   \n",
       "...                    ...                ...               ...   \n",
       "119947                 NaN                NaN               NaN   \n",
       "119948                 NaN                NaN               NaN   \n",
       "119949                 NaN                NaN               NaN   \n",
       "119950                 1.0           0.030577         12.704059   \n",
       "119951                 1.0           0.171886       3911.119314   \n",
       "\n",
       "        Eccentricity@DCO     MT_Donor_Hist(1)     MT_Donor_Hist(2)    Mass(1)  \\\n",
       "0                    NaN                  NaN                  NaN        NaN   \n",
       "1                    NaN                  NaN                  NaN        NaN   \n",
       "2                    NaN                  NaN                  NaN        NaN   \n",
       "3                    NaN                  NaN                  NaN        NaN   \n",
       "4                    NaN                  NaN                  NaN        NaN   \n",
       "...                  ...                  ...                  ...        ...   \n",
       "119947               NaN                  NaN                  NaN        NaN   \n",
       "119948               NaN                  NaN                  NaN        NaN   \n",
       "119949               NaN                  NaN                  NaN        NaN   \n",
       "119950          0.168223  b'2               '  b'4               '  25.092719   \n",
       "119951          0.195007  b'NA              '  b'NA              '  31.559764   \n",
       "\n",
       "          Mass(2)   unique_Z_SEED  \n",
       "0             NaN  900111_0.01414  \n",
       "1             NaN  900180_0.01414  \n",
       "2             NaN  900319_0.01414  \n",
       "3             NaN  900364_0.01414  \n",
       "4             NaN  900407_0.01414  \n",
       "...           ...             ...  \n",
       "119947        NaN  824412_0.00010  \n",
       "119948        NaN  824602_0.00010  \n",
       "119949        NaN  824766_0.00010  \n",
       "119950  18.397697  824848_0.00010  \n",
       "119951  31.559764  824858_0.00010  \n",
       "\n",
       "[119952 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(potential_DCO_progenitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we add the RLOF information to the potential DCO progenitor table\n",
    "\n",
    "Use the above created table to start from and add\n",
    "* mass transfer 1\n",
    "* First MT from star 2\n",
    "* the mass transfer that lead to a merger\n",
    "\n",
    "### And in the end also supernova information \n",
    "\n",
    "#####  'Supernova_State'\n",
    "*  No supernova = 0 \n",
    "*  Star 1 is the supernova \t = 1 \n",
    "*  Star 2 is the supernova \t = 2 \n",
    "*  Both stars are supernovae \t = 3\n",
    "\n",
    "##### 'SN_Type(SN)'\n",
    "*  NONE \t = 0 \n",
    "*  CCSN \t = 1 \n",
    "*  ECSN \t = 2 \n",
    "*  PISN \t = 4 \n",
    "*  PPISN \t = 8 \n",
    "*  USSN \t = 16 \n",
    "*  AIC \t     = 32 \n",
    "*  SNIA \t = 64 \n",
    "*  HeSD \t = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "start reading RLOF data\n",
      "add a few extra cols to RLOF\n",
      "Adding the MT information for the first MT \n",
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/356593650.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
      "/tmp/ipykernel_2622428/356593650.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n",
      "this should be 1 [1]\n",
      "start merging tables\n",
      "done with first_RLOF_table\n",
      "done with MT_leading_to_merger_table\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/356593650.py:121: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors_RLOFinfo.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors.h5', key='All_DCO')\n",
    "\n",
    "    # Initialize a list to store all SEEDS that ever become a DCO\n",
    "    All_DCO_seeds = []\n",
    "\n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "        # Get the seeds that ever become a DCO\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\") \n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    with h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "        ####################################\n",
    "        # Read RLOF data\n",
    "        RLOF = pd.DataFrame()\n",
    "        # Select only the RLOF events for systems that could potentially become a DCO\n",
    "        RLOF_mask = np.in1d(All_data['BSE_RLOF']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "        ########################################################################################\n",
    "        # Create the new RLOF columns in the potential DCO progenitors table\n",
    "        print('start reading RLOF data')\n",
    "        RLOF_keys = ['SEED', 'Metallicity@ZAMS(1)','SemiMajorAxis<MT', 'SemiMajorAxis>MT', 'Radius(1)<MT', 'Radius(2)<MT', 'Radius(1)>MT', \n",
    "                    'Radius(2)>MT', 'Mass(1)<MT', 'Mass(2)<MT', 'Mass(1)>MT', 'Mass(2)>MT','Stellar_Type(1)<MT', 'Stellar_Type(2)<MT', \n",
    "                    'Stellar_Type(1)>MT', 'Stellar_Type(2)>MT', 'MT_Event_Counter', 'CEE>MT', 'RLOF(1)>MT', 'RLOF(2)>MT', 'Merger']\n",
    "        for key in RLOF_keys:\n",
    "            read_data = All_data['BSE_RLOF'][key][()]\n",
    "            RLOF[key] = read_data[RLOF_mask]\n",
    "        print('add a few extra cols to RLOF')\n",
    "        RLOF['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(RLOF['SEED'], RLOF['Metallicity@ZAMS(1)'])]\n",
    "        RLOF['M1_M2<MT'] = RLOF['Mass(1)<MT']/RLOF['Mass(2)<MT'].astype(float)\n",
    "        RLOF.rename(columns={'Merger': 'RLOF_Merger'}, inplace=True) # rename so it wont conflict with the SYS['Merger']\n",
    "\n",
    "\n",
    "    ########################################################################################\n",
    "    # Now make subselections of this RLOF table that we can later add to the potential DCO progenitors table\n",
    "    # first_RLOF_table    = first_RLOF_table.add_prefix('firstMT_')                                               # Add prefix to all the keys\n",
    "    # first_RLOF_table.rename(columns={'firstMT_unique_Z_SEED': 'unique_Z_SEED'}, inplace=True)                   # Except the unique_Z_SEED\n",
    "    ################################\n",
    "    # First MT event\n",
    "    print('Adding the MT information for the first MT ')\n",
    "    first_MT_event_bool = RLOF['MT_Event_Counter'] == 1\n",
    "    first_RLOF_table    = RLOF[first_MT_event_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'first MT' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_RLOF_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################\n",
    "    # mass transfer that lead to a merger\n",
    "    print('Adding the MT information for the mass transfer that lead to a merger')\n",
    "    RLOF_Merger_bool            = RLOF['RLOF_Merger'] == 1\n",
    "    MT_leading_to_merger_table  = RLOF[RLOF_Merger_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'mass transfer leading to stellar merger' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(MT_leading_to_merger_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################################################\n",
    "    # First mass transfer from the second star\n",
    "    print('Adding the MT information for the first MT from star 2')\n",
    "    star_2_is_RLOF              = RLOF['RLOF(2)>MT'] == 1 # Star 2 is RLOF\n",
    "    star_2_is_RLOF_table        = RLOF[star_2_is_RLOF]\n",
    "\n",
    "    # Find the minimum 'MT_Event_Counter' for each 'unique_Z_SEED' where Star 2 is RLOF\n",
    "    Minimun_MT_event_count_bool = np.where(star_2_is_RLOF_table['MT_Event_Counter'] == star_2_is_RLOF_table.groupby('unique_Z_SEED')['MT_Event_Counter'].transform('min'), True, False)\n",
    "    first_MT_from_star2_table   = star_2_is_RLOF_table[Minimun_MT_event_count_bool].copy()\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_MT_from_star2_table.rename(columns={col: 'star2_firstMT_' + col for col in first_MT_from_star2_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # lastly, the first MT from star 2 should also only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_MT_from_star2_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ########################\n",
    "    # Empty RLOF to save mem\n",
    "    del RLOF\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    print('start merging tables')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_RLOF_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_RLOF_table')\n",
    "    del first_RLOF_table # to save memory\n",
    "    # Merge info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(MT_leading_to_merger_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with MT_leading_to_merger_table')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_MT_from_star2_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_MT_from_star2_table')\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with MT info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "Adding the SN information\n",
      "Done!, Saving the potential DCO progenitors with SN info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/3203042940.py:66: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors_Allinfo.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors_RLOFinfo.h5', key='All_DCO')\n",
    "\n",
    "    # Initialize a list to store all SEEDS that ever become a DCO\n",
    "    All_DCO_seeds = []\n",
    "    \n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "        # Get the seeds that ever become a DCO\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\") \n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "    #################################################################################\n",
    "    # Finally, add supernove information\n",
    "    print('Adding the SN information')\n",
    "    with h5.File(datar_root+f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:        \n",
    "        # Read SN info as pandas dataframes\n",
    "        SNe = pd.DataFrame()\n",
    "        \n",
    "        # Select only the SN events for systems that could potentially become a DCO\n",
    "        SN_mask = np.in1d(All_data['BSE_Supernovae']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "        SN_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'SN_Type(SN)', 'Supernova_State']\n",
    "        for key in SN_keys_of_interest:\n",
    "            read_data   = All_data['BSE_Supernovae'][key][()]\n",
    "            SNe[key]    = read_data[SN_mask]\n",
    "\n",
    "        #Add unique seed key\n",
    "        SNe['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(SNe['SEED'], SNe['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # # Star 1 is going SN\n",
    "    # star1_SN = SNe[SNe['Supernova_State'] == 1]\n",
    "    # # Star 2 is going SN\n",
    "    # star2_SN = SNe[SNe['Supernova_State'] == 2]\n",
    "    \n",
    "    # Add the SN info to the potential DCO progenitors\n",
    "    potential_DCO_progenitors['SN_Type(1)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 1].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "    potential_DCO_progenitors['SN_Type(2)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 2].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "\n",
    "    del SNe # empty SNe to save memory\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with SN info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, split your potential DCO table between potential BBH, BHNS and NSNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(datar_root+f'{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "    DCO = All_data['BSE_Double_Compact_Objects']\n",
    "    st1 = DCO['Stellar_Type(1)'][()]\n",
    "    st2 = DCO['Stellar_Type(2)'][()]\n",
    "    dco_merger = DCO['Merges_Hubble_Time'][()]  \n",
    "    DCO_seed = DCO['SEED'][()]\n",
    "    # Now I want to add a bool that tells me if this system is ever a BBH, BHNS or BNS progenitor\n",
    "    BBH_bool = np.logical_and(st1 == 14,st2 == 14)\n",
    "    BHNS_bool = np.logical_or(np.logical_and(st1 == 13,st2 == 14),\n",
    "                            np.logical_and(st1 == 14,st2 == 13) )\n",
    "    NSNS_bool = np.logical_and(st1 == 13,st2 == 13)\n",
    "    merger_bool = dco_merger == 1\n",
    "\n",
    "    # Split our potential DCO progenitors into BBH, BHNS and NSNS progenitors\n",
    "    potential_BBH_progenitors  = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BBH_bool*merger_bool]) )]\n",
    "    potential_BHNS_progenitors = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BHNS_bool*merger_bool]) )]\n",
    "    potential_NSNS_progenitors = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[NSNS_bool*merger_bool]) )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
