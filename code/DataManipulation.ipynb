{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "\n",
    "Read the full COMPAS data, and extract only the information that you need (specifically only the systems that are every a DCO)\n",
    "\n",
    "Then we want to add relevant information about the system in the following cases:\n",
    "\n",
    " * The first mass transfer that the binary engaged in\n",
    " * The first mass transfer that star 2 engaged in\n",
    " * The mass transfer that lead to a stellar merger (if any)\n",
    " * The supernova information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "home_dir = os.path.expanduser(\"~\") \n",
    "compas_v = \"v03.01.02\" #\"v02.46.01/\"#v02.35.02/\"\n",
    "datar_root =  f\"{home_dir}/ceph/CompasOutput/{compas_v}/\"\n",
    "\n",
    "sim_name =  'NewWinds_RemFryer2012'#'OldWinds_RemFryer2012'#  \n",
    "\n",
    "######################################\n",
    "## PLOT setttings\n",
    "plt.rc('font', family='serif')\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "fsize, SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = 30,20,25,30\n",
    "for obj in ['axes','xtick','ytick']:\n",
    "    plt.rc(obj, labelsize=SMALL_SIZE)          # controls default text sizes\n",
    "for obj in ['figure','axes']:\n",
    "    plt.rc(obj, titlesize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "\n",
    "# Turn off natural name warning for panda tables (this is due to '@' and '>' in the COMPAS column names)\n",
    "import warnings\n",
    "from tables import NaturalNameWarning\n",
    "warnings.filterwarnings('ignore', category=NaturalNameWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the potential DCO progenitors\n",
    "\n",
    "Read the full COMPAS data, and extract systems that become a DCO at any of the simulated metallicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from /mnt/home/lvanson/ceph/CompasOutput/v03.01.02//NewWinds_RemFryer2012/\n",
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "All_DCO_seeds [     33     472     494 ... 4999861 4999945 4999991] 46671\n",
      "potential_DCO_seeds [     33     472     494 ... 4999861 4999945 4999991] counts [12 12 12 ... 12 12 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3075344/1037347188.py:71: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors.h5'\n",
    "\n",
    "# Initialize a list to store all SEEDS that ever become a DCO\n",
    "All_DCO_seeds = []\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    print(f'reading from {datar_root}/{sim_name}/')\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\")\n",
    "\n",
    "            # Open the HDF5 file for all systems at a given metallicity\n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "\n",
    "            # Get the seeds that ever become a DCO\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "\n",
    "            # Add them to the list of all DCO seeds\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "    print('All_DCO_seeds', All_DCO_seeds, len(All_DCO_seeds) )\n",
    "\n",
    "    # Open the HDF5 file for all systems at all metallicities (This is heavy on the memory)\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "\n",
    "    # Create a mask to select only the systems that could potentially become a DCO\n",
    "    SYS_mask = np.in1d(All_data['BSE_System_Parameters']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    # Read the HDF5 datasets as pandas dataframes\n",
    "    SYS = pd.DataFrame()\n",
    "    # chosen to allow for rerunning of systems and other interesting parameters\n",
    "    SYS_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Stellar_Type(1)', 'Stellar_Type(2)','CE_Event_Counter', 'Mass@ZAMS(1)', 'Mass@ZAMS(2)','SemiMajorAxis@ZAMS',\n",
    "                            'Merger','Merger_At_Birth','Unbound', 'Immediate_RLOF>CE','Optimistic_CE', 'Applied_Kick_Magnitude(1)', 'Applied_Kick_Magnitude(2)', 'CH_on_MS(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(1)','SN_Kick_Phi(1)','SN_Kick_Theta(1)','SN_Kick_Mean_Anomaly(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(2)','SN_Kick_Phi(2)','SN_Kick_Theta(2)','SN_Kick_Mean_Anomaly(2)' ]\n",
    "    for key in SYS_keys_of_interest:\n",
    "        # You cant directly apply the mask to the HDF5 dataset, so you have to read it first\n",
    "        read_data = All_data['BSE_System_Parameters'][key][()]\n",
    "        SYS[key] = read_data[SYS_mask]\n",
    "\n",
    "    # Same mask for the DCO\n",
    "    DCO_mask = np.in1d(All_data['BSE_Double_Compact_Objects']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    DCO = pd.DataFrame()\n",
    "    DCO_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Merges_Hubble_Time', 'SemiMajorAxis@DCO','Coalescence_Time', 'Eccentricity@DCO', 'MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'Mass(1)', 'Mass(2)']\n",
    "    for key in DCO_keys_of_interest:\n",
    "        read_data = All_data['BSE_Double_Compact_Objects'][key][()]\n",
    "        DCO[key] = read_data[DCO_mask]\n",
    "\n",
    "    # Merge the SYS and DCO dataframes to make potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = SYS.merge(DCO, on=['SEED', 'Metallicity@ZAMS(1)'], how='left')\n",
    "    # Create a unique SEED that is a combination of SEED and metallicity\n",
    "    potential_DCO_progenitors['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(potential_DCO_progenitors['SEED'], potential_DCO_progenitors['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # test that this worked (every seed should occur 7 times, once for each Z)\n",
    "    potential_DCO_seeds, counts = np.unique(potential_DCO_progenitors['SEED'], return_counts=True)\n",
    "    print('potential_DCO_seeds', potential_DCO_seeds, 'counts', counts)\n",
    "\n",
    "    # Save the total dataframe\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEED</th>\n",
       "      <th>Metallicity@ZAMS(1)</th>\n",
       "      <th>Stellar_Type(1)</th>\n",
       "      <th>Stellar_Type(2)</th>\n",
       "      <th>CE_Event_Counter</th>\n",
       "      <th>Mass@ZAMS(1)</th>\n",
       "      <th>Mass@ZAMS(2)</th>\n",
       "      <th>SemiMajorAxis@ZAMS</th>\n",
       "      <th>Merger</th>\n",
       "      <th>Merger_At_Birth</th>\n",
       "      <th>...</th>\n",
       "      <th>SN_Kick_Mean_Anomaly(2)</th>\n",
       "      <th>Merges_Hubble_Time</th>\n",
       "      <th>SemiMajorAxis@DCO</th>\n",
       "      <th>Coalescence_Time</th>\n",
       "      <th>Eccentricity@DCO</th>\n",
       "      <th>MT_Donor_Hist(1)</th>\n",
       "      <th>MT_Donor_Hist(2)</th>\n",
       "      <th>Mass(1)</th>\n",
       "      <th>Mass(2)</th>\n",
       "      <th>unique_Z_SEED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4500388</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>48.307774</td>\n",
       "      <td>48.307774</td>\n",
       "      <td>0.071733</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.705172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500388_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4500405</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>49.636229</td>\n",
       "      <td>38.079249</td>\n",
       "      <td>0.170808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500405_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4500671</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>80.160161</td>\n",
       "      <td>80.160161</td>\n",
       "      <td>0.114802</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.301214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500671_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4500877</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>72.662111</td>\n",
       "      <td>69.938701</td>\n",
       "      <td>0.462166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.243619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839567</td>\n",
       "      <td>771284.181589</td>\n",
       "      <td>0.703032</td>\n",
       "      <td>b'1-2             '</td>\n",
       "      <td>b'2               '</td>\n",
       "      <td>17.534156</td>\n",
       "      <td>25.474271</td>\n",
       "      <td>4500877_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4500908</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>47.439012</td>\n",
       "      <td>38.575968</td>\n",
       "      <td>0.243410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500908_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560047</th>\n",
       "      <td>4812024</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.465246</td>\n",
       "      <td>109.170748</td>\n",
       "      <td>0.168447</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4812024_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560048</th>\n",
       "      <td>4812159</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>79.924891</td>\n",
       "      <td>24.764897</td>\n",
       "      <td>0.729994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.890759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466207</td>\n",
       "      <td>667980.850334</td>\n",
       "      <td>0.599241</td>\n",
       "      <td>b'2               '</td>\n",
       "      <td>b'1-2             '</td>\n",
       "      <td>31.982269</td>\n",
       "      <td>4.153385</td>\n",
       "      <td>4812159_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560049</th>\n",
       "      <td>4812205</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13.050822</td>\n",
       "      <td>12.872051</td>\n",
       "      <td>11.785939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.255288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4812205_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560050</th>\n",
       "      <td>4812316</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13.506336</td>\n",
       "      <td>13.051983</td>\n",
       "      <td>9.999071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.150467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4812316_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560051</th>\n",
       "      <td>4812472</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.480496</td>\n",
       "      <td>67.072790</td>\n",
       "      <td>0.263646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.848027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4812472_0.00010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560052 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SEED  Metallicity@ZAMS(1)  Stellar_Type(1)  Stellar_Type(2)  \\\n",
       "0       4500388             0.014142               16               16   \n",
       "1       4500405             0.014142               14                2   \n",
       "2       4500671             0.014142               16               16   \n",
       "3       4500877             0.014142               14               14   \n",
       "4       4500908             0.014142               14               14   \n",
       "...         ...                  ...              ...              ...   \n",
       "560047  4812024             0.000100                1                1   \n",
       "560048  4812159             0.000100               14               14   \n",
       "560049  4812205             0.000100               13               13   \n",
       "560050  4812316             0.000100               13               13   \n",
       "560051  4812472             0.000100                1                1   \n",
       "\n",
       "        CE_Event_Counter  Mass@ZAMS(1)  Mass@ZAMS(2)  SemiMajorAxis@ZAMS  \\\n",
       "0                      0     48.307774     48.307774            0.071733   \n",
       "1                      1     49.636229     38.079249            0.170808   \n",
       "2                      0     80.160161     80.160161            0.114802   \n",
       "3                      0     72.662111     69.938701            0.462166   \n",
       "4                      0     47.439012     38.575968            0.243410   \n",
       "...                  ...           ...           ...                 ...   \n",
       "560047                 1    131.465246    109.170748            0.168447   \n",
       "560048                 0     79.924891     24.764897            0.729994   \n",
       "560049                 0     13.050822     12.872051           11.785939   \n",
       "560050                 0     13.506336     13.051983            9.999071   \n",
       "560051                 1     67.480496     67.072790            0.263646   \n",
       "\n",
       "        Merger  Merger_At_Birth  ...  SN_Kick_Mean_Anomaly(2)  \\\n",
       "0            1                1  ...                 2.705172   \n",
       "1            1                0  ...                 0.644230   \n",
       "2            1                1  ...                 5.301214   \n",
       "3            0                0  ...                 3.243619   \n",
       "4            0                0  ...                 1.001612   \n",
       "...        ...              ...  ...                      ...   \n",
       "560047       1                0  ...                 3.162670   \n",
       "560048       0                0  ...                 1.890759   \n",
       "560049       0                0  ...                 2.255288   \n",
       "560050       0                0  ...                 6.150467   \n",
       "560051       1                0  ...                 1.848027   \n",
       "\n",
       "        Merges_Hubble_Time  SemiMajorAxis@DCO  Coalescence_Time  \\\n",
       "0                      NaN                NaN               NaN   \n",
       "1                      NaN                NaN               NaN   \n",
       "2                      NaN                NaN               NaN   \n",
       "3                      0.0           0.839567     771284.181589   \n",
       "4                      NaN                NaN               NaN   \n",
       "...                    ...                ...               ...   \n",
       "560047                 NaN                NaN               NaN   \n",
       "560048                 0.0           0.466207     667980.850334   \n",
       "560049                 NaN                NaN               NaN   \n",
       "560050                 NaN                NaN               NaN   \n",
       "560051                 NaN                NaN               NaN   \n",
       "\n",
       "        Eccentricity@DCO     MT_Donor_Hist(1)     MT_Donor_Hist(2)    Mass(1)  \\\n",
       "0                    NaN                  NaN                  NaN        NaN   \n",
       "1                    NaN                  NaN                  NaN        NaN   \n",
       "2                    NaN                  NaN                  NaN        NaN   \n",
       "3               0.703032  b'1-2             '  b'2               '  17.534156   \n",
       "4                    NaN                  NaN                  NaN        NaN   \n",
       "...                  ...                  ...                  ...        ...   \n",
       "560047               NaN                  NaN                  NaN        NaN   \n",
       "560048          0.599241  b'2               '  b'1-2             '  31.982269   \n",
       "560049               NaN                  NaN                  NaN        NaN   \n",
       "560050               NaN                  NaN                  NaN        NaN   \n",
       "560051               NaN                  NaN                  NaN        NaN   \n",
       "\n",
       "          Mass(2)    unique_Z_SEED  \n",
       "0             NaN  4500388_0.01414  \n",
       "1             NaN  4500405_0.01414  \n",
       "2             NaN  4500671_0.01414  \n",
       "3       25.474271  4500877_0.01414  \n",
       "4             NaN  4500908_0.01414  \n",
       "...           ...              ...  \n",
       "560047        NaN  4812024_0.00010  \n",
       "560048   4.153385  4812159_0.00010  \n",
       "560049        NaN  4812205_0.00010  \n",
       "560050        NaN  4812316_0.00010  \n",
       "560051        NaN  4812472_0.00010  \n",
       "\n",
       "[560052 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(potential_DCO_progenitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we add the RLOF information to the potential DCO progenitor table\n",
    "\n",
    "Use the above created table to start from and add\n",
    "* mass transfer 1\n",
    "* First MT from star 2\n",
    "* the mass transfer that lead to a merger\n",
    "\n",
    "### And in the end also supernova information \n",
    "\n",
    "#####  'Supernova_State'\n",
    "*  No supernova = 0 \n",
    "*  Star 1 is the supernova \t = 1 \n",
    "*  Star 2 is the supernova \t = 2 \n",
    "*  Both stars are supernovae \t = 3\n",
    "\n",
    "##### 'SN_Type(SN)'\n",
    "*  NONE \t = 0 \n",
    "*  CCSN \t = 1 \n",
    "*  ECSN \t = 2 \n",
    "*  PISN \t = 4 \n",
    "*  PPISN \t = 8 \n",
    "*  USSN \t = 16 \n",
    "*  AIC \t     = 32 \n",
    "*  SNIA \t = 64 \n",
    "*  HeSD \t = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "start reading RLOF data\n",
      "add a few extra cols to RLOF\n",
      "Adding the MT information for the first MT \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3075344/356593650.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n",
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3075344/356593650.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "start merging tables\n",
      "done with first_RLOF_table\n",
      "done with MT_leading_to_merger_table\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3075344/356593650.py:121: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors_RLOFinfo.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors.h5', key='All_DCO')\n",
    "\n",
    "    # Initialize a list to store all SEEDS that ever become a DCO\n",
    "    All_DCO_seeds = []\n",
    "\n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "        # Get the seeds that ever become a DCO\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\") \n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    with h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "        ####################################\n",
    "        # Read RLOF data\n",
    "        RLOF = pd.DataFrame()\n",
    "        # Select only the RLOF events for systems that could potentially become a DCO\n",
    "        RLOF_mask = np.in1d(All_data['BSE_RLOF']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "        ########################################################################################\n",
    "        # Create the new RLOF columns in the potential DCO progenitors table\n",
    "        print('start reading RLOF data')\n",
    "        RLOF_keys = ['SEED', 'Metallicity@ZAMS(1)','SemiMajorAxis<MT', 'SemiMajorAxis>MT', 'Radius(1)<MT', 'Radius(2)<MT', 'Radius(1)>MT', \n",
    "                    'Radius(2)>MT', 'Mass(1)<MT', 'Mass(2)<MT', 'Mass(1)>MT', 'Mass(2)>MT','Stellar_Type(1)<MT', 'Stellar_Type(2)<MT', \n",
    "                    'Stellar_Type(1)>MT', 'Stellar_Type(2)>MT', 'MT_Event_Counter', 'CEE>MT', 'RLOF(1)>MT', 'RLOF(2)>MT', 'Merger']\n",
    "        for key in RLOF_keys:\n",
    "            read_data = All_data['BSE_RLOF'][key][()]\n",
    "            RLOF[key] = read_data[RLOF_mask]\n",
    "        print('add a few extra cols to RLOF')\n",
    "        RLOF['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(RLOF['SEED'], RLOF['Metallicity@ZAMS(1)'])]\n",
    "        RLOF['M1_M2<MT'] = RLOF['Mass(1)<MT']/RLOF['Mass(2)<MT'].astype(float)\n",
    "        RLOF.rename(columns={'Merger': 'RLOF_Merger'}, inplace=True) # rename so it wont conflict with the SYS['Merger']\n",
    "\n",
    "\n",
    "    ########################################################################################\n",
    "    # Now make subselections of this RLOF table that we can later add to the potential DCO progenitors table\n",
    "    # first_RLOF_table    = first_RLOF_table.add_prefix('firstMT_')                                               # Add prefix to all the keys\n",
    "    # first_RLOF_table.rename(columns={'firstMT_unique_Z_SEED': 'unique_Z_SEED'}, inplace=True)                   # Except the unique_Z_SEED\n",
    "    ################################\n",
    "    # First MT event\n",
    "    print('Adding the MT information for the first MT ')\n",
    "    first_MT_event_bool = RLOF['MT_Event_Counter'] == 1\n",
    "    first_RLOF_table    = RLOF[first_MT_event_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'first MT' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_RLOF_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################\n",
    "    # mass transfer that lead to a merger\n",
    "    print('Adding the MT information for the mass transfer that lead to a merger')\n",
    "    RLOF_Merger_bool            = RLOF['RLOF_Merger'] == 1\n",
    "    MT_leading_to_merger_table  = RLOF[RLOF_Merger_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'mass transfer leading to stellar merger' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(MT_leading_to_merger_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################################################\n",
    "    # First mass transfer from the second star\n",
    "    print('Adding the MT information for the first MT from star 2')\n",
    "    star_2_is_RLOF              = RLOF['RLOF(2)>MT'] == 1 # Star 2 is RLOF\n",
    "    star_2_is_RLOF_table        = RLOF[star_2_is_RLOF]\n",
    "\n",
    "    # Find the minimum 'MT_Event_Counter' for each 'unique_Z_SEED' where Star 2 is RLOF\n",
    "    Minimun_MT_event_count_bool = np.where(star_2_is_RLOF_table['MT_Event_Counter'] == star_2_is_RLOF_table.groupby('unique_Z_SEED')['MT_Event_Counter'].transform('min'), True, False)\n",
    "    first_MT_from_star2_table   = star_2_is_RLOF_table[Minimun_MT_event_count_bool].copy()\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_MT_from_star2_table.rename(columns={col: 'star2_firstMT_' + col for col in first_MT_from_star2_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # lastly, the first MT from star 2 should also only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_MT_from_star2_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ########################\n",
    "    # Empty RLOF to save mem\n",
    "    del RLOF\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    print('start merging tables')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_RLOF_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_RLOF_table')\n",
    "    del first_RLOF_table # to save memory\n",
    "    # Merge info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(MT_leading_to_merger_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with MT_leading_to_merger_table')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_MT_from_star2_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_MT_from_star2_table')\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with MT info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "Adding the SN information\n",
      "Done!, Saving the potential DCO progenitors with SN info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3075344/3203042940.py:66: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors_Allinfo.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors_RLOFinfo.h5', key='All_DCO')\n",
    "\n",
    "    # Initialize a list to store all SEEDS that ever become a DCO\n",
    "    All_DCO_seeds = []\n",
    "    \n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "        # Get the seeds that ever become a DCO\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\") \n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "    #################################################################################\n",
    "    # Finally, add supernove information\n",
    "    print('Adding the SN information')\n",
    "    with h5.File(datar_root+f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:        \n",
    "        # Read SN info as pandas dataframes\n",
    "        SNe = pd.DataFrame()\n",
    "        \n",
    "        # Select only the SN events for systems that could potentially become a DCO\n",
    "        SN_mask = np.in1d(All_data['BSE_Supernovae']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "        SN_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'SN_Type(SN)', 'Supernova_State']\n",
    "        for key in SN_keys_of_interest:\n",
    "            read_data   = All_data['BSE_Supernovae'][key][()]\n",
    "            SNe[key]    = read_data[SN_mask]\n",
    "\n",
    "        #Add unique seed key\n",
    "        SNe['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(SNe['SEED'], SNe['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # # Star 1 is going SN\n",
    "    # star1_SN = SNe[SNe['Supernova_State'] == 1]\n",
    "    # # Star 2 is going SN\n",
    "    # star2_SN = SNe[SNe['Supernova_State'] == 2]\n",
    "    \n",
    "    # Add the SN info to the potential DCO progenitors\n",
    "    potential_DCO_progenitors['SN_Type(1)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 1].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "    potential_DCO_progenitors['SN_Type(2)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 2].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "\n",
    "    del SNe # empty SNe to save memory\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with SN info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, split your potential DCO table between potential BBH, BHNS and NSNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(datar_root+f'{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "    DCO = All_data['BSE_Double_Compact_Objects']\n",
    "    st1 = DCO['Stellar_Type(1)'][()]\n",
    "    st2 = DCO['Stellar_Type(2)'][()]\n",
    "    dco_merger = DCO['Merges_Hubble_Time'][()]  \n",
    "    DCO_seed = DCO['SEED'][()]\n",
    "    # Now I want to add a bool that tells me if this system is ever a BBH, BHNS or BNS progenitor\n",
    "    BBH_bool = np.logical_and(st1 == 14,st2 == 14)\n",
    "    BHNS_bool = np.logical_or(np.logical_and(st1 == 13,st2 == 14),\n",
    "                            np.logical_and(st1 == 14,st2 == 13) )\n",
    "    NSNS_bool = np.logical_and(st1 == 13,st2 == 13)\n",
    "    merger_bool = dco_merger == 1\n",
    "\n",
    "    # Split our potential DCO progenitors into BBH, BHNS and NSNS progenitors\n",
    "    potential_BBH_progenitors  = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BBH_bool*merger_bool]) )]\n",
    "    potential_BHNS_progenitors = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BHNS_bool*merger_bool]) )]\n",
    "    potential_NSNS_progenitors = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[NSNS_bool*merger_bool]) )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
