{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "\n",
    "Read the full COMPAS data, and extract only the information that you need (specifically only the systems that are every a DCO)\n",
    "\n",
    "Then we want to add relevant information about the system in the following cases:\n",
    "\n",
    " * The first mass transfer that the binary engaged in\n",
    " * The first mass transfer that star 2 engaged in\n",
    " * The mass transfer that lead to a stellar merger (if any)\n",
    " * The supernova information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import gc\n",
    "\n",
    "import multiprocessing\n",
    "import importlib\n",
    "import DataManipulation\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(DataManipulation)\n",
    "\n",
    "# Turn off natural name warning for panda tables (this is due to '@' and '>' in the COMPAS column names)\n",
    "import warnings\n",
    "from tables import NaturalNameWarning\n",
    "warnings.filterwarnings('ignore', category=NaturalNameWarning)\n",
    "\n",
    "\n",
    "######################################\n",
    "home_dir = os.path.expanduser(\"~\") \n",
    "compas_v = \"v03.01.02\" #\"v02.46.01/\"#v02.35.02/\"\n",
    "datar_root =  f\"{home_dir}/ceph/CompasOutput/{compas_v}/\"\n",
    "\n",
    "sim_name =  'NewWinds_RemFryer2012'#'OldWinds_RemFryer2012'#  \n",
    "\n",
    "# do you only want to select a certain formation channel? \n",
    "channel_key     = '_CE' #'_stable' # '_CE' '_CHE'  '' \n",
    "\n",
    "######################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Data Manipulation using the overall python script\n",
    "this script follows the same steps as below, but it is easier to multiprocess the total python script\n",
    "\n",
    "-- it takes about 10 min to run the full 'DataManipulation' script that extracts all the potential DCO information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential_DCO_progenitors.h5potential_DCO_progenitors_CHE.h5potential_DCO_progenitors_CE.h5potential_DCO_progenitors_stable.h5\n",
      "\n",
      "\n",
      "\n",
      "reading from /mnt/home/lvanson/ceph/CompasOutput/v03.01.02//NewWinds_RemFryer2012_extremeWRwinds/\n",
      "reading from /mnt/home/lvanson/ceph/CompasOutput/v03.01.02//NewWinds_RemFryer2012_extremeWRwinds/\n",
      "reading from /mnt/home/lvanson/ceph/CompasOutput/v03.01.02//NewWinds_RemFryer2012_extremeWRwinds/\n",
      "reading from /mnt/home/lvanson/ceph/CompasOutput/v03.01.02//NewWinds_RemFryer2012_extremeWRwinds/\n",
      "Reading DCO seeds from logZ-1.85Reading DCO seeds from logZ-1.85Reading DCO seeds from logZ-1.85\n",
      "\n",
      "\n",
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-2.4Reading DCO seeds from logZ-2.4\n",
      "\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-1.7Reading DCO seeds from logZ-1.7\n",
      "\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-2.7Reading DCO seeds from logZ-2.7\n",
      "\n",
      "Reading DCO seeds from logZ-3.52Reading DCO seeds from logZ-3.52\n",
      "\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.0Reading DCO seeds from logZ-2.0\n",
      "\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "Reading DCO seeds from logZ-4.0\n",
      "Reading DCO seeds from logZ-4.0Reading DCO seeds from logZ-4.0\n",
      "\n",
      "potential_DCO_seeds [     33     613     891 ... 4998990 4999038 4999945] counts [12 12 12 ... 12 12 12]\n",
      "potential_DCO_seeds [     66     472     494 ... 4999193 4999836 4999991] counts [12 12 12 ... 12 12 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:142: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:142: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the DCO seeds\n",
      "potential_DCO_seeds [     55     270     519 ... 4999879 4999905 4999942] counts [12 12 12 ... 12 12 12]\n",
      "Loading the DCO seeds\n",
      "potential_DCO_seeds [     33      55      66 ... 4999942 4999945 4999991] counts [12 12 12 ... 12 12 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:142: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the DCO seeds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:142: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the DCO seeds\n",
      "start reading RLOF data\n",
      "start reading RLOF data\n",
      "start reading RLOF data\n",
      "start reading RLOF data\n",
      "add a few extra cols to RLOF\n",
      "add a few extra cols to RLOF\n",
      "add a few extra cols to RLOF\n",
      "add a few extra cols to RLOF\n",
      "Adding the MT information for the first MT \n",
      "Adding the MT information for the first MT \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:209: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:209: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:222: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n",
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:222: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "start merging tables\n",
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n",
      "done with first_RLOF_table\n",
      "done with MT_leading_to_merger_table\n",
      "this should be 1 [1]\n",
      "start merging tables\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n",
      "done with first_RLOF_table\n",
      "Adding the MT information for the first MT \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:265: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:209: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:222: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n",
      "done with MT_leading_to_merger_table\n",
      "Loading the DCO seeds\n",
      "Adding the SN information\n",
      "this should be 1 [1]\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n",
      "start merging tables\n",
      "done with first_RLOF_table\n",
      "done with MT_leading_to_merger_table\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n",
      "Adding the MT information for the first MT \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:209: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:265: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n",
      "Loading the DCO seeds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:222: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the SN information\n",
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:265: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Loading the DCO seeds\n",
      "start merging tables\n",
      "Adding the SN information\n",
      "done with first_RLOF_table\n",
      "done with MT_leading_to_merger_table\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:265: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the DCO seeds\n",
      "Adding the SN information\n",
      "Done!, Saving the potential DCO progenitors with SN info\n",
      "Done!, Saving the potential DCO progenitors with SN info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:345: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!, Saving the potential DCO progenitors with SN info\n",
      "Finished with NewWinds_RemFryer2012_extremeWRwinds,  _CHE \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:345: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!, Saving the potential DCO progenitors with SN info\n",
      "Finished with NewWinds_RemFryer2012_extremeWRwinds,  _stable \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:345: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with NewWinds_RemFryer2012_extremeWRwinds,  _CE \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lvanson/ZdependentFormEff/code/DataManipulation.py:345: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with NewWinds_RemFryer2012_extremeWRwinds,   \n"
     ]
    }
   ],
   "source": [
    "from DataManipulation import main\n",
    "\n",
    "# Define your sim_name and channel_key options to vary over\n",
    "sim_names = ['NewWinds_RemFryer2012_extremeWRwinds']\n",
    "    # 'NewWinds_RemFryer2012', 'OldWinds_RemFryer2012', 'NewWinds_RemMullerMandel', 'NewWinds_RemFryer2012_noBHkick', 'NewWinds_RemFryer2012_noNSBHkick',\\\n",
    "    # #  'NewWinds_RemFryer2012_noWRwinds', 'NewWinds_RemFryer2012_noMSwinds', 'RemFryer2012_NOwinds','NewWinds_RemFryer2012_WRBELCZYNSKI2010', 'NewWinds_RemFryer2012_noCHE'] \n",
    "\n",
    "channel_keys = ['', '_stable', '_CE',  '_CHE'] #'_stable', '_CE',  '_CHE'  ''\n",
    "\n",
    "# Define a function that takes two arguments and calls main with the other argument constant\n",
    "def main_wrapper(sim_name, channel_key):\n",
    "    return main(sim_name = sim_name, channel_key = channel_key, compas_v = 'v03.01.02')\n",
    "\n",
    "# Create a pool of processes\n",
    "with multiprocessing.Pool() as pool:\n",
    "    # For each sim_name\n",
    "    for sim_name in sim_names:\n",
    "        # Apply main_wrapper to every channel_key\n",
    "        pool.starmap(main_wrapper, [(sim_name, key) for key in channel_keys])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the potential DCO progenitors\n",
    "\n",
    "Read the full COMPAS data, and extract systems that become a DCO at any of the simulated metallicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential_DCO_progenitors_CHE.h5\n",
      "reading from /mnt/home/lvanson/ceph/CompasOutput/v03.01.02//OldWinds_RemFryer2012_noBHkick/\n",
      "Reading DCO seeds from logZ-1.85\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'CH_on_MS(1)' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m     channel_bool        \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogical_and(CE_Event_Counter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, CHE_in_DCO \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m ) \u001b[38;5;66;03m# Common envelope and non-CHE\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m channel_key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_CHE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 53\u001b[0m     CHE_bool            \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBSE_Double_Compact_Objects\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH_on_MS(1)\u001b[39m\u001b[38;5;124m'\u001b[39m][()])\n\u001b[1;32m     54\u001b[0m     channel_bool        \u001b[38;5;241m=\u001b[39m CHE_in_DCO \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/b4q5asj8flwlgmaijgj1r6wbmnls5x8k-python-3.9.15-view/lib/python3.9/site-packages/h5py/_hl/group.py:328\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 328\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:190\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'CH_on_MS(1)' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "save_name_table = f'potential_DCO_progenitors{channel_key}.h5'\n",
    "print(save_name_table)\n",
    "\n",
    "# Initialize a list to store all SEEDS that ever become a DCO\n",
    "All_DCO_seeds = []\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    print(f'reading from {datar_root}/{sim_name}/')\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\")\n",
    "\n",
    "            # Open the HDF5 file for all systems at a given metallicity\n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "\n",
    "            # Get the seeds that ever become a DCO\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "\n",
    "            # Simple case: you want all DCOs\n",
    "            if channel_key == '':\n",
    "                channel_bool = np.ones_like(DCO_seeds, dtype=bool)\n",
    "            \n",
    "            # Add extra constraints based on the channel you are interested in\n",
    "            else:\n",
    "                # I didn't save the CHE bool in most variations :(\n",
    "                try: \n",
    "                    CHE_in_DCO = data['BSE_Double_Compact_Objects']['CH_on_MS(1)'][()]      \n",
    "                except:          \n",
    "                    # Create a mask to map between the DCO seeds and the seeds in the system parameters\n",
    "                    SYS_SEED            = data['BSE_System_Parameters']['SEED'][()]\n",
    "                    SYS_DCO_mask        = np.in1d(SYS_SEED, DCO_seeds)\n",
    "                    #print('SAFETY CHECK FOR THE IN1D SEED COUPLING: ', np.nonzero(np.array(SYS_SEED[SYS_DCO_mask]).flatten() - np.array(DCO_seeds).flatten()) )\n",
    "\n",
    "                    CHE_bool            = data['BSE_System_Parameters']['CH_on_MS(1)'][()]\n",
    "                    CHE_in_DCO          = CHE_bool[SYS_DCO_mask]\n",
    "\n",
    "                if channel_key == '_stable':\n",
    "                    CE_Event_Counter    = pd.Series(data['BSE_Double_Compact_Objects']['CE_Event_Counter'][()])\n",
    "                    channel_bool        = np.logical_and(CE_Event_Counter == 0, CHE_in_DCO == 0 ) # stable and non-CHE\n",
    "\n",
    "                elif channel_key == '_CE':\n",
    "                    CE_Event_Counter    = pd.Series(data['BSE_Double_Compact_Objects']['CE_Event_Counter'][()])\n",
    "                    channel_bool        = np.logical_and(CE_Event_Counter > 0, CHE_in_DCO == 0 ) # Common envelope and non-CHE\n",
    "\n",
    "                elif channel_key == '_CHE':\n",
    "                    channel_bool        = CHE_in_DCO == 1\n",
    "\n",
    "                else:\n",
    "                    raise Exception(f'Unknown channel key {channel_key}')\n",
    "\n",
    "                # Add them to the list of all DCO seeds\n",
    "                All_DCO_seeds.extend(DCO_seeds[channel_bool])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "    print(f'for {channel_key}, All_DCO_seeds', All_DCO_seeds, len(All_DCO_seeds) )\n",
    "    # Save the seeds to a file\n",
    "    np.savetxt(datar_root+ f'/{sim_name}/All_DCO_seeds{channel_key}.txt', All_DCO_seeds)\n",
    "\n",
    "    # Open the HDF5 file for all systems at all metallicities (This is heavy on the memory)\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "\n",
    "    # Create a mask to select only the systems that could potentially become a DCO\n",
    "    SYS_mask = np.in1d(All_data['BSE_System_Parameters']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    # Read the HDF5 datasets as pandas dataframes\n",
    "    SYS = pd.DataFrame()\n",
    "    # chosen to allow for rerunning of systems and other interesting parameters\n",
    "    SYS_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Stellar_Type(1)', 'Stellar_Type(2)','CE_Event_Counter', 'Mass@ZAMS(1)', 'Mass@ZAMS(2)','SemiMajorAxis@ZAMS',\n",
    "                            'Merger','Merger_At_Birth','Unbound', 'Immediate_RLOF>CE','Optimistic_CE', 'Applied_Kick_Magnitude(1)', 'Applied_Kick_Magnitude(2)', 'CH_on_MS(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(1)','SN_Kick_Phi(1)','SN_Kick_Theta(1)','SN_Kick_Mean_Anomaly(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(2)','SN_Kick_Phi(2)','SN_Kick_Theta(2)','SN_Kick_Mean_Anomaly(2)' ]\n",
    "    for key in SYS_keys_of_interest:\n",
    "        # You cant directly apply the mask to the HDF5 dataset, so you have to read it first\n",
    "        read_data = All_data['BSE_System_Parameters'][key][()]\n",
    "        SYS[key] = read_data[SYS_mask]\n",
    "\n",
    "    # Same mask for the DCO \n",
    "    DCO_mask = np.in1d(All_data['BSE_Double_Compact_Objects']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    DCO = pd.DataFrame()\n",
    "    DCO_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Merges_Hubble_Time', 'SemiMajorAxis@DCO','Coalescence_Time', 'Eccentricity@DCO', 'MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'Mass(1)', 'Mass(2)']\n",
    "    for key in DCO_keys_of_interest:\n",
    "        read_data = All_data['BSE_Double_Compact_Objects'][key][()]\n",
    "        DCO[key] = read_data[DCO_mask]\n",
    "\n",
    "    # Merge the SYS and DCO dataframes to make potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = SYS.merge(DCO, on=['SEED', 'Metallicity@ZAMS(1)'], how='left')\n",
    "    # Create a unique SEED that is a combination of SEED and metallicity\n",
    "    potential_DCO_progenitors['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(potential_DCO_progenitors['SEED'], potential_DCO_progenitors['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # test that this worked (every seed should occur len(metallicity) times, once for each Z)\n",
    "    potential_DCO_seeds, counts = np.unique(potential_DCO_progenitors['SEED'], return_counts=True)\n",
    "    print('potential_DCO_seeds', potential_DCO_seeds, 'counts', counts)\n",
    "\n",
    "    # Save the total dataframe\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we add the RLOF information to the potential DCO progenitor table\n",
    "\n",
    "Use the above created table to start from and add\n",
    "* mass transfer 1\n",
    "* First MT from star 2\n",
    "* the mass transfer that lead to a merger\n",
    "\n",
    "### And in the end also supernova information \n",
    "\n",
    "#####  'Supernova_State'\n",
    "*  No supernova = 0 \n",
    "*  Star 1 is the supernova \t = 1 \n",
    "*  Star 2 is the supernova \t = 2 \n",
    "*  Both stars are supernovae \t = 3\n",
    "\n",
    "##### 'SN_Type(SN)'\n",
    "*  NONE \t = 0 \n",
    "*  CCSN \t = 1 \n",
    "*  ECSN \t = 2 \n",
    "*  PISN \t = 4 \n",
    "*  PPISN \t = 8 \n",
    "*  USSN \t = 16 \n",
    "*  AIC \t     = 32 \n",
    "*  SNIA \t = 64 \n",
    "*  HeSD \t = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the DCO seeds\n",
      "start reading RLOF data\n",
      "add a few extra cols to RLOF\n",
      "Adding the MT information for the first MT \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875379/1571146138.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875379/1571146138.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n",
      "this should be 1 [1]\n",
      "start merging tables\n",
      "done with first_RLOF_table\n",
      "done with MT_leading_to_merger_table\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875379/1571146138.py:124: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = f'potential_DCO_progenitors_RLOFinfo{channel_key}.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors.h5', key='All_DCO')\n",
    "\n",
    "    # # Initialize a list to store all SEEDS that ever become a DCO\n",
    "    # All_DCO_seeds = []\n",
    "\n",
    "    # # Loop over all directories starting wiht \"logZ\"\n",
    "    # for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "    #     # Get the seeds that ever become a DCO\n",
    "    #     if dir.startswith('logZ'):\n",
    "    #         print(f\"Reading DCO seeds from {dir}\") \n",
    "    #         data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "    #         DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "    #         All_DCO_seeds.extend(DCO_seeds)\n",
    "            \n",
    "    #     else:\n",
    "    #         continue\n",
    "\n",
    "    # # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    # All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "\n",
    "    # Load the DCO seeds\n",
    "    print('Loading the DCO seeds')\n",
    "    All_DCO_seeds = np.loadtxt(datar_root+ f'/{sim_name}/All_DCO_seeds{channel_key}.txt')\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    with h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "        ####################################\n",
    "        # Read RLOF data\n",
    "        RLOF = pd.DataFrame()\n",
    "        # Select only the RLOF events for systems that could potentially become a DCO\n",
    "        RLOF_mask = np.in1d(All_data['BSE_RLOF']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "        ########################################################################################\n",
    "        # Create the new RLOF columns in the potential DCO progenitors table\n",
    "        print('start reading RLOF data')\n",
    "        RLOF_keys = ['SEED', 'Metallicity@ZAMS(1)','SemiMajorAxis<MT', 'SemiMajorAxis>MT', 'Radius(1)<MT', 'Radius(2)<MT', 'Radius(1)>MT', \n",
    "                    'Radius(2)>MT', 'Mass(1)<MT', 'Mass(2)<MT', 'Mass(1)>MT', 'Mass(2)>MT','Stellar_Type(1)<MT', 'Stellar_Type(2)<MT', \n",
    "                    'Stellar_Type(1)>MT', 'Stellar_Type(2)>MT', 'MT_Event_Counter', 'CEE>MT', 'RLOF(1)>MT', 'RLOF(2)>MT', 'Merger']\n",
    "        for key in RLOF_keys:\n",
    "            read_data = All_data['BSE_RLOF'][key][()]\n",
    "            RLOF[key] = read_data[RLOF_mask]\n",
    "        print('add a few extra cols to RLOF')\n",
    "        RLOF['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(RLOF['SEED'], RLOF['Metallicity@ZAMS(1)'])]\n",
    "        RLOF['M1_M2<MT'] = RLOF['Mass(1)<MT']/RLOF['Mass(2)<MT'].astype(float)\n",
    "        RLOF.rename(columns={'Merger': 'RLOF_Merger'}, inplace=True) # rename so it wont conflict with the SYS['Merger']\n",
    "\n",
    "\n",
    "    ########################################################################################\n",
    "    # Now make subselections of this RLOF table that we can later add to the potential DCO progenitors table\n",
    "    # first_RLOF_table    = first_RLOF_table.add_prefix('firstMT_')                                               # Add prefix to all the keys\n",
    "    # first_RLOF_table.rename(columns={'firstMT_unique_Z_SEED': 'unique_Z_SEED'}, inplace=True)                   # Except the unique_Z_SEED\n",
    "    ################################\n",
    "    # First MT event\n",
    "    print('Adding the MT information for the first MT ')\n",
    "    first_MT_event_bool = RLOF['MT_Event_Counter'] == 1\n",
    "    first_RLOF_table    = RLOF[first_MT_event_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'first MT' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_RLOF_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################\n",
    "    # mass transfer that lead to a merger\n",
    "    print('Adding the MT information for the mass transfer that lead to a merger')\n",
    "    RLOF_Merger_bool            = RLOF['RLOF_Merger'] == 1\n",
    "    MT_leading_to_merger_table  = RLOF[RLOF_Merger_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'mass transfer leading to stellar merger' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(MT_leading_to_merger_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################################################\n",
    "    # First mass transfer from the second star\n",
    "    print('Adding the MT information for the first MT from star 2')\n",
    "    star_2_is_RLOF              = RLOF['RLOF(2)>MT'] == 1 # Star 2 is RLOF\n",
    "    star_2_is_RLOF_table        = RLOF[star_2_is_RLOF]\n",
    "\n",
    "    # Find the minimum 'MT_Event_Counter' for each 'unique_Z_SEED' where Star 2 is RLOF\n",
    "    Minimun_MT_event_count_bool = np.where(star_2_is_RLOF_table['MT_Event_Counter'] == star_2_is_RLOF_table.groupby('unique_Z_SEED')['MT_Event_Counter'].transform('min'), True, False)\n",
    "    first_MT_from_star2_table   = star_2_is_RLOF_table[Minimun_MT_event_count_bool].copy()\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_MT_from_star2_table.rename(columns={col: 'star2_firstMT_' + col for col in first_MT_from_star2_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # lastly, the first MT from star 2 should also only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_MT_from_star2_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ########################\n",
    "    # Empty RLOF to save mem\n",
    "    del RLOF\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    print('start merging tables')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_RLOF_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_RLOF_table')\n",
    "    del first_RLOF_table # to save memory\n",
    "    # Merge info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(MT_leading_to_merger_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with MT_leading_to_merger_table')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_MT_from_star2_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_MT_from_star2_table')\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with MT info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table already exists, loading it\n"
     ]
    }
   ],
   "source": [
    "save_name_table = f'potential_DCO_progenitors_Allinfo{channel_key}.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors_RLOFinfo.h5', key='All_DCO')\n",
    "\n",
    "    # # Initialize a list to store all SEEDS that ever become a DCO\n",
    "    # All_DCO_seeds = []\n",
    "    \n",
    "    # # Loop over all directories starting wiht \"logZ\"\n",
    "    # for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "    #     # Get the seeds that ever become a DCO\n",
    "    #     if dir.startswith('logZ'):\n",
    "    #         print(f\"Reading DCO seeds from {dir}\") \n",
    "    #         data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "    #         DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "    #         All_DCO_seeds.extend(DCO_seeds)\n",
    "            \n",
    "    #     else:\n",
    "    #         continue\n",
    "        \n",
    "    \n",
    "    # # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    # All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "    # Load the DCO seeds\n",
    "    print('Loading the DCO seeds')\n",
    "    All_DCO_seeds = np.loadtxt(datar_root+ f'/{sim_name}/All_DCO_seeds{channel_key}.txt')\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "    #################################################################################\n",
    "    # Finally, add supernove information\n",
    "    print('Adding the SN information')\n",
    "    with h5.File(datar_root+f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:        \n",
    "        # Read SN info as pandas dataframes\n",
    "        SNe = pd.DataFrame()\n",
    "        \n",
    "        # Select only the SN events for systems that could potentially become a DCO\n",
    "        SN_mask = np.in1d(All_data['BSE_Supernovae']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "        SN_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'SN_Type(SN)', 'Supernova_State']\n",
    "        for key in SN_keys_of_interest:\n",
    "            read_data   = All_data['BSE_Supernovae'][key][()]\n",
    "            SNe[key]    = read_data[SN_mask]\n",
    "\n",
    "        #Add unique seed key\n",
    "        SNe['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(SNe['SEED'], SNe['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # # Star 1 is going SN\n",
    "    # star1_SN = SNe[SNe['Supernova_State'] == 1]\n",
    "    # # Star 2 is going SN\n",
    "    # star2_SN = SNe[SNe['Supernova_State'] == 2]\n",
    "    \n",
    "    # Add the SN info to the potential DCO progenitors\n",
    "    potential_DCO_progenitors['SN_Type(1)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 1].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "    potential_DCO_progenitors['SN_Type(2)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 2].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "\n",
    "    del SNe # empty SNe to save memory\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with SN info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, split your potential DCO table between potential BBH, BHNS and NSNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(datar_root+f'{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "    DCO = All_data['BSE_Double_Compact_Objects']\n",
    "    st1 = DCO['Stellar_Type(1)'][()]\n",
    "    st2 = DCO['Stellar_Type(2)'][()]\n",
    "    dco_merger = DCO['Merges_Hubble_Time'][()]  \n",
    "    DCO_seed = DCO['SEED'][()]\n",
    "    # Now I want to add a bool that tells me if this system is ever a BBH, BHNS or BNS progenitor\n",
    "    BBH_bool = np.logical_and(st1 == 14,st2 == 14)\n",
    "    BHNS_bool = np.logical_or(np.logical_and(st1 == 13,st2 == 14),\n",
    "                            np.logical_and(st1 == 14,st2 == 13) )\n",
    "    NSNS_bool = np.logical_and(st1 == 13,st2 == 13)\n",
    "    merger_bool = dco_merger == 1\n",
    "\n",
    "    # Split our potential DCO progenitors into BBH, BHNS and NSNS progenitors\n",
    "    potential_BBH_progenitors  = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BBH_bool*merger_bool]) )]\n",
    "    potential_BHNS_progenitors = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BHNS_bool*merger_bool]) )]\n",
    "    potential_NSNS_progenitors = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[NSNS_bool*merger_bool]) )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 215076 entries, 0 to 565040\n",
      "Data columns (total 95 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   SEED                                  215076 non-null  uint64 \n",
      " 1   Metallicity@ZAMS(1)                   215076 non-null  float64\n",
      " 2   Stellar_Type(1)                       215076 non-null  int32  \n",
      " 3   Stellar_Type(2)                       215076 non-null  int32  \n",
      " 4   CE_Event_Counter                      215076 non-null  uint32 \n",
      " 5   Mass@ZAMS(1)                          215076 non-null  float64\n",
      " 6   Mass@ZAMS(2)                          215076 non-null  float64\n",
      " 7   SemiMajorAxis@ZAMS                    215076 non-null  float64\n",
      " 8   Merger                                215076 non-null  uint8  \n",
      " 9   Merger_At_Birth                       215076 non-null  uint8  \n",
      " 10  Unbound                               215076 non-null  uint8  \n",
      " 11  Immediate_RLOF>CE                     215076 non-null  uint8  \n",
      " 12  Optimistic_CE                         215076 non-null  uint8  \n",
      " 13  Applied_Kick_Magnitude(1)             215076 non-null  float64\n",
      " 14  Applied_Kick_Magnitude(2)             215076 non-null  float64\n",
      " 15  CH_on_MS(1)                           215076 non-null  uint8  \n",
      " 16  SN_Kick_Magnitude_Random_Number(1)    215076 non-null  float64\n",
      " 17  SN_Kick_Phi(1)                        215076 non-null  float64\n",
      " 18  SN_Kick_Theta(1)                      215076 non-null  float64\n",
      " 19  SN_Kick_Mean_Anomaly(1)               215076 non-null  float64\n",
      " 20  SN_Kick_Magnitude_Random_Number(2)    215076 non-null  float64\n",
      " 21  SN_Kick_Phi(2)                        215076 non-null  float64\n",
      " 22  SN_Kick_Theta(2)                      215076 non-null  float64\n",
      " 23  SN_Kick_Mean_Anomaly(2)               215076 non-null  float64\n",
      " 24  Merges_Hubble_Time                    62313 non-null   float64\n",
      " 25  SemiMajorAxis@DCO                     62313 non-null   float64\n",
      " 26  Coalescence_Time                      62313 non-null   float64\n",
      " 27  Eccentricity@DCO                      62313 non-null   float64\n",
      " 28  MT_Donor_Hist(1)                      62313 non-null   object \n",
      " 29  MT_Donor_Hist(2)                      62313 non-null   object \n",
      " 30  Mass(1)                               62313 non-null   float64\n",
      " 31  Mass(2)                               62313 non-null   float64\n",
      " 32  unique_Z_SEED                         215076 non-null  object \n",
      " 33  firstMT_SemiMajorAxis<MT              144333 non-null  float64\n",
      " 34  firstMT_SemiMajorAxis>MT              144331 non-null  float64\n",
      " 35  firstMT_Radius(1)<MT                  144333 non-null  float64\n",
      " 36  firstMT_Radius(2)<MT                  144333 non-null  float64\n",
      " 37  firstMT_Radius(1)>MT                  144333 non-null  float64\n",
      " 38  firstMT_Radius(2)>MT                  144333 non-null  float64\n",
      " 39  firstMT_Mass(1)<MT                    144333 non-null  float64\n",
      " 40  firstMT_Mass(2)<MT                    144333 non-null  float64\n",
      " 41  firstMT_Mass(1)>MT                    144333 non-null  float64\n",
      " 42  firstMT_Mass(2)>MT                    144333 non-null  float64\n",
      " 43  firstMT_Stellar_Type(1)<MT            144333 non-null  float64\n",
      " 44  firstMT_Stellar_Type(2)<MT            144333 non-null  float64\n",
      " 45  firstMT_Stellar_Type(1)>MT            144333 non-null  float64\n",
      " 46  firstMT_Stellar_Type(2)>MT            144333 non-null  float64\n",
      " 47  firstMT_MT_Event_Counter              144333 non-null  float64\n",
      " 48  firstMT_CEE>MT                        144333 non-null  float64\n",
      " 49  firstMT_RLOF(1)>MT                    144333 non-null  float64\n",
      " 50  firstMT_RLOF(2)>MT                    144333 non-null  float64\n",
      " 51  firstMT_RLOF_Merger                   144333 non-null  float64\n",
      " 52  firstMT_M1_M2<MT                      144331 non-null  float64\n",
      " 53  MT_lead_to_merger_SemiMajorAxis<MT    39310 non-null   float64\n",
      " 54  MT_lead_to_merger_SemiMajorAxis>MT    39310 non-null   float64\n",
      " 55  MT_lead_to_merger_Radius(1)<MT        39310 non-null   float64\n",
      " 56  MT_lead_to_merger_Radius(2)<MT        39310 non-null   float64\n",
      " 57  MT_lead_to_merger_Radius(1)>MT        39310 non-null   float64\n",
      " 58  MT_lead_to_merger_Radius(2)>MT        39310 non-null   float64\n",
      " 59  MT_lead_to_merger_Mass(1)<MT          39310 non-null   float64\n",
      " 60  MT_lead_to_merger_Mass(2)<MT          39310 non-null   float64\n",
      " 61  MT_lead_to_merger_Mass(1)>MT          39310 non-null   float64\n",
      " 62  MT_lead_to_merger_Mass(2)>MT          39310 non-null   float64\n",
      " 63  MT_lead_to_merger_Stellar_Type(1)<MT  39310 non-null   float64\n",
      " 64  MT_lead_to_merger_Stellar_Type(2)<MT  39310 non-null   float64\n",
      " 65  MT_lead_to_merger_Stellar_Type(1)>MT  39310 non-null   float64\n",
      " 66  MT_lead_to_merger_Stellar_Type(2)>MT  39310 non-null   float64\n",
      " 67  MT_lead_to_merger_MT_Event_Counter    39310 non-null   float64\n",
      " 68  MT_lead_to_merger_CEE>MT              39310 non-null   float64\n",
      " 69  MT_lead_to_merger_RLOF(1)>MT          39310 non-null   float64\n",
      " 70  MT_lead_to_merger_RLOF(2)>MT          39310 non-null   float64\n",
      " 71  MT_lead_to_merger_RLOF_Merger         39310 non-null   float64\n",
      " 72  MT_lead_to_merger_M1_M2<MT            39310 non-null   float64\n",
      " 73  star2_firstMT_SemiMajorAxis<MT        103202 non-null  float64\n",
      " 74  star2_firstMT_SemiMajorAxis>MT        103200 non-null  float64\n",
      " 75  star2_firstMT_Radius(1)<MT            103202 non-null  float64\n",
      " 76  star2_firstMT_Radius(2)<MT            103202 non-null  float64\n",
      " 77  star2_firstMT_Radius(1)>MT            103202 non-null  float64\n",
      " 78  star2_firstMT_Radius(2)>MT            103202 non-null  float64\n",
      " 79  star2_firstMT_Mass(1)<MT              103202 non-null  float64\n",
      " 80  star2_firstMT_Mass(2)<MT              103202 non-null  float64\n",
      " 81  star2_firstMT_Mass(1)>MT              103202 non-null  float64\n",
      " 82  star2_firstMT_Mass(2)>MT              103202 non-null  float64\n",
      " 83  star2_firstMT_Stellar_Type(1)<MT      103202 non-null  float64\n",
      " 84  star2_firstMT_Stellar_Type(2)<MT      103202 non-null  float64\n",
      " 85  star2_firstMT_Stellar_Type(1)>MT      103202 non-null  float64\n",
      " 86  star2_firstMT_Stellar_Type(2)>MT      103202 non-null  float64\n",
      " 87  star2_firstMT_MT_Event_Counter        103202 non-null  float64\n",
      " 88  star2_firstMT_CEE>MT                  103202 non-null  float64\n",
      " 89  star2_firstMT_RLOF(1)>MT              103202 non-null  float64\n",
      " 90  star2_firstMT_RLOF(2)>MT              103202 non-null  float64\n",
      " 91  star2_firstMT_RLOF_Merger             103202 non-null  float64\n",
      " 92  star2_firstMT_M1_M2<MT                103200 non-null  float64\n",
      " 93  SN_Type(1)                            215076 non-null  float64\n",
      " 94  SN_Type(2)                            215076 non-null  float64\n",
      "dtypes: float64(82), int32(2), object(3), uint32(1), uint64(1), uint8(6)\n",
      "memory usage: 146.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(potential_BBH_progenitors.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
