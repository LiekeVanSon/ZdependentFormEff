{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "\n",
    "Read the full COMPAS data, and extract only the information that you need (specifically only the systems that are every a DCO)\n",
    "\n",
    "Then we want to add relevant information about the system in the following cases:\n",
    "\n",
    " * The first mass transfer that the binary engaged in\n",
    " * The first mass transfer that star 2 engaged in\n",
    " * The mass transfer that lead to a stellar merger (if any)\n",
    " * The supernova information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "home_dir = os.path.expanduser(\"~\") \n",
    "datar_root = home_dir + \"/ceph/CompasOutput/v02.46.01/\" #v02.35.02/\"\n",
    "sim_name =  'OldWinds_RemFryer2012_noBHkick'#'OldWinds_RemFryer2012'#  \n",
    "\n",
    "######################################\n",
    "## PLOT setttings\n",
    "plt.rc('font', family='serif')\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "fsize, SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = 30,20,25,30\n",
    "for obj in ['axes','xtick','ytick']:\n",
    "    plt.rc(obj, labelsize=SMALL_SIZE)          # controls default text sizes\n",
    "for obj in ['figure','axes']:\n",
    "    plt.rc(obj, titlesize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "\n",
    "# Turn off natural name warning for panda tables (this is due to '@' and '>' in the COMPAS column names)\n",
    "import warnings\n",
    "from tables import NaturalNameWarning\n",
    "warnings.filterwarnings('ignore', category=NaturalNameWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the potential DCO progenitors\n",
    "\n",
    "Read the full COMPAS data, and extract systems that become a DCO at any of the simulated metallicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from /mnt/home/lvanson/ceph/CompasOutput/v02.46.01//OldWinds_RemFryer2012_noBHkick/\n",
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "All_DCO_seeds [    15     18     30 ... 999985 999995 999999] 64026\n",
      "potential_DCO_seeds [    15     18     30 ... 999985 999995 999999] counts [12 12 12 ... 12 12 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/263237746.py:72: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors.h5'\n",
    "\n",
    "\n",
    "# Initialize a list to store all SEEDS that ever become a DCO\n",
    "All_DCO_seeds = []\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    print(f'reading from {datar_root}/{sim_name}/')\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\")\n",
    "\n",
    "            # Open the HDF5 file for all systems at a given metallicity\n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "\n",
    "            # Get the seeds that ever become a DCO\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "\n",
    "            # Add them to the list of all DCO seeds\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "    print('All_DCO_seeds', All_DCO_seeds, len(All_DCO_seeds) )\n",
    "\n",
    "    # Open the HDF5 file for all systems at all metallicities (This is heavy on the memory)\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "\n",
    "    # Create a mask to select only the systems that could potentially become a DCO\n",
    "    SYS_mask = np.in1d(All_data['BSE_System_Parameters']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    # Read the HDF5 datasets as pandas dataframes\n",
    "    SYS = pd.DataFrame()\n",
    "    # chosen to allow for rerunning of systems and other interesting parameters\n",
    "    SYS_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Stellar_Type(1)', 'Stellar_Type(2)','CE_Event_Counter', 'Mass@ZAMS(1)', 'Mass@ZAMS(2)','SemiMajorAxis@ZAMS',\n",
    "                            'Merger','Merger_At_Birth','Unbound', 'Immediate_RLOF>CE','Optimistic_CE', 'Applied_Kick_Magnitude(1)', 'Applied_Kick_Magnitude(2)', 'CH_on_MS(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(1)','SN_Kick_Phi(1)','SN_Kick_Theta(1)','SN_Kick_Mean_Anomaly(1)',\n",
    "                            'SN_Kick_Magnitude_Random_Number(2)','SN_Kick_Phi(2)','SN_Kick_Theta(2)','SN_Kick_Mean_Anomaly(2)' ]\n",
    "    for key in SYS_keys_of_interest:\n",
    "        # You cant directly apply the mask to the HDF5 dataset, so you have to read it first\n",
    "        read_data = All_data['BSE_System_Parameters'][key][()]\n",
    "        SYS[key] = read_data[SYS_mask]\n",
    "\n",
    "    # Same mask for the DCO\n",
    "    DCO_mask = np.in1d(All_data['BSE_Double_Compact_Objects']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "    DCO = pd.DataFrame()\n",
    "    DCO_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'Merges_Hubble_Time', 'SemiMajorAxis@DCO','Coalescence_Time', 'Eccentricity@DCO', 'MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'Mass(1)', 'Mass(2)']\n",
    "    for key in DCO_keys_of_interest:\n",
    "        read_data = All_data['BSE_Double_Compact_Objects'][key][()]\n",
    "        DCO[key] = read_data[DCO_mask]\n",
    "\n",
    "    # Merge the SYS and DCO dataframes to make potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = SYS.merge(DCO, on=['SEED', 'Metallicity@ZAMS(1)'], how='left')\n",
    "    # Create a unique SEED that is a combination of SEED and metallicity\n",
    "    potential_DCO_progenitors['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(potential_DCO_progenitors['SEED'], potential_DCO_progenitors['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # test that this worked (every seed should occur 7 times, once for each Z)\n",
    "    potential_DCO_seeds, counts = np.unique(potential_DCO_progenitors['SEED'], return_counts=True)\n",
    "    print('potential_DCO_seeds', potential_DCO_seeds, 'counts', counts)\n",
    "\n",
    "    # Save the total dataframe\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEED</th>\n",
       "      <th>Metallicity@ZAMS(1)</th>\n",
       "      <th>Stellar_Type(1)</th>\n",
       "      <th>Stellar_Type(2)</th>\n",
       "      <th>CE_Event_Counter</th>\n",
       "      <th>Mass@ZAMS(1)</th>\n",
       "      <th>Mass@ZAMS(2)</th>\n",
       "      <th>SemiMajorAxis@ZAMS</th>\n",
       "      <th>Merger</th>\n",
       "      <th>Merger_At_Birth</th>\n",
       "      <th>...</th>\n",
       "      <th>SN_Kick_Mean_Anomaly(2)</th>\n",
       "      <th>Merges_Hubble_Time</th>\n",
       "      <th>SemiMajorAxis@DCO</th>\n",
       "      <th>Coalescence_Time</th>\n",
       "      <th>Eccentricity@DCO</th>\n",
       "      <th>MT_Donor_Hist(1)</th>\n",
       "      <th>MT_Donor_Hist(2)</th>\n",
       "      <th>Mass(1)</th>\n",
       "      <th>Mass(2)</th>\n",
       "      <th>unique_Z_SEED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900023</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>47.897158</td>\n",
       "      <td>32.368349</td>\n",
       "      <td>2.595920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.606319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.149012</td>\n",
       "      <td>4.947119e+08</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>b'2               '</td>\n",
       "      <td>b'2               '</td>\n",
       "      <td>9.400702</td>\n",
       "      <td>6.331269</td>\n",
       "      <td>900023_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900034</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>33.115931</td>\n",
       "      <td>26.689699</td>\n",
       "      <td>15.581657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.543176</td>\n",
       "      <td>2.089996e+17</td>\n",
       "      <td>0.440750</td>\n",
       "      <td>b'4               '</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>5.998917</td>\n",
       "      <td>6.031777</td>\n",
       "      <td>900034_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900037</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>35.490032</td>\n",
       "      <td>19.946880</td>\n",
       "      <td>219.979280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.253111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2081.122354</td>\n",
       "      <td>6.791244e+20</td>\n",
       "      <td>0.747955</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>9.117844</td>\n",
       "      <td>4.223612</td>\n",
       "      <td>900037_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900046</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>43.425875</td>\n",
       "      <td>23.965251</td>\n",
       "      <td>4.743468</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015941</td>\n",
       "      <td>7.938333e+01</td>\n",
       "      <td>0.372979</td>\n",
       "      <td>b'2               '</td>\n",
       "      <td>b'4               '</td>\n",
       "      <td>7.531063</td>\n",
       "      <td>2.134204</td>\n",
       "      <td>900046_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900054</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>62.503296</td>\n",
       "      <td>32.489124</td>\n",
       "      <td>299.607511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1174.879387</td>\n",
       "      <td>1.755978e+20</td>\n",
       "      <td>0.128822</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>16.872008</td>\n",
       "      <td>7.899542</td>\n",
       "      <td>900054_0.01414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768307</th>\n",
       "      <td>824894</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>58.799119</td>\n",
       "      <td>57.500724</td>\n",
       "      <td>289.947497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.137539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.612430</td>\n",
       "      <td>2.730432e+18</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>24.503266</td>\n",
       "      <td>23.877479</td>\n",
       "      <td>824894_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768308</th>\n",
       "      <td>824903</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>45.447621</td>\n",
       "      <td>38.437686</td>\n",
       "      <td>0.785057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.803550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.482618</td>\n",
       "      <td>2.255250e+09</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>b'2               '</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>16.665591</td>\n",
       "      <td>28.166040</td>\n",
       "      <td>824903_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768309</th>\n",
       "      <td>824971</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>26.082112</td>\n",
       "      <td>17.207498</td>\n",
       "      <td>875.562949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14133.468770</td>\n",
       "      <td>6.587642e+21</td>\n",
       "      <td>0.935865</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>17.274452</td>\n",
       "      <td>4.332580</td>\n",
       "      <td>824971_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768310</th>\n",
       "      <td>824972</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>46.147422</td>\n",
       "      <td>23.919990</td>\n",
       "      <td>6.300153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.278903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.924272</td>\n",
       "      <td>6.852835e+13</td>\n",
       "      <td>0.172584</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>b'5               '</td>\n",
       "      <td>18.466046</td>\n",
       "      <td>5.111758</td>\n",
       "      <td>824972_0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768311</th>\n",
       "      <td>824981</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>19.055846</td>\n",
       "      <td>15.589171</td>\n",
       "      <td>171.281888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1609.186429</td>\n",
       "      <td>3.617415e+20</td>\n",
       "      <td>0.790638</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>b'NA              '</td>\n",
       "      <td>6.926427</td>\n",
       "      <td>2.912496</td>\n",
       "      <td>824981_0.00010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768312 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SEED  Metallicity@ZAMS(1)  Stellar_Type(1)  Stellar_Type(2)  \\\n",
       "0       900023             0.014142               14               14   \n",
       "1       900034             0.014142               14               14   \n",
       "2       900037             0.014142               14               14   \n",
       "3       900046             0.014142               14               13   \n",
       "4       900054             0.014142               14               14   \n",
       "...        ...                  ...              ...              ...   \n",
       "768307  824894             0.000100               14               14   \n",
       "768308  824903             0.000100               14               14   \n",
       "768309  824971             0.000100               14               14   \n",
       "768310  824972             0.000100               14               14   \n",
       "768311  824981             0.000100               14               14   \n",
       "\n",
       "        CE_Event_Counter  Mass@ZAMS(1)  Mass@ZAMS(2)  SemiMajorAxis@ZAMS  \\\n",
       "0                      0     47.897158     32.368349            2.595920   \n",
       "1                      0     33.115931     26.689699           15.581657   \n",
       "2                      0     35.490032     19.946880          219.979280   \n",
       "3                      1     43.425875     23.965251            4.743468   \n",
       "4                      0     62.503296     32.489124          299.607511   \n",
       "...                  ...           ...           ...                 ...   \n",
       "768307                 0     58.799119     57.500724          289.947497   \n",
       "768308                 0     45.447621     38.437686            0.785057   \n",
       "768309                 0     26.082112     17.207498          875.562949   \n",
       "768310                 0     46.147422     23.919990            6.300153   \n",
       "768311                 0     19.055846     15.589171          171.281888   \n",
       "\n",
       "        Merger  Merger_At_Birth  ...  SN_Kick_Mean_Anomaly(2)  \\\n",
       "0            0                0  ...                 2.606319   \n",
       "1            0                0  ...                 0.573541   \n",
       "2            0                0  ...                 6.253111   \n",
       "3            0                0  ...                 0.885482   \n",
       "4            0                0  ...                 0.112864   \n",
       "...        ...              ...  ...                      ...   \n",
       "768307       0                0  ...                 5.137539   \n",
       "768308       0                0  ...                 2.803550   \n",
       "768309       0                0  ...                 0.108075   \n",
       "768310       0                0  ...                 3.278903   \n",
       "768311       0                0  ...                 1.589654   \n",
       "\n",
       "        Merges_Hubble_Time  SemiMajorAxis@DCO  Coalescence_Time  \\\n",
       "0                      0.0           1.149012      4.947119e+08   \n",
       "1                      0.0         156.543176      2.089996e+17   \n",
       "2                      0.0        2081.122354      6.791244e+20   \n",
       "3                      1.0           0.015941      7.938333e+01   \n",
       "4                      0.0        1174.879387      1.755978e+20   \n",
       "...                    ...                ...               ...   \n",
       "768307                 0.0         699.612430      2.730432e+18   \n",
       "768308                 0.0           3.482618      2.255250e+09   \n",
       "768309                 0.0       14133.468770      6.587642e+21   \n",
       "768310                 0.0          26.924272      6.852835e+13   \n",
       "768311                 0.0        1609.186429      3.617415e+20   \n",
       "\n",
       "        Eccentricity@DCO     MT_Donor_Hist(1)     MT_Donor_Hist(2)    Mass(1)  \\\n",
       "0               0.232158  b'2               '  b'2               '   9.400702   \n",
       "1               0.440750  b'4               '  b'NA              '   5.998917   \n",
       "2               0.747955  b'NA              '  b'NA              '   9.117844   \n",
       "3               0.372979  b'2               '  b'4               '   7.531063   \n",
       "4               0.128822  b'NA              '  b'NA              '  16.872008   \n",
       "...                  ...                  ...                  ...        ...   \n",
       "768307          0.003468  b'NA              '  b'NA              '  24.503266   \n",
       "768308          0.001167  b'2               '  b'NA              '  16.665591   \n",
       "768309          0.935865  b'NA              '  b'NA              '  17.274452   \n",
       "768310          0.172584  b'NA              '  b'5               '  18.466046   \n",
       "768311          0.790638  b'NA              '  b'NA              '   6.926427   \n",
       "\n",
       "          Mass(2)   unique_Z_SEED  \n",
       "0        6.331269  900023_0.01414  \n",
       "1        6.031777  900034_0.01414  \n",
       "2        4.223612  900037_0.01414  \n",
       "3        2.134204  900046_0.01414  \n",
       "4        7.899542  900054_0.01414  \n",
       "...           ...             ...  \n",
       "768307  23.877479  824894_0.00010  \n",
       "768308  28.166040  824903_0.00010  \n",
       "768309   4.332580  824971_0.00010  \n",
       "768310   5.111758  824972_0.00010  \n",
       "768311   2.912496  824981_0.00010  \n",
       "\n",
       "[768312 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(potential_DCO_progenitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we add the RLOF information to the potential DCO progenitor table\n",
    "\n",
    "Use the above created table to start from and add\n",
    "* mass transfer 1\n",
    "* First MT from star 2\n",
    "* the mass transfer that lead to a merger\n",
    "\n",
    "### And in the end also supernova information \n",
    "\n",
    "#####  'Supernova_State'\n",
    "*  No supernova = 0 \n",
    "*  Star 1 is the supernova \t = 1 \n",
    "*  Star 2 is the supernova \t = 2 \n",
    "*  Both stars are supernovae \t = 3\n",
    "\n",
    "##### 'SN_Type(SN)'\n",
    "*  NONE \t = 0 \n",
    "*  CCSN \t = 1 \n",
    "*  ECSN \t = 2 \n",
    "*  PISN \t = 4 \n",
    "*  PPISN \t = 8 \n",
    "*  USSN \t = 16 \n",
    "*  AIC \t     = 32 \n",
    "*  SNIA \t = 64 \n",
    "*  HeSD \t = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "start reading RLOF data\n",
      "add a few extra cols to RLOF\n",
      "Adding the MT information for the first MT \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/356593650.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the mass transfer that lead to a merger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/356593650.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be 1 [1]\n",
      "Adding the MT information for the first MT from star 2\n",
      "this should be 1 [1]\n",
      "start merging tables\n",
      "done with first_RLOF_table\n",
      "done with MT_leading_to_merger_table\n",
      "done with first_MT_from_star2_table\n",
      "Done!, Saving the potential DCO progenitors with MT info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/356593650.py:121: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors_RLOFinfo.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors.h5', key='All_DCO')\n",
    "\n",
    "    # Initialize a list to store all SEEDS that ever become a DCO\n",
    "    All_DCO_seeds = []\n",
    "\n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "        # Get the seeds that ever become a DCO\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\") \n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "\n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    with h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "        ####################################\n",
    "        # Read RLOF data\n",
    "        RLOF = pd.DataFrame()\n",
    "        # Select only the RLOF events for systems that could potentially become a DCO\n",
    "        RLOF_mask = np.in1d(All_data['BSE_RLOF']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "        ########################################################################################\n",
    "        # Create the new RLOF columns in the potential DCO progenitors table\n",
    "        print('start reading RLOF data')\n",
    "        RLOF_keys = ['SEED', 'Metallicity@ZAMS(1)','SemiMajorAxis<MT', 'SemiMajorAxis>MT', 'Radius(1)<MT', 'Radius(2)<MT', 'Radius(1)>MT', \n",
    "                    'Radius(2)>MT', 'Mass(1)<MT', 'Mass(2)<MT', 'Mass(1)>MT', 'Mass(2)>MT','Stellar_Type(1)<MT', 'Stellar_Type(2)<MT', \n",
    "                    'Stellar_Type(1)>MT', 'Stellar_Type(2)>MT', 'MT_Event_Counter', 'CEE>MT', 'RLOF(1)>MT', 'RLOF(2)>MT', 'Merger']\n",
    "        for key in RLOF_keys:\n",
    "            read_data = All_data['BSE_RLOF'][key][()]\n",
    "            RLOF[key] = read_data[RLOF_mask]\n",
    "        print('add a few extra cols to RLOF')\n",
    "        RLOF['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(RLOF['SEED'], RLOF['Metallicity@ZAMS(1)'])]\n",
    "        RLOF['M1_M2<MT'] = RLOF['Mass(1)<MT']/RLOF['Mass(2)<MT'].astype(float)\n",
    "        RLOF.rename(columns={'Merger': 'RLOF_Merger'}, inplace=True) # rename so it wont conflict with the SYS['Merger']\n",
    "\n",
    "\n",
    "    ########################################################################################\n",
    "    # Now make subselections of this RLOF table that we can later add to the potential DCO progenitors table\n",
    "    # first_RLOF_table    = first_RLOF_table.add_prefix('firstMT_')                                               # Add prefix to all the keys\n",
    "    # first_RLOF_table.rename(columns={'firstMT_unique_Z_SEED': 'unique_Z_SEED'}, inplace=True)                   # Except the unique_Z_SEED\n",
    "    ################################\n",
    "    # First MT event\n",
    "    print('Adding the MT information for the first MT ')\n",
    "    first_MT_event_bool = RLOF['MT_Event_Counter'] == 1\n",
    "    first_RLOF_table    = RLOF[first_MT_event_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_RLOF_table.rename(columns={col: 'firstMT_' + col for col in first_RLOF_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'first MT' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_RLOF_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################\n",
    "    # mass transfer that lead to a merger\n",
    "    print('Adding the MT information for the mass transfer that lead to a merger')\n",
    "    RLOF_Merger_bool            = RLOF['RLOF_Merger'] == 1\n",
    "    MT_leading_to_merger_table  = RLOF[RLOF_Merger_bool]\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    MT_leading_to_merger_table.rename(columns={col: 'MT_lead_to_merger_' + col for col in MT_leading_to_merger_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # a 'mass transfer leading to stellar merger' should only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(MT_leading_to_merger_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ################################################################\n",
    "    # First mass transfer from the second star\n",
    "    print('Adding the MT information for the first MT from star 2')\n",
    "    star_2_is_RLOF              = RLOF['RLOF(2)>MT'] == 1 # Star 2 is RLOF\n",
    "    star_2_is_RLOF_table        = RLOF[star_2_is_RLOF]\n",
    "\n",
    "    # Find the minimum 'MT_Event_Counter' for each 'unique_Z_SEED' where Star 2 is RLOF\n",
    "    Minimun_MT_event_count_bool = np.where(star_2_is_RLOF_table['MT_Event_Counter'] == star_2_is_RLOF_table.groupby('unique_Z_SEED')['MT_Event_Counter'].transform('min'), True, False)\n",
    "    first_MT_from_star2_table   = star_2_is_RLOF_table[Minimun_MT_event_count_bool].copy()\n",
    "\n",
    "    # Add prefix to all the keys, Except 'SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'\n",
    "    first_MT_from_star2_table.rename(columns={col: 'star2_firstMT_' + col for col in first_MT_from_star2_table.columns if col not in ['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED']}, inplace=True)\n",
    "\n",
    "    # lastly, the first MT from star 2 should also only happen once per unique_Z_SEED\n",
    "    s, counts = np.unique(first_MT_from_star2_table['unique_Z_SEED'], return_counts = True)\n",
    "    print('this should be 1', np.unique(counts))\n",
    "\n",
    "    ########################\n",
    "    # Empty RLOF to save mem\n",
    "    del RLOF\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    print('start merging tables')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_RLOF_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_RLOF_table')\n",
    "    del first_RLOF_table # to save memory\n",
    "    # Merge info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(MT_leading_to_merger_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with MT_leading_to_merger_table')\n",
    "    # Merge this info with the potential_DCO_progenitors\n",
    "    potential_DCO_progenitors = potential_DCO_progenitors.merge(first_MT_from_star2_table, on=['SEED', 'Metallicity@ZAMS(1)', 'unique_Z_SEED'], how='left')\n",
    "    print('done with first_MT_from_star2_table')\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with MT info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DCO seeds from logZ-1.85\n",
      "Reading DCO seeds from logZ-3.26\n",
      "Reading DCO seeds from logZ-1.52\n",
      "Reading DCO seeds from logZ-3.0\n",
      "Reading DCO seeds from logZ-2.4\n",
      "Reading DCO seeds from logZ-1.7\n",
      "Reading DCO seeds from logZ-2.7\n",
      "Reading DCO seeds from logZ-3.52\n",
      "Reading DCO seeds from logZ-3.76\n",
      "Reading DCO seeds from logZ-2.0\n",
      "Reading DCO seeds from logZ-2.2\n",
      "Reading DCO seeds from logZ-4.0\n",
      "Adding the SN information\n",
      "Done!, Saving the potential DCO progenitors with SN info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2622428/3203042940.py:66: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['MT_Donor_Hist(1)', 'MT_Donor_Hist(2)', 'unique_Z_SEED'], dtype='object')]\n",
      "\n",
      "  potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n"
     ]
    }
   ],
   "source": [
    "save_name_table = 'potential_DCO_progenitors_Allinfo.h5'\n",
    "\n",
    "# check if your table exists\n",
    "if os.path.isfile(datar_root+ f'/{sim_name}/{save_name_table}'):\n",
    "    print('Table already exists, loading it')\n",
    "    potential_DCO_progenitors = pd.read_hdf(datar_root + f'/{sim_name}/{save_name_table}', key='All_DCO')\n",
    "\n",
    "else:\n",
    "    # Read the beginning of the potential DCO progenitors table that you made above\n",
    "    potential_DCO_progenitors = pd.read_hdf(f'{datar_root}/{sim_name}/potential_DCO_progenitors_RLOFinfo.h5', key='All_DCO')\n",
    "\n",
    "    # Initialize a list to store all SEEDS that ever become a DCO\n",
    "    All_DCO_seeds = []\n",
    "    \n",
    "    # Loop over all directories starting wiht \"logZ\"\n",
    "    for i, dir in enumerate(os.listdir(datar_root+ f'/{sim_name}/')):\n",
    "        # Get the seeds that ever become a DCO\n",
    "        if dir.startswith('logZ'):\n",
    "            print(f\"Reading DCO seeds from {dir}\") \n",
    "            data = h5.File(datar_root+ f'/{sim_name}/{dir}/COMPAS_Output.h5', 'r')\n",
    "            DCO_seeds = pd.Series(data['BSE_Double_Compact_Objects']['SEED'][()])\n",
    "            All_DCO_seeds.extend(DCO_seeds)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    # take the unique seeds (some SEEDS might make a DCO at multiple metallicities)\n",
    "    All_DCO_seeds  = np.unique(All_DCO_seeds)\n",
    "\n",
    "    # Open the HDF5 file for all systems at a given metallicity\n",
    "    All_data = h5.File(datar_root+ f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r')\n",
    "    #################################################################################\n",
    "    # Finally, add supernove information\n",
    "    print('Adding the SN information')\n",
    "    with h5.File(datar_root+f'/{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:        \n",
    "        # Read SN info as pandas dataframes\n",
    "        SNe = pd.DataFrame()\n",
    "        \n",
    "        # Select only the SN events for systems that could potentially become a DCO\n",
    "        SN_mask = np.in1d(All_data['BSE_Supernovae']['SEED'][()], All_DCO_seeds)\n",
    "\n",
    "        SN_keys_of_interest = ['SEED', 'Metallicity@ZAMS(1)', 'SN_Type(SN)', 'Supernova_State']\n",
    "        for key in SN_keys_of_interest:\n",
    "            read_data   = All_data['BSE_Supernovae'][key][()]\n",
    "            SNe[key]    = read_data[SN_mask]\n",
    "\n",
    "        #Add unique seed key\n",
    "        SNe['unique_Z_SEED'] = [f\"{seed}_{Z:.5f}\" for seed, Z in zip(SNe['SEED'], SNe['Metallicity@ZAMS(1)'])]\n",
    "\n",
    "    # # Star 1 is going SN\n",
    "    # star1_SN = SNe[SNe['Supernova_State'] == 1]\n",
    "    # # Star 2 is going SN\n",
    "    # star2_SN = SNe[SNe['Supernova_State'] == 2]\n",
    "    \n",
    "    # Add the SN info to the potential DCO progenitors\n",
    "    potential_DCO_progenitors['SN_Type(1)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 1].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "    potential_DCO_progenitors['SN_Type(2)'] = potential_DCO_progenitors['unique_Z_SEED'].map(SNe[SNe['Supernova_State'] == 2].set_index('unique_Z_SEED')['SN_Type(SN)']).fillna(-1)\n",
    "\n",
    "    del SNe # empty SNe to save memory\n",
    "    gc.collect()  # Force garbage collector to release unreferenced memory\n",
    "\n",
    "    #################################################################################\n",
    "    # Save the dataframe\n",
    "    print('Done!, Saving the potential DCO progenitors with SN info')\n",
    "    potential_DCO_progenitors.to_hdf(datar_root+ f'/{sim_name}/{save_name_table}', key='All_DCO', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, split your potential DCO table between potential BBH, BHNS and NSNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(datar_root+f'{sim_name}/COMPAS_Output_combinedZ.h5', 'r') as All_data:\n",
    "    DCO = All_data['BSE_Double_Compact_Objects']\n",
    "    st1 = DCO['Stellar_Type(1)'][()]\n",
    "    st2 = DCO['Stellar_Type(2)'][()]\n",
    "    dco_merger = DCO['Merges_Hubble_Time'][()]  \n",
    "    DCO_seed = DCO['SEED'][()]\n",
    "    # Now I want to add a bool that tells me if this system is ever a BBH, BHNS or BNS progenitor\n",
    "    BBH_bool = np.logical_and(st1 == 14,st2 == 14)\n",
    "    BHNS_bool = np.logical_or(np.logical_and(st1 == 13,st2 == 14),\n",
    "                            np.logical_and(st1 == 14,st2 == 13) )\n",
    "    NSNS_bool = np.logical_and(st1 == 13,st2 == 13)\n",
    "    merger_bool = dco_merger == 1\n",
    "\n",
    "    # Split our potential DCO progenitors into BBH, BHNS and NSNS progenitors\n",
    "    potential_BBH_progenitors  = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BBH_bool*merger_bool]) )]\n",
    "    potential_BHNS_progenitors = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[BHNS_bool*merger_bool]) )]\n",
    "    potential_NSNS_progenitors = potential_DCO_progenitors[np.in1d(potential_DCO_progenitors['SEED'], np.unique(DCO_seed[NSNS_bool*merger_bool]) )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
