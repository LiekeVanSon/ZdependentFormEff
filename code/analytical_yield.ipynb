{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical computation of the Maximum formation efficiency\n",
    "\n",
    "As described in section 2 from the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "import multiprocessing as mp\n",
    "\n",
    "# add run_data path to sys\n",
    "sys.path.append('./run_data')\n",
    "from definitions import sim_flags_dict\n",
    "\n",
    "\n",
    "######################################\n",
    "## PLOT setttings\n",
    "plt.rc('font', family='serif')\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "fsize, SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = 30,20,25,30\n",
    "for obj in ['axes','xtick','ytick']:\n",
    "    plt.rc(obj, labelsize=SMALL_SIZE)          # controls default text sizes\n",
    "for obj in ['figure','axes']:\n",
    "    plt.rc(obj, titlesize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "\n",
    "\n",
    "home_dir    = os.path.expanduser(\"~\") \n",
    "compas_v    = \"v03.01.02\" #\"v02.46.01\" # #\"#v02.35.02/\"\n",
    "datar_root  =  f\"{home_dir}/ceph/CompasOutput/{compas_v}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the average SF mass per system\n",
    "\n",
    "We use the 'total mass evolved per Z' function that we also use for the yield calculations for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def totalMassEvolvedPerZ(pathCOMPASh5, x2=0.08, x3=0.5, a1=-0.3, a2=-1.3, a3=-2.3, C1=1.,\n",
    "                         binaryFraction=0.7, Mmin_universe=0.1, Mmax_universe=300., sampleSize=2000000):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        # COMPAS simulation parameters\n",
    "        pathCOMPASh5 (_type_, optional): path to your COMPAS file. Defaults to None.\n",
    "\n",
    "        # Broken powerlaw (Kroupa IMF) parameters\n",
    "        x1, x2, x3, x4: float, the break points (mass ranges) for the three segments\n",
    "        a1, a2, a3: float, the power law indices \n",
    "        <0.01 - 0.08> a = -0.3, <0.08 - 0.5> a = -1.3, <0.5 - 200> a = -2.3\n",
    "        C1: float, the normalization constant for the first segment\n",
    "        \n",
    "        # Believes about star formation in the Universe\n",
    "        binaryFraction (int, optional): What fraction of stars are in binaries. Default= 1.\n",
    "        Mmin_universe, Mmax_universe (float): the min and max mass that stars in the Universe can be born with  Defaults: 0.01 and 200.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\" \n",
    "    x1 = Mmin_universe\n",
    "    x4 = Mmax_universe\n",
    "\n",
    "    # Open the COMPAS file\n",
    "    COMPASdataf = h5.File(pathCOMPASh5, 'r')\n",
    "\n",
    "    # Min and max M sampled in your COMPAS simulation.\n",
    "    COMPAS_m1       = COMPASdataf['BSE_System_Parameters']['Mass@ZAMS(1)'][()]\n",
    "    Mlower_COMPAS   = np.min(COMPAS_m1)\n",
    "    Mupper_COMPAS   = np.max(COMPAS_m1)\n",
    "\n",
    "    ##########################\n",
    "    # Create Sample Universe \n",
    "    ##########################\n",
    "    # we will use 'inverse transform sampling method' to sample our sample Universe from the IMF\n",
    "\n",
    "    ### Primary mass\n",
    "    # first we compute the y-values of the CDF of our IMF at Mmin_universe and Mmax_universe\n",
    "    # Mmin_universe and Mmax_universe have to be between x1 and x4\n",
    "    CDFmin = CDFbrokenPowerLaw(np.array([Mmin_universe]), x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "    CDFmax = CDFbrokenPowerLaw(np.array([Mmax_universe]), x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "\n",
    "    # Now we can sample Uniformly from the CDF between CDFmin and CDFmax\n",
    "    drawM1      = np.random.uniform(CDFmin,CDFmax,sampleSize)\n",
    "    # Convert CDF values back to masses\n",
    "    M1          = invertCDFbrokenPowerLaw(drawM1, x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "\n",
    "    ### Binary fraction\n",
    "    # we want that binaryFraction of the stars are in binaries\n",
    "    # Hence by drawing between 0-1, we have to throw out everything that is above binaryFraction (i.e. = single and m2 = 0)\n",
    "    # ! NOTE that this assumes that the binary Fraction is mass indepent! > Future work to implenet Max Moe ps and qs options\n",
    "    drawBinary      = np.random.uniform(0,1,sampleSize)\n",
    "    maskBinary      = drawBinary < binaryFraction  #booleans\n",
    "\n",
    "    ### Secondary mass\n",
    "    # mass ratio (q = m2/m1) distribution is assumed to be flat \n",
    "    # so then the drawM2 (if it is in a binary) just becomes the mass fraction.\n",
    "    drawM2          = np.random.uniform(0,1,sampleSize)    # we are actually sampling q\n",
    "    M2              = np.zeros(sampleSize)                 #\n",
    "    M2[maskBinary]  = drawM2[maskBinary] * M1[maskBinary]  # = q * m1, all the ones outside the mask remain zero\n",
    "    \n",
    "    totalMassInStarFormation = np.sum(M1) + np.sum(M2)\n",
    "\n",
    "    ##########################\n",
    "    # Select what lies in the range of COMPAS\n",
    "    ##########################\n",
    "    # mask M1 and M2 to see what lies in the range of COMPAS\n",
    "    maskM1          = (M1>=Mlower_COMPAS) & (M1<=Mupper_COMPAS)\n",
    "    maskBinaries    = (M2!=0)\n",
    "    mask_COMPAS     = maskM1 & maskBinaries\n",
    "\n",
    "    totalMassEvolvedCOMPAS = np.sum(M1[mask_COMPAS]) + np.sum(M2[mask_COMPAS])\n",
    "\n",
    "    ##########################\n",
    "    # Finally compute the tot mass evolved per Z\n",
    "    ##########################\n",
    "    \n",
    "    # load a bit more COMPAS data\n",
    "    COMPAS_m2       = COMPASdataf['BSE_System_Parameters']['Mass@ZAMS(2)'][()]\n",
    "    COMPAS_metals   = COMPASdataf['BSE_System_Parameters']['Metallicity@ZAMS(1)'][()]\n",
    "    uniqueZ_COMPAS  = np.unique(COMPAS_metals)\n",
    "    \n",
    "    # Determine if your samples are weighted\n",
    "    # boolWeighted = 'mixture_weight' in COMPASdataf['BSE_System_Parameters'].keys()\n",
    "\n",
    "    # I assume that if you have more than 100 metallicities, it's not discrete, but a continuous Z distribution\n",
    "    w_NbinariesEvolvedPerZ = []                                                           # Nbinaries simulated per Z //floor\n",
    "    for Z in uniqueZ_COMPAS:\n",
    "        mask = COMPAS_metals == Z\n",
    "        Nbinaries = len(COMPAS_m1[mask])\n",
    "        w_NbinariesEvolvedPerZ.append(Nbinaries)\n",
    "    w_NbinariesEvolvedPerZ        = np.array(w_NbinariesEvolvedPerZ)\n",
    "    w_AverageMassPerBinaryCOMPAS  = totalMassEvolvedCOMPAS / len(M1[mask_COMPAS])         # average mass of a binary in COMPAS simulation  //floor\n",
    "    w_MassEvolvedPerZ             = w_AverageMassPerBinaryCOMPAS * w_NbinariesEvolvedPerZ     # //floor    \n",
    "\n",
    "    # Simulation with discrete metallicities\n",
    "    total = []\n",
    "    for Z in uniqueZ_COMPAS:\n",
    "        Zmask = COMPAS_metals == Z\n",
    "        total.append( np.sum(COMPAS_m1[Zmask]) + np.sum(COMPAS_m2[Zmask]) )\n",
    "\n",
    "        MassEvolvedPerZ  = np.array(total)\n",
    "\n",
    "    # fraction of total universe that was sampled by COMPAS\n",
    "    fraction = totalMassEvolvedCOMPAS/float(totalMassInStarFormation)\n",
    "\n",
    "    # We need to muliply the mass evolved per metallicity times (1/fraction) to know the total mass evolved per metallicity\n",
    "    totalMassEvolvedPerMetallicity = (MassEvolvedPerZ)/(fraction)\n",
    "\n",
    "    return w_NbinariesEvolvedPerZ, w_AverageMassPerBinaryCOMPAS, w_MassEvolvedPerZ, totalMassEvolvedCOMPAS, float(totalMassInStarFormation),  MassEvolvedPerZ\n",
    "\n",
    "\n",
    "def CDFbrokenPowerLaw(x, x1=0.01, x2=0.08, x3=0.5, x4=200, a1=-0.3, a2=-1.3, a3=-2.3, C1=1):\n",
    "    \"\"\"\n",
    "    CDF values of a three-part broken powerlaw representing a Kroupa IMF by default.\n",
    "    \n",
    "    Parameters:\n",
    "    x: array-like, the input values\n",
    "    x1, x2, x3, x4: float, the break points (mass ranges) for the three segments\n",
    "    a1, a2, a3: float, the power law indices \n",
    "    C1: float, the normalization constant for the first segment\n",
    "    \n",
    "    Returns:\n",
    "    yvalues: array-like, the output values of the CDF\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the output array\n",
    "    yvalues = np.zeros(len(x))\n",
    "    \n",
    "    # Calculate the normalization constants for the other segments\n",
    "    # Ensuring that the next segments start where the previous segment ends\n",
    "    C2 = float(C1 * (x2**(a1-a2)))\n",
    "    C3 = float(C2 * (x3**(a2-a3)))\n",
    "    \n",
    "    # Calculate the normalization factors for the three segments\n",
    "    N1 = float(((1./(a1+1)) * C1 * (x2**(a1+1))) - ((1./(a1+1)) * C1 * (x1**(a1+1))))\n",
    "    N2 = float(((1./(a2+1)) * C2 * (x3**(a2+1))) - ((1./(a2+1)) * C2 * (x2**(a2+1))))\n",
    "    N3 = float(((1./(a3+1)) * C3 * (x4**(a3+1))) - ((1./(a3+1)) * C3 * (x3**(a3+1))))\n",
    "    \n",
    "    # Calculate the denominator of the CDF\n",
    "    bottom = N1+N2+N3\n",
    "    \n",
    "    # Calculate the CDF values for x range: x1<=x<x2\n",
    "    mask1 = (x>=x1) & (x<x2)\n",
    "    top1 = ( (1./(a1+1) ) * C1 * (x[mask1]**(a1+1) ) - (1./(a1+1) ) * C1 * (x1**(a1+1) ) ) \n",
    "    yvalues[mask1] = top1/bottom\n",
    "    \n",
    "    # Calculate the CDF values for x range: x2<=x<x3\n",
    "    mask2 = (x>=x2) & (x<x3)\n",
    "    top2 =  N1 + ( (1./(a2+1) ) * C2 * (x[mask2]**(a2+1) ) - (1./(a2+1)) * C2 * (x2**(a2+1) ) ) \n",
    "    yvalues[mask2] = top2/bottom\n",
    "    \n",
    "    # Calculate the CDF values for x range: x3<=x<=x4\n",
    "    mask3 = (x>=x3) & (x<=x4)\n",
    "    top3 =  N1 + N2 + ( (1./(a3+1)) * C3 * (x[mask3]**(a3+1)) - (1./(a3+1)) * C3 * (x3**(a3+1) ) )\n",
    "    yvalues[mask3] = top3/bottom\n",
    "    \n",
    "    return yvalues\n",
    "\n",
    "\n",
    "def invertCDFbrokenPowerLaw(CDF, x1, x2, x3, x4, a1, a2, a3, C1):\n",
    "    \"\"\"\n",
    "    Invert y-values of a CDF back to x-vals (i.e. the masses)\n",
    "    Specifically for a three-part piece-wise powerlaw representing a Kroupa IMF by default. \n",
    "\n",
    "    Parameters:\n",
    "    CDF: array-like, the CDF values to invert\n",
    "    x1, x2, x3, x4: float, the break points (ranges) for the three segments\n",
    "    a1, a2, a3: float, the power law indices for the three segments\n",
    "    C1: float, the normalization constant for the first segment\n",
    "\n",
    "    Returns:\n",
    "    xvalues: array-like, the inverted CDF values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the normalization constants for the second and third segments\n",
    "    C2 = float(C1 * (x2**(a1-a2)))\n",
    "    C3 = float(C2 * (x3**(a2-a3)))\n",
    "    \n",
    "    # Calculate the area under the curve for each segment\n",
    "    N1 = float(((1./(a1+1)) * C1 * (x2**(a1+1))) - ((1./(a1+1)) * C1 * (x1**(a1+1))))\n",
    "    N2 = float(((1./(a2+1)) * C2 * (x3**(a2+1))) - ((1./(a2+1)) * C2 * (x2**(a2+1))))\n",
    "    N3 = float(((1./(a3+1)) * C3 * (x4**(a3+1))) - ((1./(a3+1)) * C3 * (x3**(a3+1))))\n",
    "    \n",
    "    # Calculate the CDF values at the breakpoints\n",
    "    CDFx2 = CDFbrokenPowerLaw(np.array([x2,x2]), x1, x2, x3, x4, a1, a2, a3, C1)[0]\n",
    "    CDFx3 = CDFbrokenPowerLaw(np.array([x3,x3]), x1, x2, x3, x4, a1, a2, a3, C1)[0]\n",
    "\n",
    "    # Initialize the output array\n",
    "    xvalues = np.zeros(len(CDF))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the first segment\n",
    "    mask1 = (CDF < CDFx2)\n",
    "    xvalues[mask1] =  (((CDF[mask1]*(N1+N2+N3))  + \\\n",
    "                      ( (1./(a1+1))*C1*(x1**(a1+1))))/((1./(a1+1))*C1))**(1./(a1+1))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the second segment\n",
    "    mask2 = (CDFx2<= CDF) & (CDF < CDFx3)\n",
    "    xvalues[mask2] = ((((CDF[mask2]*(N1+N2+N3))-(N1))  + \\\n",
    "                      ( (1./(a2+1))*C2*(x2**(a2+1))))/((1./(a2+1))*C2))**(1./(a2+1))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the third segment\n",
    "    mask3 = (CDFx3<= CDF) \n",
    "    xvalues[mask3] = ((((CDF[mask3]*(N1+N2+N3))-(N1+N2))  + \\\n",
    "                      ((1./(a3+1))*C3*(x3**(a3+1))))/((1./(a3+1))*C3))**(1./(a3+1))\n",
    "    \n",
    "    # Return the inverse CDF values\n",
    "    return xvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_name = 'NewWinds_RemFryer2012'\n",
    "\n",
    "Sampe_size = int(2e6)\n",
    "\n",
    "w_NbinariesEvolvedPerZ, w_AverageMassPerBinaryCOMPAS, w_MassEvolvedPerZ, totalMassEvolvedCOMPAS, totalMassInStarFormation,  MassEvolvedPerZ = totalMassEvolvedPerZ(f'{datar_root}/{sim_name}/COMPAS_Output_combinedZ.h5', sampleSize=Sampe_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mass per system in Universe 0.899409810483058\n"
     ]
    }
   ],
   "source": [
    "average_mass_per_system_univ = totalMassInStarFormation/Sampe_size\n",
    "print(f'Average mass per system in Universe {average_mass_per_system_univ}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{dP}{dm} = m^{-2.35}\n",
    " \\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "f_{primary} = \\frac{m^{-1/35}|_{Mmin}^{300}}{m^{-1.35}|_{0.1}^{300}} = \\frac{ 300^{-1.35} - Mmin^{-1.35} }{-22.39}\n",
    "\\end{equation}\n",
    "\n",
    " for BBHs, $Mmin = 20$, for NS, $Mmin = 8$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_primary for BBH = 0.0007625160671152889\n",
      "f_primary for NSNS 0.002676503668045551\n"
     ]
    }
   ],
   "source": [
    "f_prim_bbh = (300**-1.35 - 20**-1.35)/(300**-1.35 - 0.1**-1.35)\n",
    "print(f'f_primary for BBH = {f_prim_bbh}')\n",
    "f_prim_nsns = (300**-1.35 - 8**-1.35)/(300**-1.35 - 0.1**-1.35)\n",
    "print(f'f_primary for NSNS {f_prim_nsns}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a flat in q distribution, so for both BBH and NSNS, $f_{secondary} = 0.5$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_secondary_bbh = 0.5\n",
    "f_secondary_nsns = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for $f_{init sep}$, we adopt the fraction of systems that interacts ever. \n",
    "\n",
    "We assume that binaries can form with separations between 0.01AU and 1000 AU \n",
    "\n",
    "we assume a flat-in-log distribution of initial separations\n",
    "\n",
    "\\begin{equation}\n",
    "P(a_i) = 1/a_i\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "f_{init sep} = \\frac{\\log(a_i)|_{mina}^{maxa} }{\\log(a_i)|_{0.01 AU}^{1000 AU} }\n",
    "\\end{equation}\n",
    "\n",
    "where $mina$ and $maxa$ are the min and max separation for interaction,\n",
    "For the minimum, we look at our case A,B C plots, and stars have radii of $3-20R_{\\odot}$ at birth (roughly), leading to a range of 0.0279AU - 0.186AU. We adopt the average of $mina \\approx 0.1 AU$\n",
    "\n",
    "For the upper end, we use our max R per Z to estimate this. Very roughly stars range between a max R of 1000 and 5000, so we adopt $maxa \\approx 3000 R_{\\odot} = 13.95 AU$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "f_{init sep} = \\frac{\\log(13.95) - \\log(0.1)}{\\log(100) - \\log(0.01)} \\approx 0.42\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_init_sep = 0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We assume no kicks for BBH so $f_{SN1} = f_{SN2} = 1$\n",
    "\n",
    " We assume full kicks for NSNS so $f_{SN1} = f_{SN2} = 0.14$ (See Soumendra's derivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sn1_bbh = 1.\n",
    "f_sn2_bbh = 1.\n",
    "\n",
    "\n",
    "f_sn1_nsns = 0.14\n",
    "f_sn2_nsns = 0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_BBH = 0.0001780371664038314\n",
      "eta_nsns = 1.2248575642908227e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eta_BBH = 1./average_mass_per_system_univ * (f_prim_bbh * f_secondary_bbh * f_init_sep * f_sn1_bbh * f_sn2_bbh )\n",
    "print(f'eta_BBH = {eta_BBH}')\n",
    "\n",
    "\n",
    "eta_NSNS = 1./average_mass_per_system_univ * (f_prim_nsns * f_secondary_nsns * f_init_sep * f_sn1_nsns * f_sn2_nsns )\n",
    "print(f'eta_nsns = {eta_NSNS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for BHNS\n",
    "\n",
    "$f_{init sep} = 0.42$ stays the same\n",
    "$f_{SN1} = 1$\n",
    "$f_{SN2} = 0.14$\n",
    "$f_{primary} = 7.6 \\cdot 10^{-4}$ (same as for BBH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_prim_bhns = (300**-1.35 - 20**-1.35)/(300**-1.35 - 0.1**-1.35)\n",
    "f_sn1_bhns = 1\n",
    "f_sn2_bhns = 0.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "But now $f_{secondary}$ is a more complicated conditional probability\n",
    "\\begin{equation}\n",
    "f_{secondary} = P(8 < m_2 < 20\\, | m_1 > 20) = \\frac{\\int_{20}^{300} P(8 < m_2 < 20\\, | m_1)P(m1)dm }{P(m1>20) }\n",
    "\\end{equation}\n",
    "\n",
    "$q = m_2/m_1$ is a flat distribution\n",
    "\n",
    "we can re-write $m_2$ in terms of q and $m_1$\n",
    "\\begin{equation}\n",
    "P(8 < m_2 < 20\\, | m_1) = P(8/m_1 < q < 20/m_1 | m_1)\n",
    "\\end{equation}\n",
    "\n",
    "Because q is flat the probability for q is just the difference\n",
    "\\begin{equation}\n",
    " P(8/m_1 < q < 20/m_1 | m_1) = \\frac{20}{m_1} - \\frac{8}{m_1} = \\frac{12}{m_1}\n",
    "\\end{equation}\n",
    "\n",
    "multiplying this by the $m_1$ probability:\n",
    "\\begin{equation}\n",
    "P(8 < m_2 < 20\\, | m_1)P(m1) =\\frac{12}{m_1} P(m1)  = \\frac{12}{m_1} m_1^{-2.3}\n",
    "\\end{equation}\n",
    "\n",
    "so we get:\n",
    "\\begin{equation}\n",
    "f_{secondary} =  \\frac{ \\int_{20}^{300} 12 m_1^{-3.3} }{ \\int_{20}^{300} m_1^{-2.3} }  = \\frac{12 \\cdot (300^{-2.35} - 20^{-2.35})/-2.35  }{(300^{-1.35} - 20^{-1.35})/-1.35}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_secondary for BHNS 0.3532138172332844\n"
     ]
    }
   ],
   "source": [
    "f_secondary_bhns =  12 *  ((300**-2.35 - 20**-2.35)/-2.35) / ((300**-1.35 - 20**-1.35)/(-1.35))\n",
    "print(f'f_secondary for BHNS {f_secondary_bhns}' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_BHNS = 1.760785240337053e-05\n"
     ]
    }
   ],
   "source": [
    "eta_BHNS = 1./average_mass_per_system_univ * (f_prim_bhns * f_secondary_bhns * f_init_sep * f_sn1_bhns * f_sn2_bhns )\n",
    "print(f'eta_BHNS = {eta_BHNS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
