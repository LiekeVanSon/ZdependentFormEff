{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical computation of the Maximum formation efficiency\n",
    "\n",
    "As described in section 2 from the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "import multiprocessing as mp\n",
    "\n",
    "# add run_data path to sys\n",
    "sys.path.append('./run_data')\n",
    "from definitions import sim_flags_dict\n",
    "\n",
    "\n",
    "######################################\n",
    "## PLOT setttings\n",
    "plt.rc('font', family='serif')\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "fsize, SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = 30,20,25,30\n",
    "for obj in ['axes','xtick','ytick']:\n",
    "    plt.rc(obj, labelsize=SMALL_SIZE)          # controls default text sizes\n",
    "for obj in ['figure','axes']:\n",
    "    plt.rc(obj, titlesize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "\n",
    "\n",
    "\n",
    "home_dir    = os.path.expanduser(\"~\") \n",
    "compas_v    = \"v03.01.02\" #\"v02.46.01\" # #\"#v02.35.02/\"\n",
    "datar_root  =  f\"{home_dir}/ceph/CompasOutput/{compas_v}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate maximum formation efficiency\n",
    "\n",
    "We approximate the 'maximum' formation efficiency using a drake equation:\n",
    "\n",
    "\\begin{equation}\n",
    "     \\eta_{form} = \\frac{1}{\\langle M_{SF} \\rangle } \\Bigl( f_{\\mathrm{primary}} \\times f_{\\mathrm{secondary}} \\times f_{\\mathrm{init \\, sep}} \\times f_{\\mathrm{survive \\, SN1}} \\times f_{\\mathrm{survive \\, SN2}} \\Bigr)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### Probability of forming \n",
    "\n",
    "We approximate the terms _within the round brackets of Equation 2 above_ with the probability to form a pair of massive stars with the `right' set of (initial) conditions. The conditions in questions are random variables at ZAMS (the primary mass, $m_1$, secondary mass, $m_2$, orbital separation, $a$), and factors affecting the stars' survival during supernovae in the first and second mass transfer phases. \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(m_1, ~m_2, ~a, ~\\text{survive SN1}, ~\\text{survive SN2}) \n",
    "& = p(m_1) \\times p(m_2~|~m_1) \\\\\n",
    "& \\times p(a ~|~m_1, ~m_2) \\\\\n",
    "& \\times  p(\\text{survive SN1}~|~m_1, ~m_2, ~a) \\\\\n",
    "& \\times p(\\text{survive SN2}~|~m_1, ~m_2, ~a, ~\\text{survive SN1})\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "By integrating over the relevant ranges of $m_1, ~q, ~a, ~\\text{survive SN1}, ~\\text{survive SN2} \\in C$, we obtain the probability for a specific type of compact binary merger to occur. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Primary and secondary masses\n",
    "We compute the probability that $m_2$ falls within a certain mass range [c,d] given that $m_1$ within a certain mass range [a,b]:\n",
    "\n",
    "\\begin{equation} \n",
    "\\begin{split}\n",
    "f_{\\text{primary}} \\times f_{\\text{secondary}} \n",
    "&  \\approx   \\int_{m_1 = a}^{m_1 = b} \\int_{m_2 = c}^{m_2 = d} p(m_1) \\times p(m_2 | m_1)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "We can write $m_2$ in terms of the mass ratio $q \\equiv m_2/m_1 < 1$:\n",
    "\\begin{equation}\n",
    "    p(m_2~|~m_1) = \\frac{\\partial q}{\\partial m_2} p(q~|~m_1) = \\frac{1}{m_1} p(q~|~m_1)\n",
    "\\end{equation}\n",
    "\n",
    "We assume $p(q)$ follows a uniform probability distribution between $0$ and $1$:\n",
    "\\begin{equation} \n",
    "    p(q~|~m_1) = U(q|0,1)\n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume $p(m_1)$ follows the Kroupa IMF, defined as:\n",
    "\\begin{equation} \n",
    "\\text{Kroupa IMF}(m_1) = C_1\n",
    "    \\begin{cases}\n",
    "      (m_1/M_{\\odot})^{-0.3} & 0.01~M_{\\odot} \\leq m_1 < 0.08~M_{\\odot}\\\\\n",
    "      C_2 \\cdot (m_1/M_{\\odot})^{-1.3} & 0.08~M_{\\odot} \\leq m_1 < 0.5~M_{\\odot}\\\\\n",
    "      C_3 \\cdot (m_1/M_{\\odot})^{-2.3} & 0.5~M_{\\odot} \\leq m_1 < 300~M_{\\odot}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n",
    "Here $C_2 = 0.08^{-0.3 + 1.3} = 0.08$ and $C_3 = C_2 \\cdot 0.5^{-1.3 + 2.3} = C_2 \\cdot 0.5$ to ensure continuity.\n",
    "C_1 is a normalization constant, determined by normalizing the IMF over the entire mass range:\n",
    "\\begin{equation*}\n",
    "    C_1 = \\Big[ \\frac{0.08^{(-0.3+1)}-0.01^{(-0.3+1)}}{(-0.3+1)} + 0.08 \\cdot \\left( \\frac{0.5^{(-1.3+1)}-0.08^{(-1.3+1)}}{(-1.3+1)} \\right) + 0.08 \\cdot 0.5 \\cdot \\left(\\frac{300^{(-2.3+1)}-0.5^{(-2.3+1)}}{(-2.3+1)} \\right)  \\Big]^{-1}\n",
    "\\end{equation*}\n",
    "Note that we set the minimum and maximum stellar masses to $0.01~M_{\\odot}$ and $300~M_{\\odot}$, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given a fixed primary mass $m_1$, $p(q~|~m_1)$ represents the probability density of finding a partner star such that the mass ratio becomes $q$. \n",
    "\n",
    "\n",
    "\n",
    "Combining equations above we get:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "        f_{\\text{primary}} \\times f_{\\text{secondary}} \n",
    "        & = \\int_{m_1=a}^{m_1=b} dm_1 \\int_{q=c/m_1}^{q=d/m_1} dq ~\\text{Kroupa IMF}(m_1) \\times \\frac{M_{\\odot}}{m_1}U(q|0,1) \\\\\n",
    "        & = \\int_{m_1=a}^{m_1=b} dm_1 ~\\text{Kroupa IMF}(m_1) \\times \\frac{1}{m_1} \\left( \\frac{d}{m_1} - \\frac{c}{m_1} \\right)  \\\\\n",
    "        & = (d -c) \\int_{m_1=a}^{m_1=b} dm_1 ~\\text{Kroupa IMF}(m_1) \\times \\frac{1}{m_1^2} \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9869192439784182\n"
     ]
    }
   ],
   "source": [
    "# the integral of a piece (or term) of a broken powerlaw\n",
    "def norm_term(minm, maxm, power):\n",
    "    return (maxm**(power + 1) - minm**(power + 1)) / (power + 1)\n",
    "\n",
    "term1 = norm_term(0.01, 0.08, -0.3)\n",
    "term2 = 0.08 * norm_term(0.08, 0.5, -1.3)\n",
    "term3 = 0.08 * 0.5 * norm_term(0.5, 300, -2.3)\n",
    "\n",
    "Norm = 1/(term1+ term2 + term3 )\n",
    "print(Norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BHBH\n",
    "\n",
    "For BHBH, we assume both primary and secondary masses range from [$20M_{\\odot}$,$300M_{\\odot}$]\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    f_{\\text{primary}} \\times f_{\\text{secondary}}\n",
    "    & = C_1  \\left(300 - 20 \\right)\\int_{m_1=20M_{\\odot}}^{m_1=300M_{\\odot}} dm_1 C_3 \\cdot m_1^{-2.3} \\times m_1^{-2} \\\\\n",
    "    & = C_1  \\left(300 - 20 \\right) C_3\\int_{m_1=20M_{\\odot}}^{m_1=300M_{\\odot}} dm_1  \\cdot m_1^{-4.3} \\\\\n",
    "    & = C_1  \\left(300 - 20 \\right)  \\frac{C_3 }{-3.3} \\left| m_1^{-3.3} \\right|^{300}_{20} \\\\\n",
    "    & = C_1  \\left(300 - 20 \\right)  \\frac{C_3 }{-3.3} \\left( 300^{-3.3} - 20^{-3.3} \\right) \\\\\n",
    "    & = 3.4 \\times 10^{-4}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "<!-- 2.43 \\times 10^{-4} -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!--     & = C_1 \\int_{m_1=20M_{\\odot}}^{m_1=300M_{\\odot}} dm_1 \\int_{q=20/m_1}^{q=300/m_1} dq ~\\Big(\\frac{m_1}{1}\\Big)^{-2.7} \\times \\frac{1}{m_1} \\\\\n",
    "    & = C_1 \\int_{m_1=20M_{\\odot}}^{m_1=300M_{\\odot}} \\left(\\frac{300}{m_1} - \\frac{20}{m_1} \\right) ~\\Big(\\frac{m_1}{1}\\Big)^{-3.7} \\\\\n",
    "    & = C_1 \\int_{m_1=20M_{\\odot}}^{m_1=300M_{\\odot}} m_1 ^{-1} \\left(300 - 20 \\right) ~\\Big(\\frac{m_1}{1}\\Big)^{-3.7} \\\\\n",
    "    & = C_1  \\left(300 - 20 \\right) \\int_{m_1=20M_{\\odot}}^{m_1=300M_{\\odot}} ~\\Big(\\frac{m_1}{1}\\Big)^{-4.7} \\\\\n",
    "    & = C_1  \\frac{\\left(300 - 20 \\right)}{-3.7} \\Big[ \\left(\\frac{m_1}{1}\\right)^{-3.7} \\Big]^{300}_{20} \\\\\n",
    "    & = C_1  \\frac{\\left(300 - 20 \\right)}{-3.7} \\Big[ 300^{-3.7} - 20^{-3.7} \\Big]\\\\ -->\n",
    "\n",
    "As long as our masses $m_1 >0.5 M_{\\odot}$, we can write this more generally as: \n",
    "\\begin{equation}\n",
    "    f_{\\text{primary}} \\times f_{\\text{secondary}} = C_1  \\frac{(d - c) C_3 }{-3.3} \\Big[b^{-3.3} - a^{-3.3} \\Big]\n",
    "\\end{equation}\n",
    "\n",
    "for $m_1 = [a,b]$ and $m_2 = [c,d]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003431059134688049\n",
      "0.0003431059134688049 = 3.43E-04\n"
     ]
    }
   ],
   "source": [
    "C3 = 0.08 * 0.5\n",
    "print( (Norm * (300 - 20) * C3) /-3.3 * (300**-3.3 - 20**-3.3) ) \n",
    "\n",
    "def f_primaryXf_secondary(power, a,b,c,d, C1 = Norm, C3 = (0.08*0.5)):\n",
    "    # here power is the powerlaw that the mass distribution pdf follows. \n",
    "    # This only works if a-b, and c-d all fall within one leg of the Kroupa IMF\n",
    "    # i.e. have the same power alpha\n",
    "    # C_3 = 0.08 * 0.5    # = C2 * 0.5^(-1.3 + 2.3), with C_2 = 0.08^(-0.3 + 1.3)\n",
    "    return  (C1 * (d-c)* C3 ) / (power- 1) * (b**(power-1) - a**(power-1))\n",
    "\n",
    "f_primaryf_secondary_bhbh = f_primaryXf_secondary(-2.3, 20,300,20,300, C1 = Norm, C3 = (0.08*0.5)) \n",
    "print(f\"{f_primaryf_secondary_bhbh} = {f_primaryf_secondary_bhbh:.2E}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSNS\n",
    "\n",
    "For NSNS we assume both primary and secondary masses range from [$8M_{\\odot}$,$20M_{\\odot}$]\n",
    "\n",
    "<!-- \\begin{equation}\n",
    "\\begin{split}\n",
    "    f_{\\text{primary}} \\times f_{\\text{secondary}}\n",
    "    & = (\\text{constant}) \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} d(m_1/M_{\\odot}) \\int_{q=8/m_1}^{q=20/m_1} dq ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-2.7} \\times \\frac{M_{\\odot}}{m_1} \\\\\n",
    "    & = \\text{constant} \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} \\left(\\frac{20}{m_1} - \\frac{8}{m_1} \\right) ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-3.7} \\\\\n",
    "    & = \\text{constant} \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} m_1 ^{-1} \\left(20 - 8 \\right) ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-3.7} \\\\\n",
    "    & = \\text{constant}  \\left(20 - 8 \\right) \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-4.7} \\\\\n",
    "    & = \\text{constant}  \\frac{\\left(20 - 8 \\right)}{-3.7} \\Big[ \\left(\\frac{m_1}{M_{\\odot}}\\right)^{-3.7} \\Big]^{20}_{8} \\\\\n",
    "    & = \\text{constant}  \\frac{\\left(20 - 8 \\right)}{-3.7} \\Big[ 20^{-3.7} - 8^{-3.7} \\Big]\\\\\n",
    "    & = 2.43 \\times 10^{-4}\n",
    "\\end{split}\n",
    "\\end{equation} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001134746975095127\n",
      "0.0001134746975095127 = 1.13E-04\n"
     ]
    }
   ],
   "source": [
    "print( ((Norm * (20 - 8) * C3 ) /-3.7) * (20**-3.7 - 8**-3.7) ) \n",
    "\n",
    "f_primaryf_secondary_nsns = f_primaryXf_secondary(-2.7, 8,20,8,20, C1 = Norm, C3 = (0.08*0.5)) \n",
    "\n",
    "print(f\"{f_primaryf_secondary_nsns} = {f_primaryf_secondary_nsns:.2E}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BHNS\n",
    "\n",
    "Lastly for BHNS we assume $m_1 = [20M_{\\odot}$,$300M_{\\odot}]$ while $m_2 = [8M_{\\odot}$,$20M_{\\odot}]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.957212883472308e-06\n",
      "3.957212883472308e-06 = 3.96E-06\n"
     ]
    }
   ],
   "source": [
    "print( ((Norm * (20 - 8) * C3)/-3.7) * (300**-3.7 - 20**-3.7) ) \n",
    "\n",
    "f_primaryf_secondary_bhns =  f_primaryXf_secondary(-2.7, 20,300,8,20, C1 = Norm, C3 = (0.08*0.5))\n",
    "print(f\"{f_primaryf_secondary_bhns} = {f_primaryf_secondary_bhns:.2E}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for $f_{init sep}$, we adopt the fraction of systems that interacts ever. \n",
    "\n",
    "We assume that binaries can form with separations between 0.01AU and 1000 AU \n",
    "\n",
    "we assume a flat-in-log distribution of initial separations\n",
    "\n",
    "\\begin{equation}\n",
    "P(a_i) = 1/a_i\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "f_{init sep} = \\frac{\\log(a_i)|_{mina}^{maxa} }{\\log(a_i)|_{0.01 AU}^{1000 AU} }\n",
    "\\end{equation}\n",
    "\n",
    "where $mina$ and $maxa$ are the min and max separation for interaction,\n",
    "For the minimum, we look at our case A,B C plots, and stars have radii of $3-20R_{\\odot}$ at birth (roughly), leading to a range of 0.0279AU - 0.186AU. We adopt the average of $mina \\approx 0.1 AU$\n",
    "\n",
    "For the upper end, we use our max R per Z to estimate this. Very roughly stars range between a max R of 1000 and 5000, so we adopt $maxa \\approx 3000 R_{\\odot} = 13.95 AU$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "f_{init sep} = \\frac{\\log(13.95) - \\log(0.1)}{\\log(1000) - \\log(0.01)} \\approx 0.43\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43\n"
     ]
    }
   ],
   "source": [
    "f_init_sep = (np.log(14) - np.log(0.1))/ (np.log(1000) - np.log(0.01))\n",
    "print( np.round(f_init_sep,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability to survive SN1 and SN2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We assume no kicks for BBH so $f_{SN1} = f_{SN2} = 1$\n",
    "\n",
    " We assume full kicks for NSNS so $f_{SN2} = f_{SN1} \\approx 0.2$ (See derivationin appendix A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sn1_bbh = 1.\n",
    "f_sn2_bbh = 1.\n",
    "\n",
    "f_sn1_bhns = 1.\n",
    "f_sn2_bhns = 1. #0.2\n",
    "\n",
    "f_sn1_nsns = 0.2\n",
    "f_sn2_nsns = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average SF mass per binary system\n",
    "\n",
    "We use the 'total mass evolved per Z' function that we also use for the yield calculations for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_totalMassInStarFormation(x2=0.08, x3=0.5, a1=-0.3, a2=-1.3, a3=-2.3, C1=1.,\n",
    "                         binaryFraction=0.7, Mmin_universe=0.01, Mmax_universe=300., sampleSize=2000000):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        # COMPAS simulation parameters\n",
    "        pathCOMPASh5 (_type_, optional): path to your COMPAS file. Defaults to None.\n",
    "\n",
    "        # Broken powerlaw (Kroupa IMF) parameters\n",
    "        x1, x2, x3, x4: float, the break points (mass ranges) for the three segments\n",
    "        a1, a2, a3: float, the power law indices \n",
    "        <0.01 - 0.08> a = -0.3, <0.08 - 0.5> a = -1.3, <0.5 - 200> a = -2.3\n",
    "        C1: float, the normalization constant for the first segment\n",
    "        \n",
    "        # Believes about star formation in the Universe\n",
    "        binaryFraction (int, optional): What fraction of stars are in binaries. Default= 1.\n",
    "        Mmin_universe, Mmax_universe (float): the min and max mass that stars in the Universe can be born with  Defaults: 0.01 and 200.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\" \n",
    "    x1 = Mmin_universe\n",
    "    x4 = Mmax_universe\n",
    "\n",
    "    ##########################\n",
    "    # Create Sample Universe \n",
    "    ##########################\n",
    "    # we will use 'inverse transform sampling method' to sample our sample Universe from the IMF\n",
    "\n",
    "    ### Primary mass\n",
    "    # first we compute the y-values of the CDF of our IMF at Mmin_universe and Mmax_universe\n",
    "    # Mmin_universe and Mmax_universe have to be between x1 and x4\n",
    "    CDFmin = CDFbrokenPowerLaw(np.array([Mmin_universe]), x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "    CDFmax = CDFbrokenPowerLaw(np.array([Mmax_universe]), x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "\n",
    "    # Now we can sample Uniformly from the CDF between CDFmin and CDFmax\n",
    "    drawM1      = np.random.uniform(CDFmin,CDFmax,sampleSize)\n",
    "    # Convert CDF values back to masses\n",
    "    M1          = invertCDFbrokenPowerLaw(drawM1, x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "\n",
    "    ### Secondary mass\n",
    "    # mass ratio (q = m2/m1) distribution is assumed to be flat \n",
    "    # so then the drawM2 (if it is in a binary) just becomes the mass fraction.\n",
    "    drawM2          = np.random.uniform(0,1,sampleSize)    # we are actually sampling q\n",
    "    M2              = np.zeros(sampleSize)                 # are zeros, but will be filled with binary fraction\n",
    "\n",
    "    ### Binary fraction\n",
    "    # we want that binaryFraction of the stars are in binaries\n",
    "    # Hence by drawing between 0-1, we have to throw out everything that is above binaryFraction (i.e. = single and m2 = 0)\n",
    "    # to incorporate the mass dependence of f_binary, we bin our samples in mass and draw a binary fraction for each bin\n",
    "    binary_bin_edges    = [x1, 0.08, 0.5, 1, 10, x4]\n",
    "    binaryFractions     = [0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "    for m_i in range(len(binary_bin_edges[:-1])):\n",
    "        m1_mask = (M1 >= binary_bin_edges[m_i]) & (M1 < binary_bin_edges[m_i+1])\n",
    "        drawBinary = np.random.uniform(0,1,np.sum(m1_mask)) # draw a binary for all the samples in this mass bin\n",
    "        maskBinary = drawBinary < binaryFractions[m_i]\n",
    "        \n",
    "        # if maskBinary is True, then M2 = q * m1, else M2 = 0\n",
    "        M2[m1_mask] = np.where(maskBinary, drawM2[m1_mask] * M1[m1_mask], 0)\n",
    "\n",
    "    totalMassInStarFormation = np.sum(M1) + np.sum(M2)\n",
    "\n",
    "    return totalMassInStarFormation\n",
    "\n",
    "\n",
    "def CDFbrokenPowerLaw(x, x1=0.01, x2=0.08, x3=0.5, x4=200, a1=-0.3, a2=-1.3, a3=-2.3, C1=1):\n",
    "    \"\"\"\n",
    "    CDF values of a three-part broken powerlaw representing a Kroupa IMF by default.\n",
    "    \n",
    "    Parameters:\n",
    "    x: array-like, the input values\n",
    "    x1, x2, x3, x4: float, the break points (mass ranges) for the three segments\n",
    "    a1, a2, a3: float, the power law indices \n",
    "    C1: float, the normalization constant for the first segment\n",
    "    \n",
    "    Returns:\n",
    "    yvalues: array-like, the output values of the CDF\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the output array\n",
    "    yvalues = np.zeros(len(x))\n",
    "    \n",
    "    # Calculate the normalization constants for the other segments\n",
    "    # Ensuring that the next segments start where the previous segment ends\n",
    "    C2 = float(C1 * (x2**(a1-a2)))\n",
    "    C3 = float(C2 * (x3**(a2-a3)))\n",
    "    \n",
    "    # Calculate the normalization factors for the three segments\n",
    "    N1 = float(((1./(a1+1)) * C1 * (x2**(a1+1))) - ((1./(a1+1)) * C1 * (x1**(a1+1))))\n",
    "    N2 = float(((1./(a2+1)) * C2 * (x3**(a2+1))) - ((1./(a2+1)) * C2 * (x2**(a2+1))))\n",
    "    N3 = float(((1./(a3+1)) * C3 * (x4**(a3+1))) - ((1./(a3+1)) * C3 * (x3**(a3+1))))\n",
    "    \n",
    "    # Calculate the denominator of the CDF\n",
    "    bottom = N1+N2+N3\n",
    "    \n",
    "    # Calculate the CDF values for x range: x1<=x<x2\n",
    "    mask1 = (x>=x1) & (x<x2)\n",
    "    top1 = ( (1./(a1+1) ) * C1 * (x[mask1]**(a1+1) ) - (1./(a1+1) ) * C1 * (x1**(a1+1) ) ) \n",
    "    yvalues[mask1] = top1/bottom\n",
    "    \n",
    "    # Calculate the CDF values for x range: x2<=x<x3\n",
    "    mask2 = (x>=x2) & (x<x3)\n",
    "    top2 =  N1 + ( (1./(a2+1) ) * C2 * (x[mask2]**(a2+1) ) - (1./(a2+1)) * C2 * (x2**(a2+1) ) ) \n",
    "    yvalues[mask2] = top2/bottom\n",
    "    \n",
    "    # Calculate the CDF values for x range: x3<=x<=x4\n",
    "    mask3 = (x>=x3) & (x<=x4)\n",
    "    top3 =  N1 + N2 + ( (1./(a3+1)) * C3 * (x[mask3]**(a3+1)) - (1./(a3+1)) * C3 * (x3**(a3+1) ) )\n",
    "    yvalues[mask3] = top3/bottom\n",
    "    \n",
    "    return yvalues\n",
    "\n",
    "\n",
    "def invertCDFbrokenPowerLaw(CDF, x1, x2, x3, x4, a1, a2, a3, C1):\n",
    "    \"\"\"\n",
    "    Invert y-values of a CDF back to x-vals (i.e. the masses)\n",
    "    Specifically for a three-part piece-wise powerlaw representing a Kroupa IMF by default. \n",
    "\n",
    "    Parameters:\n",
    "    CDF: array-like, the CDF values to invert\n",
    "    x1, x2, x3, x4: float, the break points (ranges) for the three segments\n",
    "    a1, a2, a3: float, the power law indices for the three segments\n",
    "    C1: float, the normalization constant for the first segment\n",
    "\n",
    "    Returns:\n",
    "    xvalues: array-like, the inverted CDF values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the normalization constants for the second and third segments\n",
    "    C2 = float(C1 * (x2**(a1-a2)))\n",
    "    C3 = float(C2 * (x3**(a2-a3)))\n",
    "    \n",
    "    # Calculate the area under the curve for each segment\n",
    "    N1 = float(((1./(a1+1)) * C1 * (x2**(a1+1))) - ((1./(a1+1)) * C1 * (x1**(a1+1))))\n",
    "    N2 = float(((1./(a2+1)) * C2 * (x3**(a2+1))) - ((1./(a2+1)) * C2 * (x2**(a2+1))))\n",
    "    N3 = float(((1./(a3+1)) * C3 * (x4**(a3+1))) - ((1./(a3+1)) * C3 * (x3**(a3+1))))\n",
    "    \n",
    "    # Calculate the CDF values at the breakpoints\n",
    "    CDFx2 = CDFbrokenPowerLaw(np.array([x2,x2]), x1, x2, x3, x4, a1, a2, a3, C1)[0]\n",
    "    CDFx3 = CDFbrokenPowerLaw(np.array([x3,x3]), x1, x2, x3, x4, a1, a2, a3, C1)[0]\n",
    "\n",
    "    # Initialize the output array\n",
    "    xvalues = np.zeros(len(CDF))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the first segment\n",
    "    mask1 = (CDF < CDFx2)\n",
    "    xvalues[mask1] =  (((CDF[mask1]*(N1+N2+N3))  + \\\n",
    "                      ( (1./(a1+1))*C1*(x1**(a1+1))))/((1./(a1+1))*C1))**(1./(a1+1))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the second segment\n",
    "    mask2 = (CDFx2<= CDF) & (CDF < CDFx3)\n",
    "    xvalues[mask2] = ((((CDF[mask2]*(N1+N2+N3))-(N1))  + \\\n",
    "                      ( (1./(a2+1))*C2*(x2**(a2+1))))/((1./(a2+1))*C2))**(1./(a2+1))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the third segment\n",
    "    mask3 = (CDFx3<= CDF) \n",
    "    xvalues[mask3] = ((((CDF[mask3]*(N1+N2+N3))-(N1+N2))  + \\\n",
    "                      ((1./(a3+1))*C3*(x3**(a3+1))))/((1./(a3+1))*C3))**(1./(a3+1))\n",
    "    \n",
    "    # Return the inverse CDF values\n",
    "    return xvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mass per system in Universe 0.5145862473992391\n"
     ]
    }
   ],
   "source": [
    "Sampe_size = int(5e6)\n",
    "totalMassInStarFormation =  get_totalMassInStarFormation(sampleSize=Sampe_size, binaryFraction=0.7)\n",
    "\n",
    "average_mass_per_system_univ = totalMassInStarFormation/Sampe_size\n",
    "print(f'Average mass per system in Universe {average_mass_per_system_univ}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "*** \n",
    "## max $\\eta_{BBH}$\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_BBH = 1./0.51 * (0.0003431059134688049 * 0.4292256071356476 * 1.0 * 1.0 ) =  0.0002861907887449239 = 2.86E-04\n"
     ]
    }
   ],
   "source": [
    "eta_BBH = 1./average_mass_per_system_univ * (f_primaryf_secondary_bhbh * f_init_sep * f_sn1_bbh * f_sn2_bbh )\n",
    "print(f'eta_BBH = 1./{np.round(average_mass_per_system_univ,2)} * ({f_primaryf_secondary_bhbh} * {f_init_sep} * {f_sn1_bbh} * {f_sn2_bbh} ) =  {eta_BBH} = {eta_BBH:.2E}' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## max $\\eta_{BHNS}$\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_BHNS = 1./0.51 * (3.957212883472308e-06 * 0.4292256071356476 * 1.0 * 1.0) =  3.300782154707697e-06 = 3.30E-06\n"
     ]
    }
   ],
   "source": [
    "eta_BHNS = 1./average_mass_per_system_univ * (f_primaryf_secondary_bhns * f_init_sep * f_sn1_bhns * f_sn2_bhns )\n",
    "print(f'eta_BHNS = 1./{np.round(average_mass_per_system_univ,2)} * ({f_primaryf_secondary_bhns} * {f_init_sep} * {f_sn1_bhns} * {f_sn2_bhns}) =  {eta_BHNS} = {eta_BHNS:.2E}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## max $\\eta_{NSNS}$\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_nsns = 1./0.51 * (0.0001134746975095127 * 0.4292256071356476 * 0.2 * 1.0 ) =  1.8930255590474834e-05 = 1.89E-05\n"
     ]
    }
   ],
   "source": [
    "f_sn2_nsns = 1.\n",
    "\n",
    "eta_NSNS = 1./average_mass_per_system_univ * (f_primaryf_secondary_nsns * f_init_sep * f_sn1_nsns * f_sn2_nsns )\n",
    "print(f'eta_nsns = 1./{np.round(average_mass_per_system_univ,2)} * ({f_primaryf_secondary_nsns} * {f_init_sep} * {f_sn1_nsns} * {f_sn2_nsns} ) =  {eta_NSNS} = {eta_NSNS:.2E}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
