{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical computation of the Maximum formation efficiency\n",
    "\n",
    "As described in section 2 from the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "# from numpy import trapz\n",
    "\n",
    "# add run_data path to sys\n",
    "sys.path.append('./run_data')\n",
    "from definitions import sim_flags_dict\n",
    "\n",
    "\n",
    "######################################\n",
    "## PLOT setttings\n",
    "plt.rc('font', family='serif')\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "fsize, SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = 30,20,25,30\n",
    "for obj in ['axes','xtick','ytick']:\n",
    "    plt.rc(obj, labelsize=SMALL_SIZE)          # controls default text sizes\n",
    "for obj in ['figure','axes']:\n",
    "    plt.rc(obj, titlesize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate maximum formation efficiency\n",
    "\n",
    "We approximate the 'maximum' formation efficiency using a drake equation:\n",
    "\n",
    "\\begin{equation}\n",
    "     \\eta_{form} = \\frac{1}{\\langle M_{SF} \\rangle } \\Bigl( f_{\\mathrm{primary}} \\times f_{\\mathrm{secondary}} \\times f_{\\mathrm{init \\, sep}} \\times f_{\\mathrm{survive \\, SN1}} \\times f_{\\mathrm{survive \\, SN2}} \\Bigr)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### Probability of forming \n",
    "\n",
    "We approximate the terms _within the round brackets_ of Equation 1 above with the probability to form a pair of massive stars with the `right' set of (initial) conditions. The conditions in questions are random variables at ZAMS (the primary mass, $m_1$, secondary mass, $m_2$, orbital separation, $a$), and factors affecting the stars' survival during supernovae in the first and second mass transfer phases. \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(m_1, ~m_2, ~a, ~\\text{survive SN1}, ~\\text{survive SN2}) \n",
    "& = p(m_1) \\times p(m_2~|~m_1) \\\\\n",
    "& \\times p(a ~|~m_1, ~m_2) \\\\\n",
    "& \\times  p(\\text{survive SN1}~|~m_1, ~m_2, ~a) \\\\\n",
    "& \\times p(\\text{survive SN2}~|~m_1, ~m_2, ~a, ~\\text{survive SN1})\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "By integrating over the relevant ranges of $m_1, ~q, ~a, ~\\text{survive SN1}, ~\\text{survive SN2} \\in C$, we obtain the probability for a specific type of compact binary merger to occur. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Primary and secondary masses\n",
    "We compute the probability that $m_2$ falls within a certain mass range [c,d] given that $m_1$ within a certain mass range [a,b]:\n",
    "\n",
    "\\begin{equation} \n",
    "\\begin{split}\n",
    "f_{\\text{primary}} \\times f_{\\text{secondary}} \n",
    "&  \\approx   \\int_{m_1 = a}^{m_1 = b} dm_1 \\int_{m_2 = c}^{m_2 = d} dm_2  \\, p(m_1) \\times p(m_2 | m_1)  \n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Given a fixed primary mass $m_1$, $p(q~|~m_1)$ represents the probability density of finding a partner star such that the mass ratio becomes $q$. \n",
    "\n",
    "We can write $m_2$ in terms of the mass ratio $q \\equiv m_2/m_1 < 1$, which follows a uniform probability distribution between $0.01$ and $1$:\n",
    "\n",
    "\\begin{equation}\n",
    "    p(q~|~m_1) = U\\left(q | \\frac{0.01 \\, M_{\\odot}}{m_1}, 1\\right) \n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume $p(m_1)$ follows the Kroupa IMF, defined as:\n",
    "\\begin{equation} \n",
    "\\text{Kroupa IMF}(m_1) = C_1\n",
    "    \\begin{cases}\n",
    "      (m_1/M_{\\odot})^{-0.3} & 0.01~M_{\\odot} \\leq m_1 < 0.08~M_{\\odot}\\\\\n",
    "      C_2 \\cdot (m_1/M_{\\odot})^{-1.3} & 0.08~M_{\\odot} \\leq m_1 < 0.5~M_{\\odot}\\\\\n",
    "      C_3 \\cdot (m_1/M_{\\odot})^{-2.3} & 0.5~M_{\\odot} \\leq m_1 < 300~M_{\\odot}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Here $C_2 = 0.08^{-0.3 + 1.3} = 0.08$, and $C_3 = C_2 \\cdot 0.5^{-1.3 + 2.3} = 0.08 \\cdot 0.5$ to ensure continuity.\n",
    "C_1 is a normalization constant, determined by normalizing the IMF over the entire mass range:\n",
    "\\begin{equation}\n",
    "    C_1 = \\Big[ \\frac{0.08^{(-0.3+1)}-0.01^{(-0.3+1)}}{(-0.3+1)} + 0.08 \\cdot \\left( \\frac{0.5^{(-1.3+1)}-0.08^{(-1.3+1)}}{(-1.3+1)} \\right) + 0.08 \\cdot 0.5 \\cdot \\left(\\frac{300^{(-2.3+1)}-0.5^{(-2.3+1)}}{(-2.3+1)} \\right)  \\Big]^{-1} \\,  1/M_{\\odot}\n",
    "\\end{equation}\n",
    "Note that we set the minimum and maximum stellar masses to $0.01~M_{\\odot}$ and $300~M_{\\odot}$, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9869192439784182\n",
      "Kroupa at 20Msun 0.00039832742373213404\n",
      "Kroupa at 20Msun 0.00039832742373213404 3.98E-04\n"
     ]
    }
   ],
   "source": [
    "# the integral of a piece (or term) of a broken powerlaw\n",
    "def norm_term(minm, maxm, power):\n",
    "    return (maxm**(power + 1) - minm**(power + 1)) / (power + 1)\n",
    "\n",
    "C2 = 0.08\n",
    "C3 = 0.08 * 0.5\n",
    "\n",
    "term1 = norm_term(0.01, 0.08, -0.3)\n",
    "term2 = C2 * norm_term(0.08, 0.5, -1.3)\n",
    "term3 = C3 * norm_term(0.5, 300, -2.3)\n",
    "\n",
    "C1 = 1/(term1+ term2 + term3 )\n",
    "print(C1)\n",
    "\n",
    "\n",
    "def normalized_Kroupa(mass, C_1 = C1, C_2 = C2, C_3 = C3):\n",
    "    mass = np.asarray(mass)  # Ensure mass is a NumPy array\n",
    "    \n",
    "    conditions = [\n",
    "        (0.01 <= mass) & (mass < 0.08),\n",
    "        (0.08 <= mass) & (mass < 0.5),\n",
    "        (0.5 <= mass) & (mass < 300)\n",
    "    ]\n",
    "    \n",
    "    choices = [\n",
    "        C_1 * mass**-0.3,\n",
    "        C_1 * C_2 * mass**-1.3,\n",
    "        C_1 * C_3 * mass**-2.3\n",
    "    ]\n",
    "    \n",
    "    return np.select(conditions, choices, default=0)\n",
    "\n",
    "print('Kroupa at 20Msun', C1 * C3 * 10**-2.3 )\n",
    "print('Kroupa at 20Msun', f\"{normalized_Kroupa(10)} {normalized_Kroupa(10):.2E}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $0.01 \\, M_{\\odot} < a < m_1 < b < 300 \\, M_{\\odot}$ and $0.01 \\, M_{\\odot} < c < m_2 < \\min\\left( m_1, d \\right) < 300 \\, M_{\\odot}$, we can coombine the equations above to get:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        f_{\\text{primary}} \\times f_{\\text{secondary}} \n",
    "        & = \\int_{m_1=a}^{m_1=b} dm_1  \\int_{q=c/m_1}^{q=\\min\\left(1, d/m_1\\right)} dq  ~ p(m_1) \\times p(q|m_1) \\\\\n",
    "        & = \\int_{m_1=a}^{m_1=b} dm_1 \\int_{q=c/m_1}^{q=\\min\\left(1, d/m_1\\right)} dq ~\\text{Kroupa IMF}(m_1) \\times U(q|\\frac{0.01M_{\\odot}}{m_1},1) \\\\\n",
    "        & = \\int_{m_1=a}^{m_1=b} dm_1 ~\\text{Kroupa IMF}(m_1) \\frac{\\min\\left(1, \\frac{d}{m_1}\\right) - \\frac{c}{m_1}}{1 - \\frac{0.01 \\, M_{\\odot}}{m_1}} \\\\\n",
    "        & = \\int_{m_1=a}^{m_1=b} dm_1 ~\\text{Kroupa IMF}(m_1) \\times  \\left( \\frac{\\min\\left(m_1, d\\right) - c}{m_1 - 0.01 \\, M_{\\odot}} \\right)  \\\\\n",
    "        & = \\int_{m_1=a}^{m_1=b} dm_1 C_1 \\cdot C_3 \\cdot  m_1^{-2.3} \\times  \\left( \\frac{\\min\\left(m_1, d\\right) - c}{m_1 - 0.01 \\, M_{\\odot}} \\right) \n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Note that the $\\min\\left(1, d/m_1\\right)$ imposes that $q$ can never be greater than 1, and that we don't have to use $\\max\\left(0, c/m_1\\right)$, because we stated above that  $0.01 \\, M_{\\odot} < c$.\n",
    "\n",
    "Moreover, we filled in the Kroupa IMF in the last line because for all our cases of interest, $a > 0.5M_{\\odot}$.  \n",
    "\n",
    "Now we want to integrate this, which we will do numerically, because it is a bit of an ugly thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_primaryXf_secondary(a, b, c, d, C_1 = C1, C_2 = C2, C_3 = C3):\n",
    "    \"\"\"function to compute the integral of p(m1)p(q|q) dm1 dq\n",
    "    a,b are the lower and upper limits of m1\n",
    "    c,d are the lower and upper limits of m2, though we have re-written the integral in terms of q\n",
    "    \"\"\"\n",
    "    masses = np.logspace(np.log10(a), np.log10(b), 1000)\n",
    "    # print(normalized_Kroupa(masses, C_1, C_2,  C_3))\n",
    "\n",
    "    dfprimXfsec_dm1 = normalized_Kroupa(masses, C_1, C_2,  C_3) * (np.minimum(masses,d) - c ) / (masses - 0.01)\n",
    "    \n",
    "    return np.trapz(dfprimXfsec_dm1, masses)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BHBH\n",
    "\n",
    "For BHBH, we assume both primary and secondary masses range from [$20M_{\\odot}$,$300M_{\\odot}$]\n",
    "\n",
    "\n",
    "for $m_1 = [a,b]$ and $m_2 = [c,d]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005057173140578265 = 5.06E-04\n",
      "f_primary X f_secondary (BHBH) = 0.0005056568487100195 = 5.06E-04\n"
     ]
    }
   ],
   "source": [
    "# Do it once manuallly just to check\n",
    "ms = np.logspace(np.log10(20), np.log10(300), 1000)\n",
    "integrand = C1 * C3 * ms**-2.3 * (np.minimum(ms, 300) - 20) / (ms - 0.01)\n",
    "print(f\"{np.trapz( integrand, ms)} = {np.trapz( integrand, ms):.2E}\" )\n",
    "\n",
    "\n",
    "f_primaryf_secondary_bhbh = f_primaryXf_secondary(20, 300, 20, 300, C_1 = C1, C_2 = C2, C_3 = C3)\n",
    "print(f\"f_primary X f_secondary (BHBH) = {f_primaryf_secondary_bhbh} = {f_primaryf_secondary_bhbh:.2E}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSNS\n",
    "\n",
    "For NSNS we assume both primary and secondary masses range from [$8M_{\\odot}$,$20M_{\\odot}$]\n",
    "\n",
    "<!-- \\begin{equation}\n",
    "\\begin{split}\n",
    "    f_{\\text{primary}} \\times f_{\\text{secondary}}\n",
    "    & = (\\text{constant}) \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} d(m_1/M_{\\odot}) \\int_{q=8/m_1}^{q=20/m_1} dq ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-2.7} \\times \\frac{M_{\\odot}}{m_1} \\\\\n",
    "    & = \\text{constant} \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} \\left(\\frac{20}{m_1} - \\frac{8}{m_1} \\right) ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-3.7} \\\\\n",
    "    & = \\text{constant} \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} m_1 ^{-1} \\left(20 - 8 \\right) ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-3.7} \\\\\n",
    "    & = \\text{constant}  \\left(20 - 8 \\right) \\int_{m_1=8M_{\\odot}}^{m_1=20M_{\\odot}} ~\\Big(\\frac{m_1}{M_{\\odot}}\\Big)^{-4.7} \\\\\n",
    "    & = \\text{constant}  \\frac{\\left(20 - 8 \\right)}{-3.7} \\Big[ \\left(\\frac{m_1}{M_{\\odot}}\\right)^{-3.7} \\Big]^{20}_{8} \\\\\n",
    "    & = \\text{constant}  \\frac{\\left(20 - 8 \\right)}{-3.7} \\Big[ 20^{-3.7} - 8^{-3.7} \\Big]\\\\\n",
    "    & = 2.43 \\times 10^{-4}\n",
    "\\end{split}\n",
    "\\end{equation} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_primary X f_secondary (NSNS) =  0.0008181117372854546 = 8.18E-04\n"
     ]
    }
   ],
   "source": [
    "f_primaryf_secondary_nsns = f_primaryXf_secondary(8, 20, 8, 20, C_1 = C1, C_2 = C2, C_3 = C3)\n",
    "print(f\"f_primary X f_secondary (NSNS) =  {f_primaryf_secondary_nsns} = {f_primaryf_secondary_nsns:.2E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BHNS\n",
    "\n",
    "Lastly for BHNS we assume $m_1 = [20M_{\\odot}$,$300M_{\\odot}]$ while $m_2 = [8M_{\\odot}$,$20M_{\\odot}]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " f_primary X f_secondary (BHNS) =  0.00042132763741340086 = 4.21E-04\n"
     ]
    }
   ],
   "source": [
    "f_primaryf_secondary_bhns =  f_primaryXf_secondary(20, 300, 8, 20, C_1 = C1, C_2 = C2, C_3 = C3)\n",
    "print(f\" f_primary X f_secondary (BHNS) =  {f_primaryf_secondary_bhns} = {f_primaryf_secondary_bhns:.2E}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for $f_{init sep}$, we adopt the fraction of systems that interacts ever. \n",
    "\n",
    "We assume that binaries can form with separations between 0.01AU and 1000 AU \n",
    "\n",
    "we assume a flat-in-log distribution of initial separations\n",
    "\n",
    "\\begin{equation}\n",
    "P(a_i) = 1/a_i\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "f_{init sep} = \\frac{\\log(a_i)|_{mina}^{maxa} }{\\log(a_i)|_{0.01 AU}^{1000 AU} }\n",
    "\\end{equation}\n",
    "\n",
    "where $mina$ and $maxa$ are the min and max separation for interaction,\n",
    "For the minimum, we look at our case A,B C plots, and stars have radii of $3-20R_{\\odot}$ at birth (roughly), leading to a range of 0.0279AU - 0.186AU. We adopt the average of $mina \\approx 0.1 AU$\n",
    "\n",
    "For the upper end, we use our max R per Z to estimate this. Very roughly stars range between a max R of 1000 and 5000, so we adopt $maxa \\approx 3000 R_{\\odot} = 13.95 AU$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "f_{init sep} = \\frac{\\log(13.95) - \\log(0.1)}{\\log(1000) - \\log(0.01)} \\approx 0.43\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43\n"
     ]
    }
   ],
   "source": [
    "f_init_sep = (np.log(14) - np.log(0.1))/ (np.log(1000) - np.log(0.01))\n",
    "print( np.round(f_init_sep,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability to survive SN1 and SN2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We assume no kicks for BBH so $f_{SN1} = f_{SN2} = 1$\n",
    "\n",
    " We assume full kicks for NSNS so $f_{SN2} = f_{SN1} \\approx 0.2$ (See derivationin appendix A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sn1_bbh = 1.\n",
    "f_sn2_bbh = 1.\n",
    "\n",
    "f_sn1_bhns = 1.\n",
    "f_sn2_bhns = 1. #0.23\n",
    "\n",
    "f_sn1_nsns = 0.23\n",
    "f_sn2_nsns = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average SF mass per binary system\n",
    "\n",
    "We use the 'total mass evolved per Z' function that we also use for the yield calculations for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_totalMassInStarFormation(x2=0.08, x3=0.5, a1=-0.3, a2=-1.3, a3=-2.3, C1=1.,\n",
    "                         Mmin_universe=0.01, Mmax_universe=300., sampleSize=2000000):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        # COMPAS simulation parameters\n",
    "        pathCOMPASh5 (_type_, optional): path to your COMPAS file. Defaults to None.\n",
    "\n",
    "        # Broken powerlaw (Kroupa IMF) parameters\n",
    "        x1, x2, x3, x4: float, the break points (mass ranges) for the three segments\n",
    "        a1, a2, a3: float, the power law indices \n",
    "        <0.01 - 0.08> a = -0.3, <0.08 - 0.5> a = -1.3, <0.5 - 200> a = -2.3\n",
    "        C1: float, the normalization constant for the first segment\n",
    "        \n",
    "        # Believes about star formation in the Universe\n",
    "        binaryFraction (int, optional): What fraction of stars are in binaries. Default= 1.\n",
    "        Mmin_universe, Mmax_universe (float): the min and max mass that stars in the Universe can be born with  Defaults: 0.01 and 200.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\" \n",
    "    x1 = Mmin_universe\n",
    "    x4 = Mmax_universe\n",
    "\n",
    "    ##########################\n",
    "    # Create Sample Universe \n",
    "    ##########################\n",
    "    # we will use 'inverse transform sampling method' to sample our sample Universe from the IMF\n",
    "\n",
    "    ### Primary mass\n",
    "    # first we compute the y-values of the CDF of our IMF at Mmin_universe and Mmax_universe\n",
    "    # Mmin_universe and Mmax_universe have to be between x1 and x4\n",
    "    CDFmin = CDFbrokenPowerLaw(np.array([Mmin_universe]), x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "    CDFmax = CDFbrokenPowerLaw(np.array([Mmax_universe]), x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "\n",
    "    # Now we can sample Uniformly from the CDF between CDFmin and CDFmax\n",
    "    drawM1      = np.random.uniform(CDFmin,CDFmax,sampleSize)\n",
    "    # Convert CDF values back to masses\n",
    "    M1          = invertCDFbrokenPowerLaw(drawM1, x1, x2, x3, x4, a1, a2, a3, C1)\n",
    "\n",
    "    ### Secondary mass\n",
    "    # mass ratio (q = m2/m1) distribution is assumed to be flat \n",
    "    # so then the drawM2 (if it is in a binary) just becomes the mass fraction.\n",
    "    drawM2          = np.random.uniform(0,1,sampleSize)    # we are actually sampling q\n",
    "    M2              = np.zeros(sampleSize)                 # are zeros, but will be filled with binary fraction\n",
    "\n",
    "    ### Binary fraction\n",
    "    # we want that binaryFraction of the stars are in binaries\n",
    "    # Hence by drawing between 0-1, we have to throw out everything that is above binaryFraction (i.e. = single and m2 = 0)\n",
    "    # to incorporate the mass dependence of f_binary, we bin our samples in mass and draw a binary fraction for each bin\n",
    "    binary_bin_edges    = [x1, 0.08, 0.5, 1, 10, x4]\n",
    "    binaryFractions     = [0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "    for m_i in range(len(binary_bin_edges[:-1])):\n",
    "        m1_mask = (M1 >= binary_bin_edges[m_i]) & (M1 < binary_bin_edges[m_i+1])\n",
    "        drawBinary = np.random.uniform(0,1,np.sum(m1_mask)) # draw a binary for all the samples in this mass bin\n",
    "        maskBinary = drawBinary < binaryFractions[m_i]\n",
    "        \n",
    "        # if maskBinary is True, then M2 = q * m1, else M2 = 0\n",
    "        M2[m1_mask] = np.where(maskBinary, drawM2[m1_mask] * M1[m1_mask], 0)\n",
    "\n",
    "    totalMassInStarFormation = np.sum(M1) + np.sum(M2)\n",
    "\n",
    "    return totalMassInStarFormation\n",
    "\n",
    "\n",
    "def CDFbrokenPowerLaw(x, x1=0.01, x2=0.08, x3=0.5, x4=200, a1=-0.3, a2=-1.3, a3=-2.3, C1=1):\n",
    "    \"\"\"\n",
    "    CDF values of a three-part broken powerlaw representing a Kroupa IMF by default.\n",
    "    \n",
    "    Parameters:\n",
    "    x: array-like, the input values\n",
    "    x1, x2, x3, x4: float, the break points (mass ranges) for the three segments\n",
    "    a1, a2, a3: float, the power law indices \n",
    "    C1: float, the normalization constant for the first segment\n",
    "    \n",
    "    Returns:\n",
    "    yvalues: array-like, the output values of the CDF\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the output array\n",
    "    yvalues = np.zeros(len(x))\n",
    "    \n",
    "    # Calculate the normalization constants for the other segments\n",
    "    # Ensuring that the next segments start where the previous segment ends\n",
    "    C2 = float(C1 * (x2**(a1-a2)))\n",
    "    C3 = float(C2 * (x3**(a2-a3)))\n",
    "    \n",
    "    # Calculate the normalization factors for the three segments\n",
    "    N1 = float(((1./(a1+1)) * C1 * (x2**(a1+1))) - ((1./(a1+1)) * C1 * (x1**(a1+1))))\n",
    "    N2 = float(((1./(a2+1)) * C2 * (x3**(a2+1))) - ((1./(a2+1)) * C2 * (x2**(a2+1))))\n",
    "    N3 = float(((1./(a3+1)) * C3 * (x4**(a3+1))) - ((1./(a3+1)) * C3 * (x3**(a3+1))))\n",
    "    \n",
    "    # Calculate the denominator of the CDF\n",
    "    bottom = N1+N2+N3\n",
    "    \n",
    "    # Calculate the CDF values for x range: x1<=x<x2\n",
    "    mask1 = (x>=x1) & (x<x2)\n",
    "    top1 = ( (1./(a1+1) ) * C1 * (x[mask1]**(a1+1) ) - (1./(a1+1) ) * C1 * (x1**(a1+1) ) ) \n",
    "    yvalues[mask1] = top1/bottom\n",
    "    \n",
    "    # Calculate the CDF values for x range: x2<=x<x3\n",
    "    mask2 = (x>=x2) & (x<x3)\n",
    "    top2 =  N1 + ( (1./(a2+1) ) * C2 * (x[mask2]**(a2+1) ) - (1./(a2+1)) * C2 * (x2**(a2+1) ) ) \n",
    "    yvalues[mask2] = top2/bottom\n",
    "    \n",
    "    # Calculate the CDF values for x range: x3<=x<=x4\n",
    "    mask3 = (x>=x3) & (x<=x4)\n",
    "    top3 =  N1 + N2 + ( (1./(a3+1)) * C3 * (x[mask3]**(a3+1)) - (1./(a3+1)) * C3 * (x3**(a3+1) ) )\n",
    "    yvalues[mask3] = top3/bottom\n",
    "    \n",
    "    return yvalues\n",
    "\n",
    "\n",
    "def invertCDFbrokenPowerLaw(CDF, x1, x2, x3, x4, a1, a2, a3, C1):\n",
    "    \"\"\"\n",
    "    Invert y-values of a CDF back to x-vals (i.e. the masses)\n",
    "    Specifically for a three-part piece-wise powerlaw representing a Kroupa IMF by default. \n",
    "\n",
    "    Parameters:\n",
    "    CDF: array-like, the CDF values to invert\n",
    "    x1, x2, x3, x4: float, the break points (ranges) for the three segments\n",
    "    a1, a2, a3: float, the power law indices for the three segments\n",
    "    C1: float, the normalization constant for the first segment\n",
    "\n",
    "    Returns:\n",
    "    xvalues: array-like, the inverted CDF values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the normalization constants for the second and third segments\n",
    "    C2 = float(C1 * (x2**(a1-a2)))\n",
    "    C3 = float(C2 * (x3**(a2-a3)))\n",
    "    \n",
    "    # Calculate the area under the curve for each segment\n",
    "    N1 = float(((1./(a1+1)) * C1 * (x2**(a1+1))) - ((1./(a1+1)) * C1 * (x1**(a1+1))))\n",
    "    N2 = float(((1./(a2+1)) * C2 * (x3**(a2+1))) - ((1./(a2+1)) * C2 * (x2**(a2+1))))\n",
    "    N3 = float(((1./(a3+1)) * C3 * (x4**(a3+1))) - ((1./(a3+1)) * C3 * (x3**(a3+1))))\n",
    "    \n",
    "    # Calculate the CDF values at the breakpoints\n",
    "    CDFx2 = CDFbrokenPowerLaw(np.array([x2,x2]), x1, x2, x3, x4, a1, a2, a3, C1)[0]\n",
    "    CDFx3 = CDFbrokenPowerLaw(np.array([x3,x3]), x1, x2, x3, x4, a1, a2, a3, C1)[0]\n",
    "\n",
    "    # Initialize the output array\n",
    "    xvalues = np.zeros(len(CDF))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the first segment\n",
    "    mask1 = (CDF < CDFx2)\n",
    "    xvalues[mask1] =  (((CDF[mask1]*(N1+N2+N3))  + \\\n",
    "                      ( (1./(a1+1))*C1*(x1**(a1+1))))/((1./(a1+1))*C1))**(1./(a1+1))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the second segment\n",
    "    mask2 = (CDFx2<= CDF) & (CDF < CDFx3)\n",
    "    xvalues[mask2] = ((((CDF[mask2]*(N1+N2+N3))-(N1))  + \\\n",
    "                      ( (1./(a2+1))*C2*(x2**(a2+1))))/((1./(a2+1))*C2))**(1./(a2+1))\n",
    "    \n",
    "    # Calculate the inverse CDF values for the third segment\n",
    "    mask3 = (CDFx3<= CDF) \n",
    "    xvalues[mask3] = ((((CDF[mask3]*(N1+N2+N3))-(N1+N2))  + \\\n",
    "                      ((1./(a3+1))*C3*(x3**(a3+1))))/((1./(a3+1))*C3))**(1./(a3+1))\n",
    "    \n",
    "    # Return the inverse CDF values\n",
    "    return xvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mass per system in Universe 0.51452911659734\n"
     ]
    }
   ],
   "source": [
    "Sampe_size = int(6e6)\n",
    "totalMassInStarFormation =  get_totalMassInStarFormation(sampleSize=Sampe_size)\n",
    "\n",
    "average_mass_per_system_univ = totalMassInStarFormation/Sampe_size\n",
    "print(f'Average mass per system in Universe {average_mass_per_system_univ}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "*** \n",
    "## max $\\eta_{BBH}$\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_BBH = 1./0.51 * (5.06E-04 * 0.43 * 1.0 * 1.0 ) =  0.00042182426783770954 = 4.22E-04\n"
     ]
    }
   ],
   "source": [
    "eta_BBH = 1./average_mass_per_system_univ * (f_primaryf_secondary_bhbh * f_init_sep * f_sn1_bbh * f_sn2_bbh )\n",
    "print(f'eta_BBH = 1./{average_mass_per_system_univ:.2f} * ({f_primaryf_secondary_bhbh:.2E} * {f_init_sep:.2f} * {f_sn1_bbh} * {f_sn2_bbh} ) =  {eta_BBH} = {eta_BBH:.2E}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## max $\\eta_{NSNS}$\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_nsns = 1./0.51 * (8.18E-04 * 0.43 * 0.23 * 1.0 ) =  0.00015696980799955325 = 1.57E-04\n"
     ]
    }
   ],
   "source": [
    "eta_NSNS = 1./average_mass_per_system_univ * (f_primaryf_secondary_nsns * f_init_sep * f_sn1_nsns * f_sn2_nsns )\n",
    "print(f'eta_nsns = 1./{average_mass_per_system_univ:.2f} * ({f_primaryf_secondary_nsns:.2E} * {f_init_sep:.2f} * {f_sn1_nsns} * {f_sn2_nsns} ) =  {eta_NSNS} = {eta_NSNS:.2E}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## max $\\eta_{BHNS}$\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_BHNS = 1./0.51 * (4.21E-04 * 0.43 * 1.0 * 1.0) =  0.0003514759517746015 = 3.51E-04\n"
     ]
    }
   ],
   "source": [
    "eta_BHNS = 1./average_mass_per_system_univ * (f_primaryf_secondary_bhns * f_init_sep * f_sn1_bhns * f_sn2_bhns )\n",
    "print(f'eta_BHNS = 1./{average_mass_per_system_univ:.2f} * ({f_primaryf_secondary_bhns:.2E} * {f_init_sep:.2f} * {f_sn1_bhns} * {f_sn2_bhns}) =  {eta_BHNS} = {eta_BHNS:.2E}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
